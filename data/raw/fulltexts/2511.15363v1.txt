Fidelity-Preserving Quantum Encoding for Quantum Neural Networks
Yuhu Lu
School of Computer Science and Engineering, Central South University
Changsha 410083, China
Jinjing Shi ∗
School of Electronic Information, Central South University
Changsha 410083, China
shijinjing@csu.edu.cn
Abstract
Efficiently encoding classical visual data into quantum states is essential for realizing practical quantum neural networks
(QNNs). However, existing encoding schemes often discard spatial and semantic information when adapting high-dimensional
images to the limited qubits of Noisy Intermediate-Scale Quantum (NISQ) devices. We propose a Fidelity-Preserving Quan-
tum Encoding (FPQE) framework that performs near lossless data compression and quantum encoding. FPQE employs a
convolutional encoder-decoder to learn compact multi-channel representations capable of reconstructing the original data
with high fidelity, which are then mapped into quantum states through amplitude encoding. Experimental results show that
FPQE performs comparably to conventional methods on simple datasets such as MNIST, while achieving clear improvements
on more complex ones, outperforming PCA and pruning based encodings by up to 10.2% accuracy on Cifar-10. The perfor-
mance gain grows with data complexity, demonstrating FPQE’s ability to preserve high-level structural information across
diverse visual domains. By maintaining fidelity during classical to quantum transformation, FPQE establishes a scalable
and hardware efficient foundation for high-quality quantum representation learning.
1. Introduction
Quantum computing has emerged as a promising paradigm for advancing machine learning and visual understanding, of-
fering the potential to exploit the expressive power of quantum states for high-dimensional data analysis [11, 29]. With
recent progress in quantum hardware and simulation frameworks, quantum neural networks (QNNs) have been increasingly
explored for classification, generative modeling, and representation learning Despite rapid progress, one key bottleneck re-
mains unresolved is efficiently encoding classical visual data into quantum states without losing critical spatial or semantic
information [9, 32, 34]. This problem becomes even more severe under the constraints of Noisy Intermediate-Scale Quantum
(NISQ) devices, where the number of available qubits is limited and noise sensitivity is high.
Existing quantum encoding strategies primarily fall into three categories. The first type directly maps pixel or feature
vectors to quantum states via amplitude [10, 20] or angle encoding [19]. While these methods are straightforward, but they
may struggle to handle high-dimensional data, leading to partial loss of local structures and correlations. The second type
applies classical dimensionality reduction like principal component analysis (PCA) [17] and autoencoder compression [13]
before quantum encoding. Although this reduces qubit requirements, it introduces irreversible information loss, weakening
the representational fidelity and degrading performance on complex vision datasets. More recent quantum oriented encoders
including patch-based Single Qubit Encoding (SQE) [8] and pruning-based adaptive threshold pruning (ATP) [2] address
certain resource constraints but still degrade rapidly on datasets like Cifar-10. These methods tend to preserve pixel level
statistics while failing to retain global or local structure, which we find to be essential for quantum models to learn meaningful
decision boundaries.
The gap between compressibility and fidelity preservation motivates the need for encoding methods that remain compatible
1
arXiv:2511.15363v1  [quant-ph]  19 Nov 2025

with tight qubit budgets while retaining the structure necessary for visual recognition [14, 16]. This requirement is rarely
stated explicitly, yet our experiments show that structural fidelity that captured by metrics such as SSIM is strongly correlates
with QNN performance, whereas commonly used metrics such as MSE and PSNR do not reliably predict learning outcomes
[3]. This observation suggests that the primary bottleneck in existing encoding methods is not dimensionality reduction itself
but the loss of structural information during the transformation process.
To overcome these limitations, we propose Fidelity-Preserving Quantum Encoding (FPQE), a preprocessing framework
that achieves near-lossless classical-to-quantum data transformation. FPQE employs a convolutional encoder-decoder that
learns low-dimensional, multi-channel representations capable of reconstructing the original image with high fidelity. The
compressed representations are then mapped into quantum states using amplitude encoding, ensuring that both global and
local structures are preserved during the transformation process. Unlike conventional methods that optimize only for com-
pression or feasibility, FPQE explicitly optimizes for fidelity preservation, thereby improving the quality of quantum repre-
sentations available to downstream QNNs.
We evaluate FPQE on three benchmark datasets: MNIST, FashionMNIST, and Cifar-10. While FPQE performs compa-
rably to baseline encoders on simple datasets such as MNIST, it achieves up to 10.2% higher accuracy on more complex
datasets like Cifar-10, indicating that its advantage grows with data complexity. This improvement demonstrates FPQE’s
ability to retain rich structural correlations that conventional dimensionality-reduction techniques fail to preserve.
The main contributions of this work are summarized as follows:
1. We propose a novel Fidelity-Preserving Quantum Encoding (FPQE) that minimizes information loss during classical-to-
quantum transformation.
2. We build quantum neural networks powered by FPQE and conduct extensive binary classification experiments on MNIST,
FashionMNIST, and Cifar-10. Across all datasets, FPQE consistently outperforms traditional encoding schemes, with the
performance gap widening as visual complexity increases.
3. We provide a comprehensive fidelity analysis using MSE, PSNR, and SSIM, showing that FPQE maintains not only pixel-
level similarity but also high structural fidelity. This structure preservation directly translates into improved downstream
QNN performance.
2. Renalted Works
Classical to Quantum Encoding:
Research on quantum machine learning has progressed rapidly in recent years, driven
by advances in quantum hardware and the development of variational quantum algorithms. Within this landscape, one of the
most critical challenges is the design of efficient encoding mechanisms that translate classical data into expressive quantum
states suitable for downstream learning [24, 28, 31].
The most widely used strategies include amplitude encoding, where classical feature vectors are normalized and embedded
into the amplitudes of a quantum state; angle encoding, where data values modulate qubit rotation angles; and basis encoding,
where each bit of classical data is mapped to the state of a qubit [4, 27]. While conceptually simple, these approaches
scale poorly for high-dimensional visual inputs, as the number of required qubits increases exponentially with image size.
Moreover, when operating under the constraints of Noisy Intermediate-Scale Quantum (NISQ) devices [23], direct high-
dimensional encoding introduces noise and decoherence that severely degrade the representational fidelity of the resulting
quantum states.
To mitigate the dimensionality mismatch between high-resolution images and the small number of qubits available on
NISQ devices, several works explore classical dimensionality reduction techniques before encoding the data into quantum
states. Principal component analysis and linear projections [17] reduce dimensionality by capturing global variance, but they
fail to preserve fine grained spatial patterns. Autoencoder based strategies offer more flexible representations, yet they often
optimize reconstruction error without explicitly maintaining structural or semantic fidelity. As a result, these methods may
yield compact encodings but do not necessarily produce quantum relevant representations that benefit downstream variational
models.
More recent studies propose learning based or algorithmic compression schemes specifically designed for quantum ap-
plications. SQE transforms small image patches into single qubit states and has been shown to improve the efficiency of
quantum image classification [8]. However, SQE focuses on local patch embeddings and only partially preserves global
semantic structures, making it less effective on visually complex datasets with high inter class variability. ATP introduces a
pruning mechanism to reduce redundant coefficients prior to quantum encoding, enabling more efficient state preparation, but
it similarly sacrifices structural information when the underlying images exhibit rich textures and global patterns [2]. Both
methods illustrate the importance of balancing compression and representational fidelity, yet they provide limited strategies
for preserving overall visual structure.
2

To alleviate these issues, various preprocessing based encoding schemes have been proposed. PCA and linear embeddings
are among the earliest solutions, projecting data into a lower-dimensional subspace before quantum encoding [5, 21, 22].
Although effective for dimensionality reduction, PCA often destroys spatial correlations essential for visual recognition.
Alternatively, several works explore autoencoder based quantum data compression, where classical or hybrid neural networks
are trained to generate compact latent vectors suitable for amplitude encoding [6, 15]. Another strategy is block or patch wise
encoding, in which images are partitioned into smaller subregions, each independently encoded as a quantum state [4, 12].
These methods reduce qubit requirements but lose inter patch dependencies, limiting their ability to represent global structure.
Quantum Neural Networks: QNNs aim to leverage the expressive capacity of parameterized quantum circuits (PQCs) for
learning tasks. Unlike classical networks, which operate in Euclidean space, QNNs manipulate data within exponentially
large Hilbert spaces, enabling richer nonlinear transformations and potentially more compact models [1, 7, 26, 33]. Early
works demonstrated that PQCs could serve as universal function approximators, capable of modeling highly complex decision
boundaries with relatively few trainable parameters [25, 30]. Subsequent studies explored their application to supervised
learning [18], generative modeling, and representation learning, confirming the flexibility of variational quantum circuits for
extracting patterns not easily captured by classical models.
A growing number of hybrid architectures combine classical feature extraction with quantum classifiers. For example,
[21] integrates convolutional neural networks with PQCs to handle high-dimensional images, while [5] introduces a unified
classical-quantum training framework enabling end-to-end optimization. Fully quantum architectures such as quantum con-
volutional neural networks (QCNNs) mimic the hierarchical structure of classical CNNs but process information entirely in
quantum space. These developments demonstrate the promise of quantum models for visual tasks and suggest that improved
quantum representations could further enhance performance.
Recent studies show that QNNs can approximate complex nonlinear mappings using fewer parameters than classical
models, thanks to high-dimensional Hilbert space representations [18, 30]. However, these benefits depend heavily on the
quality of data encoding, especially the low fidelity mappings cause state overlap, reducing the separability of quantum
features and diminishing learning performance.
Our work addresses this overlooked gap by placing fidelity preservation at the center of the classical to quantum trans-
formation process. The proposed FPQE framework introduces a learnable convolutional encoder-decoder trained explicitly
to retain both pixel level appearance and structural composition before quantum state preparation. Unlike traditional dimen-
sionality reduction techniques that prioritize qubit feasibility, FPQE is optimized to maintain global shapes, local textures,
and semantic boundaries, which is essential for robust quantum learning.
Once trained, FPQE produces multi-channel low-dimensional representations that align with the dimensional constraints
of amplitude encoding while preserving the structure necessary for effective discrimination. By maintaining high structural
similarity, FPQE reduces state overlap in Hilbert space and improves the separability of quantum features, enabling QNNs
to better exploit their expressive capacity. Experimental results across MNIST, FashionMNIST, and Cifar-10 show that
FPQE yields consistently stronger performance than angle encoding, amplitude encoding, PCA, SQE, and ATP, with the
performance advantage growing as data complexity increases.
3. Methods
The proposed FPQE is designed to efficiently map high-dimensional classical data into quantum states with minimal in-
formation loss. The framework integrates classical convolutional feature extraction with quantum data encoding, allowing
quantum neural networks to operate effectively on NISQ devices. The proposed FPQE based QNNs framework is shown if
Fig. 1, which consists of two main stages:
1. A classical fidelity-preserving encoder trained through an encoder–decoder reconstruction objective is shown in Fig. 1(a,
b);
2. A downstream QNN that consumes the compressed multi-channel representation is shown in 1(c,d).
3.1. Encoder-Decoder for Fidelity Preservation
The encoder-decoder structure is shown in 1(a). The encoder architecture follows a convolutional compression paradigm
with repeated Conv-BN-ReLU-Pooling layers that progressively reduce spatial dimensions while increasing channel depth.
This design allows encoder to aggregate local texture and edge information into multi-channel latent codes that maintain the
image’s global and local structure. The decoder mirrors this structure using transposed convolutions and upsampling layers,
ensuring near lossless reconstruction.
3

Quantum Network
QNN
FPQE
Freezing Parameters
Encoder
Encoder
Decoder
Decoder
Encoder
Decoder
q[0]
q[1]
q[2]
q[3]
Amplitude 
Encoding
...
...
Classifier
...
Classifier
(a)
(d)
(c)
(b)
Quantum Network
QNN
FPQE
Freezing Parameters
Encoder
Encoder
Decoder
Decoder
Encoder
Decoder
q[0]
q[1]
q[2]
q[3]
Amplitude 
Encoding
...
...
Classifier
...
Classifier
(a)
(d)
(c)
(b)
Figure 1. FPQE framework
Formally, given an input image x ∈RC×H×W , the encoder Eθ(·) projects it into a compact latent representation
z = Eθ(x) ∈Rc×h×w,
(1)
where h < H and w < W. The decoder Dη(·) mirrors the encoder using transposed convolutions and upsampling layers to
reconstruct the input
x′ = Dη(z).
(2)
The encoder-decoder is trained to minimize reconstruction loss:
Lrec = MSE(x, x
′)
(3)
to ensure that z retains the essential spatial and semantic information of x. Through this training strategy, the encoder
learns a compressed feature representation that is compact enough to match quantum hardware constraints while retaining
the structural semantics needed for classification.
3.2. FPQE structure
Once the encoder-decoder has converged, we discard the decoder and freeze the encoder weights, which is shown in 1(b),
forming the FPQE:
z = EF P QE(x) ∈Rc×h×w
(4)
FPQE maps the original high-dimensional image to a multi-channel and low-dimensional tensor that is directly compatible
with amplitude encoding. Because the encoder was trained with structural fidelity constraints, the resulting representation
maintains global shape, edges, and textural information that traditional classical reduction methods fail to preserve.
The output tensor is flattened and normalized:
v = flatten(z), ψ =
v
∥v∥2
, ψ ∈Rc×(h×w)
(5)
where ψ becomes the amplitude vector of the quantum state. This stage ensures that quantum circuits operate on structurally
meaningful, fidelity-preserved data instead of heavily distorted encodings.
4

3.3. FPQE based Quantum neural network
We construct a quantum neural network that utilizes only quantum parameters. The overall framework is illustrated in Fig.
1(c,d), where the input is processed using FPQE. Note that the circle in 1(c) represents a parametrized quantum circuit, as
shown in Fig. 1(d). For classification tasks, the quantum network is generally structured with multiple layers; the mea-
surement outcomes from a preceding layer serve as inputs to the subsequent layer, and the final measured output is used as
the basis for classification decisions and for constructing the loss function. The designed quantum neural network utilizes a
small number of qubits while encompassing all trainable parameters of the entire network, thereby realizing a neural network
model that is fully parameterized by quantum parameters. The process of obtaining the classification result from the previ-
ously obtained ψ is as follows.
Quantum state mapping: The Quantum state mapping is the amplitude encoding in 1(d). For each channel ψk ∈R(h×w)
of the latent tensor is normalized and encoded into quantum state |ψk⟩using amplitude encoding:
|ψk⟩=
h∗w
X
i=1
ψk,i |i⟩.
(6)
Then the encoded input can be represented as |ψ⟩= {|ψ1⟩, |ψ2⟩, . . . , |ψc⟩}. Note that the encoded |ψ⟩uses only log(w ×h)
qubits, which is logarithmic degree of ψk. Parameterized quantum circuit: We define the parameterized quantum circuit
in Fig. 1(d) as UΘ,k, which can process the encoded quantum state |ψk⟩to:
|ϕk⟩= UΘ,k |ψk⟩.
(7)
The parameterized result φk = ⟨ψk∥Z∥ψk⟩is measured using Pauli Z measurement. Then the result grained after the first
layer is:
φ = {φ1, φ2, . . . , φc} ∈Rc.
(8)
Repeat and training:
By repeating the quantum network (including quantum state mapping and parameterized quantum
circuit) for fixed layer L, the output of QNN y′ is obtained for classification using CrossEntropy. The overall process of
FPQE based QNN is subscribed in Algorithm 1.
4. Experiments
4.1. Steup
We evaluate FPQE on three standard visual benchmarks: MNIST, FashionMNIST, and Cifar-10, each reduced to a binary
classification task. The encoder-decoder is implemented with three convolutional blocks (kernel size 3, stride 2) followed by
ReLU activations and batch normalization, producing a latent representation of size , where (h,w,c) is adjusted per experiment.
The decoder mirrors this structure using transposed convolutions. Training is performed using the Adam optimizer with a
learning rate of for 100 epochs. After training, the encoder is frozen, and its output channels are mapped into quantum states
via amplitude encoding.
4.2. Encoding and Preprocessing Methods
We conducted a comparative experiment of FPQE against various encoding methods, including angle encoding, amplitude
encoding, PCA, SQE, and AQT. The configurations for each encoding method are shown in Tab. 1.
Table 1. The configurations for different encoding method.
Qubits
z.shape
pruning
Angle
9
(3,3)
-
Amplitude
8
(16,16)
-
PCA
9
(9)
-
SQE
9
(3,9)
-
AQT
9
(16,16)
!
FPQE
6
(64,64)
-
5

Algorithm 1 FPQE based QNN
Require: Input data x, label y, encoder Eθ, decoder Dη, parameterized quantum circuit UΘ, QNN layer L.
Ensure: x ∈RC×H×W
1: Step 1: Encoder-Decoder
2: z = Eθ(x)
3: x′ = Dη(z)
4: Lrec = MSE(x, x
′)
5: train Eθ and Dη using Lrec
6: Step 2: FPQE
7: Freezing the parameters θ of Eθ
8: EF P QE ←Eθ
9: z = EF P QE(x)
10: v = flatten(z), ψ =
v
∥v∥2
11: Step 3: QNN
12: for l in L do
13:
|ψ⟩= {|ψk⟩= P ψk,i |i⟩for k in range(len(ψ))}
14:
|ϕ⟩= {UΘ,k |ψk⟩for k in range(len(|ψ⟩))}
15:
φ = ⟨ψ∥Z∥ψ⟩
16: end for
17: y′ ←φ
18: LQNN = CrossEntropy(y′, y)
19: train UΘ using LQNN
20: Output: Return argmax(y′, dim=1) as the classification results.
4.3. Comparison Results
Tab.2 presents the binary classification accuracy of different encoding methods across MNIST, FashionMNIST, and Cifar-
10 datasets. For each dataset, we compared the performance of FPQE against several baseline methods, including Angle
Encoding, Amplitude Encoding, PCA, SQE, and ATP. Across all pairwise binary classification tasks, FPQE consistently
Table 2. The binary classification accuracy (%) of different encoding methods.
MNIST
FashionMNIST
Cifar-10
(0,1)
(0,3)
(2,4)
(5,6)
(2,8)
(0,1)
(2,8)
(3,9)
(7,9)
(0,1)
Angle
96.0
89.0
85.0
86.0
81.0
88.5
86.0
94.0
82.0
70.0
Amplitude
95.5
88.5
84.0
85.5
79.5
88.0
84.5
87.0
78.0
68.5
PCA
99.0
88.0
84.5
85.0
86.0
88.5
86.0
93.0
79.0
68.0
SQE
88.0
86.0
82.0
83.5
78.5
86.0
83.0
81.0
77.0
66.0
ATP
99.0
91.0
86.0
87.0
83.0
91.5
86.0
94.0
83.0
74.2
Ours
99.8
99.6
98.8
98.4
98.7
98.2
97.4
99.8
95.0
84.4
outperforms existing encoding strategies, with particularly large gains on more challenging dataset pairs and on the Cifar-
10 benchmark. On MNIST and FashionMNIST, most baselines achieve reasonable performance on simpler digit or texture
distinctions, yet their accuracy begins to decline noticeably on pairs requiring fine-grained structural discrimination. In
contrast, FPQE maintains uniformly high performance across all pair combinations, suggesting that the fidelity-preserving
representations retain the subtle variations necessary for reliable quantum decision boundaries.
The advantage of FPQE becomes even more pronounced on Cifar-10, where the visual complexity and texture diversity
place much higher demands on the encoding stage. While traditional methods exhibit a substantial drop in accuracy, FPQE
continues to achieve strong and stable performance. This indicates that FPQE’s ability to preserve spatial organization and
local semantics directly translates into enhanced separability of the corresponding quantum states, enabling the QNN to
distinguish between visually complex categories that challenge amplitude, angle, PCA, and SQE methods.
6

0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
0
100
1
2
3
4
5
6
7
8
9
70
train set
85
MNIST
FashionMNIST
Cifar-10
           (%)
test set
test set
test set
train set
train set
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
0
100
1
2
3
4
5
6
7
8
9
70
train set
85
MNIST
FashionMNIST
Cifar-10
           (%)
test set
test set
test set
train set
train set
Figure 2. Visual results.
Overall, the results demonstrate that fidelity preservation is crucial to effective quantum learning, and that FPQE provides a
robust, scalable strategy for bridging high-dimensional visual data with the constraints of NISQ era quantum models. FPQE’s
consistent margins across multiple datasets and label pairs highlight its generality and its ability to provide structurally
meaningful quantum inputs, particularly where baseline encodings struggle most.
4.4. performance Results
In this subsection, we present a detailed analysis of the binary classification performance of FPQE across all labels in the
MNIST, FashionMNIST, and Cifar-10 datasets. The results, presented in Fig. 2.
The full pairwise classification results reveal several important characteristics of FPQE. On MNIST and FashionMNIST,
FPQE achieves consistently strong performance across nearly all label pairs. This stability indicates that FPQE preserves the
essential structural cues, such as stroke continuity, local shapes, and garment contours, required for distinguishing between
simple or moderately complex visual categories. These datasets contain relatively clean and well separated classes, and
FPQE’s fidelity-preserving representation allows the QNN to exploit these distinctions with minimal degradation, even under
limited qubit budgets.
However, for pairs where different categories share similar textures or local appearance patterns, the classification perfor-
mance drops compared to the datasets easier pairs. These challenging cases reflect limitations not only of FPQE, but also of
the quantum classifier’s capacity to resolve subtle semantic differences when operating on compressed representations.
4.5. Fidelity
Fidelity analyses High fidelity data encoding is essential for enabling QNNs to capture the intrinsic correlations of classical
data once mapped into quantum Hilbert space. Information loss during dimensionality reduction or quantum state preparation
typically leads to degraded learning efficiency and reduced representational power. To assess the fidelity-preserving capability
of our proposed framework, we conducted both quantitative and qualitative analyses comparing FPQE with conventional
dimensionality reduction methods.
Our evaluation employs the decoded output x′ for computing indicator like MSE, PSNR and SSIM, primarily because
the latent representations z produced by different encoding methods are inherently incomparable, making a standardized
assessment intractable.
Table 3 compares the reconstruction fidelity of different encoding schemes using MSE, PSNR, and SSIM across three
datasets. While MSE and PSNR reflect pixel level differences, SSIM captures structural similarity, which is far more critical
for quantum learning because structural degradation leads to highly overlapping quantum states after amplitude encoding.
Across MNIST and FashionMNIST, FPQE achieves substantial improvements over all baselines, but the difference be-
comes most evident on Cifar-10. Interestingly, although the MSE and PSNR of baseline encoders do not degrade significantly
on Cifar-10, their SSIM values drop sharply (e.g., Angle: 0.19, Amplitude: 0.63, PCA: 0.27). This reveals a key observation:
traditional encoders can reconstruct images with similar pixel intensities, but they fail to preserve local structures as data
complexity increases. In other words, the reconstructions “look similar” in terms of raw values but lose important edges,
textures, and semantic regions—information crucial for forming separable quantum states.
7

Table 3. The fidelity of different encoding methods.
Qubits
MNIST
FashionMNIST
Cifar-10
MSE
PSNR
SSIM
MSE
PSNR
SSIM
MSE
PSNR
SSIM
Angle
6
0.107
9.66
0.26
0.098
10.07
0.22
0.073
11.32
0.19
9
0.093
10.29
0.31
0.078
11.03
0.26
0.067
11.73
0.19
Amplitude
6
0.034
14.62
0.61
0.029
15.24
0.54
0.021
16.6
0.37
8
0.010
19.65
0.88
0.011
19.24
0.79
0.008
20.46
0.63
PCA
6
0.022
16.53
0.31
0.022
16.53
0.31
0.026
15.76
0.27
9
0.022
16.53
0.31
0.022
16.53
0.31
0.022
16.53
0.31
SQE
6
0.095
10.21
0.25
0.092
10.36
0.21
0.068
11.65
0.19
9
0.093
10.29
0.31
0.078
11.03
0.26
0.067
11.72
0.19
ATP
-
-
-
-
-
-
-
-
-
Ours
6
0.004
23.23
0.96
0.020
16.92
0.78
0.002
25.27
0.85
MNIST
Cifar-10
-
Origin Images
Angle Encoding
Amplitude Encoding
 
PCA
SQE
FashionMNIST
FPQE
Decoded Images
MNIST
Cifar-10
-
Origin Images
Angle Encoding
Amplitude Encoding
 
PCA
SQE
FashionMNIST
FPQE
Decoded Images
Figure 3. Visualize of fidelity
FPQE maintains both low MSE and high structural fidelity across all datasets with only 6 qubits. FPQE achieves 0.002
MSE, 25.27 dB PSNR, and 0.85 SSIM on Cifar-10, outperforming amplitude encoding by a large margin. The ability
to retain high SSIM under tight qubit constraints demonstrates that FPQE preserves spatial relationships and fine grained
textures rather than merely replicating average pixel values.
Visual Fidelity: Fig. 3 compares reconstructed samples for MNIST and FashionMNIST. FPQE preserves contour sharp-
ness and intra class texture details, while PCA and pooling exhibit feature loss due to linear or local averaging operations.
The visual results align with fidelity metrics, validating FPQE’s near lossless property.
5. Discussion and Conclusion
5.1. Discussion and Insights
Our study highlights the critical role of fidelity preservation in classical to quantum data encoding. While prior work has
focused primarily on reducing input dimensionality to fit NISQ hardware constraints, our findings demonstrate that structure
8

preserving compression is far more important than dimensionality alone for downstream quantum learning performance.
Experiments show that even when baselines achieve comparable MSE or PSNR, their severe SSIM degradation especially
on complex datasets like CIFAR-10, leads to highly overlapping quantum states after amplitude encoding. This collapse in
structural fidelity directly weakens the discriminative capacity of quantum neural networks.
FPQE addresses this issue by learning a compressed representation that maintains global layout, edge information, and
textural patterns. As a result, the encoded vectors produce quantum states that remain more distinguishable in Hilbert space,
enabling QNNs to leverage their expressive advantage. The growing performance gap between FPQE and classical encoders
as data complexity increases further suggests that quantum models benefit disproportionately from structurally rich inputs,
more so than from pixel accurate but structurally degraded features.
Another important observation is that FPQE enables effective quantum learning with fewer qubits. By mapping images to
multi-channel low-dimensional tensors that still encode spatial structure, FPQE bypasses the need for extremely high qubit
counts typically required for image level amplitude encoding. This hardware efficiency makes FPQE a practical choice for
near term quantum devices and a foundation for scaling quantum representation learning in future high capacity quantum
architectures.
5.2. Limitations and Future Work
Although FPQE achieves strong fidelity preservation and improved quantum classification performance, several limitations
remain. First, our experiments focus solely on binary image classification, and FPQE has not yet been validated on more
complex tasks such as multiclass recognition or structured prediction, where the benefits of structural fidelity may manifest
differently. Second, the framework currently relies on convolutional priors tailored to visual data, limiting its applicability
to domains such as natural language or graph structured information, which would require alternative encoders capable of
capturing non-spatial structure. Third, FPQE is evaluated only in discriminative settings and has not been explored in quantum
generative modeling, despite its potential as a stable latent representation for quantum VAEs or diffusion models. Finally, all
evaluations are conducted on simulators, although FPQE uses relatively few qubits and should therefore be resilient to typical
NISQ noise, real hardware may still introduce decoherence and amplitude loading errors that affect fidelity preservation.
Future studies are needed to quantify these effects and adapt FPQE for practical deployment.
Future work will explore three main directions:
1. Expanding Beyond Classification. We plan to extend FPQE to multiclass recognition, segmentation, and visual reason-
ing, examining whether fidelity preservation continues to benefit more complex decision boundaries.
2. Toward Quantum Generative Models. FPQE’s structurally stable latent space provides a natural foundation for quantum
generative pipelines. Future exploration includes quantum VAEs, quantum GANs, and quantum diffusion models.
3. Distributed Quantum Execution. As modular quantum architectures evolve, FPQE can be mapped onto distributed
quantum chips, enabling larger quantum encodings and deeper QNNs. Such architectures could support coherent, mea-
surement free execution, preserving quantum state continuity across the entire pipeline.
5.3. Conclusion
In this work, we introduced FPQE, a fidelity-preserving encoding framework designed to bridge the gap between high-
dimensional visual data and the limited representational capacity of NISQ quantum hardware. Unlike conventional classical
to quantum encodings that prioritize dimensionality reduction at the cost of structural distortion, FPQE explicitly learns
to preserve both global semantics and local textures through a convolutional encoder-decoder. By delivering compact yet
structurally faithful representations, FPQE generates quantum states with higher separability, enabling downstream QNNs to
exploit their expressiveness more effectively.
Extensive experiments across MNIST, FashionMNIST, and CIFAR-10 demonstrate that FPQE consistently achieves su-
perior reconstruction fidelity and improved quantum classification performance. Notably, FPQE’s advantage becomes more
pronounced as data complexity increases, showing that structural fidelity is crucial for generalizable quantum learning. Our
analysis further reveals that traditional encodings maintain pixel level similarity but experience sharp declines in structural
metrics such as SSIM, explaining their degraded performance on challenging datasets.
FPQE provides a scalable, hardware feasible pathway for preparing quantum ready visual representations and highlights
the importance of fidelity driven design in future quantum machine learning pipelines. We believe this direction opens new
opportunities for integrating classical representation learning with quantum information processing and sets a foundation for
robust quantum vision models as quantum hardware continues to advance.
9

References
[1] Amira Abbas, David Sutter, Christa Zoufal, Aurelien Lucchi, Alessio Figalli, and Stefan Woerner. The power of quantum neural
networks. Nature Computational Science, 1(6):403–409, 2021. 3
[2] Mohamed Afane, Gabrielle Ebbrecht, Ying Wang, Juntao Chen, and Junaid Farooq. Atp: Adaptive threshold pruning for efficient
data encoding in quantum neural networks. In Proceedings of the Computer Vision and Pattern Recognition Conference, pages
20427–20436, 2025. 1, 2
[3] S Balasubramani, PN Renjith, L Kavisankar, Rajkumar Rajavel, Muthukumaran Malarvel, and Achyut Shankar. A quantum-enhanced
artificial neural network model for efficient medical image compression. IEEE Access, 2025. 2
[4] Marcello Benedetti, Erika Lloyd, Stefan Sack, and Mattia Fiorentini. Parameterized quantum circuits as machine learning models.
Quantum Science and Technology, 4(4):043001, 2019. 2, 3
[5] Michael Broughton, Guillaume Verdon, Trevor McCourt, Adriana Martinez, John Yoo, Sergei V Isakov, Patrick Massey, Mur-
phy Yuezhen Niu, Ramin Halavati, Evan Peters, et al. Tensorflow quantum: A software framework for quantum machine learning.
arXiv preprint arXiv:2003.02989, 2020. 3
[6] Jiaqi Chen, Qiming Li, Zhaohui Wei, and Gui-Lu Long. Hybrid quantum-classical autoencoder for efficient quantum state recon-
struction. Physical Review A, 103(4):042418, 2021. 3
[7] Anh-Dzung Doan, Michele Sasdelli, David Suter, and Tat-Jun Chin. A hybrid quantum-classical algorithm for robust fitting. In
Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 417–427, 2022. 3
[8] Philip Easom-McCaldin, Ahmed Bouridane, Ammar Belatreche, Richard Jiang, and Somaya Al-Maadeed. Efficient quantum image
classification using single qubit encoding. IEEE Transactions on Neural Networks and Learning Systems, 35(2):1472–1486, 2022.
1, 2
[9] Edward Farhi and Aram W Harrow. Quantum supremacy through the quantum approximate optimization algorithm. arXiv preprint
arXiv:1602.07674, 2016. 1
[10] Javier Gonzalez-Conde, Thomas W Watts, Pablo Rodriguez-Grasa, and Mikel Sanz. Efficient quantum amplitude encoding of poly-
nomial functions. Quantum, 8:1297, 2024. 1
[11] Lov K Grover. A fast quantum mechanical algorithm for database search. In Proceedings of the Twenty-eighth Annual ACM Sympo-
sium on Theory of Computing, pages 212–219, 1996. 1
[12] Vojtech Havl´ıˇcek, Antonio D. C´orcoles, Kristan Temme, et al. Supervised learning with quantum-enhanced feature spaces. Nature,
567(7747):209–212, 2019. 3
[13] Chang-Jiang Huang, Hailan Ma, Qi Yin, Jun-Feng Tang, Daoyi Dong, Chunlin Chen, Guo-Yong Xiang, Chuan-Feng Li, and Guang-
Can Guo. Realization of a quantum autoencoder for lossless compression of quantum data. Physical Review A, 102(3):032412, 2020.
1
[14] Peter Kaufmann, Timm F Gloger, Delia Kaufmann, Michael Johanning, and Christof Wunderlich. High-fidelity preservation of
quantum information during trapped-ion transport. Physical review letters, 120(1):010501, 2018. 2
[15] Jian Liao, Fei Zhou, Xinyu Ma, and Xiaodong Hu.
Quantum autoencoders and their applications in quantum communication.
Quantum Information Processing, 21(7):252, 2022. 3
[16] Kai Liu and Deguang Han.
Fidelity preserving and decoherence for mixed unitary quantum channels.
arXiv preprint
arXiv:2410.20117, 2024. 2
[17] Seth Lloyd, Masoud Mohseni, and Patrick Rebentrost. Quantum principal component analysis. Nature physics, 10(9):631–633, 2014.
1, 2
[18] Kosuke Mitarai, Makoto Negoro, Masahiro Kitagawa, and Keisuke Fujii. Quantum circuit learning. Physical Review A, 98(3):
032309, 2018. 3
[19] Emmanuel Ovalle-Magallanes, Dora E Alvarado-Carrillo, Juan Gabriel Avina-Cervantes, Ivan Cruz-Aceves, and Jose Ruiz-Pinales.
Quantum angle encoding with learnable rotation applied to quantum–classical convolutional neural networks. Applied Soft Comput-
ing, 141:110307, 2023. 1
[20] Vittorio Pagni, Sigurd Huber, Michael Epping, and Michael Felderer. Fast quantum amplitude encoding of typical classical data.
arXiv preprint arXiv:2503.17113, 2025. 1
[21] Adrian Perez-Salinas, Alba Cervera-Lierta, Enrique Gil-Fuster, and Jose I Latorre. Training variational quantum circuits with low-
depth data re-uploading. Quantum, 5:464, 2021. 3
[22] Prathyush Prasanth Poduval, Zhuowen Zou, and Mohsen Imani. Hdqmf: Holographic feature decomposition using quantum al-
gorithms. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10978–10987, 2024.
3
[23] John Preskill. Quantum computing in the nisq era and beyond. Quantum, 2:79, 2018. 2
[24] Minati Rath and Hema Date. Quantum data encoding: A comparative analysis of classical-to-quantum mapping techniques and their
impact on machine learning accuracy. EPJ Quantum Technology, 11(1):72, 2024. 2
[25] Maria Schuld and Nathan Killoran. Quantum embeddings for machine learning. Physical Review A, 100(1):012345, 2019. 3
10

[26] Maria Schuld, Ilya Sinayskiy, and Francesco Petruccione. An introduction to quantum machine learning. Contemporary Physics, 56
(2):172–185, 2015. 3
[27] Maria Schuld, Alex Bocharov, Krysta Svore, and Nathan Wiebe. Circuit-centric quantum classifiers. Physical Review A, 101(3):
032308, 2020. 2
[28] Maria Schuld, Ryan Sweke, and Johannes Jakob Meyer. Effect of data encoding on the expressive power of variational quantum-
machine-learning models. Physical Review A, 103(3):032430, 2021. 2
[29] Peter W Shor. Algorithms for quantum computation: discrete logarithms and factoring. In Proceedings 35th Annual Symposium on
Foundations of Computer Science, pages 124–134, 1994. 1
[30] Sukin Sim, Jacob A Johnson, and Al´an Aspuru-Guzik. Expressibility and entangling capability of parameterized quantum circuits
for hybrid quantum-classical algorithms. Advanced Quantum Technologies, 2(12):1900070, 2019. 3
[31] Manuela Weigold, Johanna Barzen, Frank Leymann, and Marie Salm. Data encoding patterns for quantum computing. In Proceedings
of the 27th conference on pattern languages of programs, pages 1–11, 2020. 2
[32] Hao Xiong, Yehui Tang, Xinyu Ye, and Junchi Yan. Circuit design and efficient simulation of quantum inner product and empirical
studies of its effect on near-term hybrid quantum-classic machine learning. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pages 26162–26170, 2024. 1
[33] Yuan-Fu Yang and Min Sun. Semiconductor defect detection by hybrid classical-quantum deep learning. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2323–2332, 2022. 3
[34] Leo Zhou, Sheng Tao Wang, Soonwon Choi, Hannes Pichler, and Mikhail D Lukin. Quantum approximate optimization algorithm:
Performance, mechanism, and implementation on near-term devices. Physical Review X, 10(2):021067, 2020. 1
11
