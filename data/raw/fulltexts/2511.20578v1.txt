A User-customized and Untethered Electro-haptic
Device for Immersive Human-Machine Interaction
Ziang Cui*
ShanghaiTech University
Shanghai, China
cuiza2022@shanghaitech.edu.cn
Shanyong Wang*
ShanghaiTech University
Shanghai, China
wangshy2022@shanghaitech.edu.cn
Yining Zhao*
ShanghaiTech University
Shanghai, China
zhaoyn5@shanghaitech.edu.cn
Yiran Wang
Columbia University
New York, NY, USA
yw4397@columbia.edu
Xingming Wen
ShanghaiTech University
Shanghai, China
wenxm2024@shanghaitech.edu.cn
Siyuan Chen
ShanghaiTech University
Shanghai, China
chensy2023@shanghaitech.edu.cn
Ze Xiong†
ShanghaiTech University
Shanghai, China
xiongze@shanghaitech.edu.cn
Abstract—Haptic feedback is essential for human–machine
interaction, as it bridges physical and digital experiences and en-
ables immersive engagement with virtual environments. However,
current haptic devices are frequently tethered, lack portability
and flexibility. They also have limited ability to deliver fine-
grained, multi-dimensional feedback. To address these challenges,
we present a flexible, ultra-thin, and user-customized electro-
haptic device fabricated with soft materials and printable liquid
metal ink. Its highly integrated and lightweight design minimizes
interference with natural hand movements while maintaining
reliable skin contact. By delivering finely controlled electrical
stimulation through 15 electrodes, it can evoke a wide range
of tactile sensations that cover diverse interaction scenarios.
Our user study demonstrates that the device is comfortable to
wear and capable of generating tunable, precise electro-haptic
feedback, thereby significantly enhancing immersion and realism
in human-machine interactions.
Keywords—Electro-haptics, Wearable Devices, Flexible Elec-
tronics, Virtual Reality
I. INTRODUCTION
Human–computer interface technologies shape how people
perceive, act, and stay present in digital world. A central
goal of human-computer interaction is to craft truly immersive
experiences that integrate not only interactive visuals and
audio [1], but also the sense of touch [2]. Haptic feedback
can restore contact [3], weight [4], and texture [5] cues that
audio–visual channels alone cannot convey. In virtual and
augmented reality (VR/AR), haptic feedback are critical for
immersion and realistic human computer interaction, enabling
users to control objects, infer material properties, and time
their movements with greater precision [6, 7, 8].
Despite rapid progress, there are two key challenges of
current haptic interfaces for immersive interaction. 1) Existing
human–machine interaction interfaces are often tethered,
lack portability and flexibility. Many systems rely on rigid,
bulky, or conspicuous hardware (e.g., glove exoskeletons or
hand-held controllers). Such designs lack portability, limit
*Equal contribution. Each of them can claim to rank first.
†Corresponding author.
Fig. 1: Schematic diagram illustrating the structure of our
electro-haptic device. Simply by capturing an image of the
user’s hand, an appropriately sized model can be generated
and used for device fabrication. Soft materials and printable
liquid metal ink are used for flexible design. When interacting
with objects in the VR environment, even though users are
not physically holding anything in the real world, the electro-
haptic device provides them with a realistic haptic sensation,
as if they were holding actual objects in their hands.
natural hand movements, and attract unnecessary visual atten-
tion [9]. In addition, one-size-fits-all designs further ignore
substantial variability in hand morphology, skin properties,
and user preferences, resulting in poor fit, unstable contact,
and inconsistent sensations across users and sessions [10]. 2)
Current human machine interaction interface show lim-
itations in delivering fine-grained and multi-dimensional
feedback. Much of today’s hand-worn haptic systems typically
offer low spatial resolution and only a narrow dimension
of sensations. Feedback is commonly uniform across broad
skin regions(e.g., the whole palm or all fingers) and confined
arXiv:2511.20578v1  [cs.HC]  25 Nov 2025

to a single perceptual dimension (e.g., simple vibrotactile
intensity), constraining designers who wish to tailor cues to
diverse interaction scenarios [11, 12].
We argue that improving immersion and usability in VR/AR
demands interfaces that are flexible and untethered in use
while still delivering expressive feedback. To this end, we pro-
pose a hand-worn interface that integrates flexibility, portabil-
ity, and spatially targeted, multi-dimensional haptic feedback.
Electro-haptic is well suited to this aim, unlike mechanically
actuated device rely on pressure or moving parts, electro-
haptic stimulation directly excites cutaneous afferents through
the skin, enabling thin, silent, and lightweight implementa-
tions [13, 14, 15]. Electro-haptics also integrates naturally with
our personalization pipeline, a programmable and printable
fabrication process that enables per-user customization at a
low cost of only ∼70 USD. However, conventional electrode
layouts and packaging constrain wearability and customiza-
tion [16], while existing control strategies often underutilize
the rich perceptual space afforded by waveform parame-
ters [13]. So in our electro-haptic device, we address these
problems by employing flexible substrates with liquid metal
as conductors to realize conformal and stretchable electrodes
that maximize wearing comfort while maintaining stable skin
contact. We further combine precise waveform modulation
with a palm-wide, independently addressable electrode array
to deliver spatially precise cues spanning complementary per-
ceptual dimensions.
This work introduces a highly integrated, flexible, ultra-
thin, and user-customized electro-haptic device for immersive
human–machine interaction. Our approach combines a set of
materials, fabrication, personalization pipelines, and system
integration schemes:
• User-customized and programmable fabrication. Start-
ing from a single photograph of a user’s hand, our
computational pipeline estimates key anatomical land-
marks and skin regions, then generates a printable elec-
trode pattern that fits the individual’s palm. This fully
programmable and rapid process enables low-cost, per-
user devices without bespoke manual fitting. We employ
stretchable, flexible substrates with printed liquid-metal
traces to produce conformal, ultra-thin device that match
the hand’s complex geometry.
• Fine-grained and multi-dimensional electro-haptics.
Through waveform modulation, we synthesize a richer
haptic vocabulary: frequency modulates temporal texture
(e.g., from rough/buzzy to smooth/continuous), while
duty cycle adjusts perceived contact force. Coupled with
spatially targeted stimulation, our system delivers multi-
dimensional cues aligned with diverse interaction scenar-
ios. We further demonstrate that our electro-haptic device
could enhances task performance in VR and can serve as
a effective tool for haptic augmentation.
II. RELATED WORK
A. Wearable Haptic Devices
The pursuit of realistic haptic feedback in virtual and
augmented reality has led to the development of various hand-
worn devices, one common form of which is the haptic glove.
These systems aim to improve haptic perception of users by
delivering various forms of stimulation to the hand, thereby
significantly improving immersive experience. Based on their
fundamental structure and the types of feedback they provide,
these gloves can be broadly categorized into several types.
Vibrotactile gloves represent the most common and com-
mercially prevalent form. They typically integrate eccentric ro-
tating mass (ERM) motors or linear resonant actuators (LRA)
into the glove design [17, 18, 19, 20, 21, 22, 23]. These actua-
tors generate high-frequency oscillations to produce a buzzing
or tapping sensation. This approach is advantageous because
the technology is mature, low-cost and power-efficient, which
are key attributes that make it ideal for consumer appli-
cations. However, vibrations are not very expressive. They
cannot convey fine details about an object’s shape, texture,
or softness because they tend to spread over a large area
of the skin rather than targeting specific points precisely.
Mechanical structures and manufacturing challenges also limit
the density of actuators that can be integrated [19, 20]. Recent
advances in materials, structures, and fabrication techniques,
have enabled the development of smaller and more efficient
electromagnetic actuators that can form high-density arrays for
precise stimulation [24, 25].
To overcome the limitations of vibrotactile feedback, re-
searchers have developed kinesthetic feedback gloves. These
devices simulate force and resistance through mechanical
structures, primarily in two forms: tendon-driven and ex-
oskeleton systems. Tendon-driven systems use cable or similar
structures to carry force, offering a lightweight and flexible
design [26, 27]. Exoskeleton systems use rigid links to apply
torque directly, enabling more accurate force control [28, 29].
While these systems can effectively mimic the weight and
solid presence of objects, their complex mechanics often
make them bulky, expensive and restrictive to natural hand
movement.
In the quest for higher-fidelity touch simulation, deformable
haptic gloves have been introduced. These devices create
tactile sensations by producing controlled physical shapes
or patterns on the skin. Pneumatic and hydraulic systems
use microfluidic channels and soft actuator arrays to achieve
localized deformation through precise pressure control [30, 31,
32, 33]. Piezoelectric systems use special materials to generate
micron-level precision in motion output [34, 35, 36]. However,
pneumatic systems require external pressure regulation units,
making them large and costly. Piezoelectric solutions, on the
other hand, are limited by their low force output and high cost.
In addition to the common approaches mentioned above,
ultrasonic tactile stimulation [37, 38, 39] is also under explo-
ration. Although it may enable richer stimulation patterns, it
usually requires array-based ultrasonic elements and relatively

complex focusing strategies, which limits its integration into
glove-based systems.
B. Electro-haptic Interfaces
Electro-haptic technology is a form of haptic feedback that
directly stimulates the nervous system. It applies controlled,
low-current electrical pulses to the skin, activating tactile nerve
endings (such as Meissner’s corpuscles and Merkel cells).
This bypasses mechanical transduction and directly create
sensations such as pressure, vibration, pricking, or tingling
in the brain [40, 41, 42]. Unlike haptic technologies that rely
on moving parts like motors or pumps, electro-haptic systems
depend on precise control of electrical parameters, including
amplitude, pulse width, frequency, and waveform [43]. By ad-
justing these parameters, various sensations can be simulated,
from light touch to sustained pressure, and from fine vibrations
to coarse textures [44, 45, 46].
In research on haptic gloves, several studies have focused
on improving feedback resolution, and integrating multiple
types of feedback. For example, Keef et al. developed a multi-
modal glove that combined electrical, vibration, and thermal
feedback to simulate properties like hardness, temperature, and
roughness. However, the system had low electrode density
and was relatively bulky [47]. Abbass et al. created a high-
density electronic skin and electrode array covering the entire
palm, offering accurate spatial mapping and low-latency feed-
back [48]. Lin and colleagues used high-frequency modulation
and current steering to achieve ultra-high-resolution electro-
haptic feedback (76 points/cm²) at low voltage, demonstrating
applications in braille displays and VR. Still, the complex
design reduced stretchability and comfort [49].
Despite progress in spatial resolution, multi-modal feed-
back, and low-voltage operation, most existing systems remain
constrained by rigid wires and substrates, lack of personalized
fit to hand anatomy, and compromises in wearability for
functionality. To address these issues, this study introduces
a customizable, stretchable, full-hand electro-haptic glove us-
ing liquid metal wiring. The system incorporates 15 stim-
ulating electrodes distributed across the palm and fingers,
with placements tailored to the user’s hand dimensions and
joint structure. This ensures broad coverage and high spatial
accuracy while maintaining compatibility with natural hand
movements due to the extreme flexibility and stability of
liquid metal. Furthermore, an ultra-thin integrated design sig-
nificantly improves comfort and natural interaction, offering
a new direction for realistic, precise, and comfortable hand-
based haptic interfaces.
C. Personalized Gloves Design
Personalized customization is increasingly recognized as a
key requirement in the design of human-centric hardware.
This trend is especially evident in wearable technologies [50],
medical devices [51], and assistive systems [52], where one-
size-fits-all solutions often fail to accommodate individual
anatomical and ergonomic differences [53, 54]. In the context
of wearable devices that rely on precise stimulation points,
even small placement errors can significantly degrade per-
formance [55, 56]. Moreover, standardized devices frequently
misalign with the user’s anatomy, leading to reduced effective-
ness and suboptimal user experience [57]. In wearable glove
design, these misalignments highlight the need for accurate
digital representations of the hand [58]. A natural response
has been the use of 3D hand modeling techniques, which
provide a parametric way to capture hand geometry and
motion [59]. Models such as MANO [60] have become widely
adopted in computer vision for tasks including hand pose
estimation [61], gesture recognition [62, 63], and interaction
modeling [64, 65]. Other efforts have utilized hand kinematics
for exoskeleton design [66] and prosthetic customization [67].
While these approaches achieve high accuracy in geometric
reconstruction, they have been primarily developed for vision
and robotics applications, with limited attention to the practical
needs of physical device fabrication. Our work addresses this
gap by adapting hand modeling techniques specifically for
personalized electro stimulation skin design, ensuring optimal
stimulation point placement tailored to individual hand char-
acteristics.
III. PERSONALIZED DESIGN ALGORITHM
We propose a novel algorithm for glove personalization that
reconstructs a 3D hand model from a single RGB image. From
just one photograph, the method produces both a 2D hand
contour for accurate glove fitting and a 3D mesh compatible
with Unity-based customization. We further evaluate its per-
formance to demonstrate effectiveness.
A. Implementation of Personalized Design Algorithm
To acquire input data, users place their right hand flat on
a surface, palm facing up, while a camera positioned about
40 centimeters above captures a square image under proper
lighting. This setup ensures a clear and unobstructed view of
the hand, which is essential for reliable processing [68]. The
captured image is then processed by our algorithm, which ex-
tracts key features and performs the subsequent steps required
for 3D reconstruction. The algorithm comprises several key
steps:
1) 2D Encoding: We first extract 2D features from the input
hand image using a lightweight stacked encoder. This design
reduces parameters while preserving essential geometric de-
tails.
2) Feature Lifting: The 2D features are lifted into 3D space
through three steps:
• Spatial Regression: Combines heatmap encoding with
position regression to improve localization accuracy and
maintain temporal consistency.
• Semantic Transformation: Converts 2D pose features
into semantically meaningful representations to describe
spatial relationships between hand parts.
• Vertex Mapping: Uses a learnable mapping matrix to
project 2D features onto 3D mesh vertices for accurate
alignment.

Fig. 2: Statistical evaluation of the personalized glove
design algorithm. Upper: Absolute errors (cm) between
predicted and ground-truth finger lengths, shown as boxplots
for the five fingers (thumb, forefinger, middle, ring, pinky).
The grey line denotes the mean error across fingers. Lower:
Relative errors (%) for each finger, further decomposed into
four anatomical segments (metacarpal, proximal phalanx, in-
termediate phalanx, distal phalanx) along with the averaged
error.
3) 3D Decoding: We apply an efficient graph operator to
reconstruct a detailed 3D hand mesh from the lifted features.
The process ensures both geometric fidelity and real-time
performance [69].
4) Model Fitting: The hand model is parameterized by a
mesh consisting of 778 vertices and 1538 faces, providing
a detailed representation of hand geometry. To improve ac-
curacy, the reconstructed mesh is refined by fitting the joint
coordinates to a reference plane and projecting the vertices
accordingly, ensuring consistent geometric alignment with the
real hand.
a) Joint Coordinate Regression: Given the 21 joint co-
ordinates (20 hand joints plus one at the palm root), denoted
as p = {p1, p2, · · · , pN}, where each pi ∈R3, we fit these
points to a plane using a least-squares regression approach.
The plane is defined by the equation: n · p + d = 0, where n
= (nx, ny, nz) is the normal vector of the plane, and d is the
distance from the origin to the plane.
b) Covariance Matrix and Eigenvalue Decomposition:
To determine the optimal plane, we compute the centroid of
the joint coordinates:
c = 1
N
N
X
i=1
pi
Next, we construct the covariance matrix C ∈R3x3 as
PN
i=1(pi −c)(pi −c)T . The normal vector n of the plane
is obtained by performing eigenvalue decomposition on C.
Specifically, n corresponds to the eigenvector associated with
the smallest eigenvalue, which minimizes the orthogonal dis-
tance from the joint points to the plane.
c) Projection of Mesh Vertices.:
Once the plane is
determined,
we
project
the
778
mesh
vertices
V
=
{v1, v2, · · · , v778} onto the plane. The projection of a vertex
vi onto the plane is given by:
v
′
i = vi −(n ∗(vi −c))n
where v
′
i is the projected vertex. This ensures that the final 3D
model is both accurate and aligned with the physical hand. By
leveraging this regression-based fitting process, we achieve a
robust alignment of the hand model with the physical hand,
ensuring that the 778 vertices are optimally projected onto the
fitted plane.
B. Performance of Personalized Design Algorithm
To quantitatively assess the precision of the proposed per-
sonalized glove design algorithm, we performed a statistical
evaluation of finger length estimation on all five fingers, as
summarized in Figure 2. We collect data from the right hands
of 10 volunteers (7 male and 3 female, aged 18-25, average age
21.70, SD=1.83), all of whom are right handed, and compare
the predicted finger lengths of our algorithm with ground-truth
measurements.
As shown in the Upper panel, the absolute error (cm)
between predicted and ground-truth finger lengths is visualized
using boxplots. The thumb exhibits the largest variability,
with a mean absolute error exceeding 1 cm in certain cases,
while the forefinger and pinky demonstrate relatively low error
values, indicating more consistent predictions. The grey line
further highlights the mean error trend across fingers, which
remains below 0.5 cm for most cases, suggesting that the al-
gorithm achieves a generally robust performance. The average
error rate between five fingers is below 2.5%. The Lower
panel provides a segment-level analysis by dividing each finger
into four anatomical regions (metacarpal, proximal phalanx,
intermediate phalanx, and distal phalanx). We observe that
intermediate phalanx consistently yields the highest relative
error, whereas metacarpal and distal phalanx show lower error
rates, highlighting the algorithm’s better capability in capturing
proximal and distal structures.
C. Application of Personalized Design Algorithm
The personalized design algorithm addresses the limitations
of traditional ”one-size-fits-all” gloves by using key hand

Fig. 3: Algorithmic pipeline for personalized device design.
From left to right: input hand image, algorithm-extracted
contour, computed stimulation sites with interconnections, and
the fabricated devices applied on the hand. Examples (a–c)
show three different users, their personal device show in three
different colors for easier recognition.
parameters—finger length and joint positions—to create a
customized glove structure and functional layout. The algo-
rithm begins by constructing a parametric hand model from
input anthropometric data. Finger length directly determines
the dimensions of the glove fingers, while the relative po-
sitions of the joints are used to algorithmically determine
the placement of functional components such as electrodes
and liquid metal conductive traces. Figure 3 demonstrates the
application of the algorithm to produce customized device.
We present three representative examples that visually convey
the pipeline—from capturing the raw hand image, to contour
generation and stimulation site mapping, and finally to the
fabricated device applied on the hand. In summary, this method
enables the simultaneous customization of glove shape and
functional element placement, providing a scalable solution for
producing truly personalized gloves that are both comfortable
and effective.
IV. MATERIAL AND HARDWARE DESIGN
To fabricate a flexible and ultra-thin electro-haptic device,
we have undertaken an optimized design from a material
perspective. The core component of our approach is a printable
flexible conductive ink. This printable design significantly
reduces the manufacturing complexity of our device and
allows for better adaptation to customized device shapes. By
combining flexible encapsulation materials and an extremely
low-cost circuit control unit, we have substantially reduced the
cost of the device, as well as its size (particularly thickness),
weight, and fabrication difficulty. In this section, we will detail
the material design, circuit design, and device implementation.
A. Design of Printable Liquid Metal Ink
In previous work, similar electrical stimulation haptic de-
vices have utilized thin metal layers [70], metal powder-
based inks [71], or polymer-based conductive coatings [72].
Although metallic materials possess certain ductility and ex-
cellent electrical conductivity, their modulus does not match
that of human skin. Polymer-based conductive coatings, lim-
ited by the principle of ionic conduction, exhibit lower con-
ductivity than metallic materials. Furthermore, their conduc-
tivity changes significantly under stretching or compression,
adversely affecting the normal function of the device. Liquid
metal is a fluid material with excellent metallic conductivity
and high safety (very low toxicity, very low vapor pressure at
room temperature) [73], making it an ideal conductive material
for wearable flexible electronic devices. Compared to other
metallic materials, liquid metal, being in a liquid state at room
temperature, exhibits extremely high stretchability and flexi-
bility [74]. Compared to polymer conductive materials, liquid
metal offers superior conductivity ( ∼3.4 × 106S/m) [75].
Moreover, the conductivity of liquid metal changes very little
under strain [76], making it more suitable for manufacturing
flexible electronic devices. However, liquid metal inherently
has very high surface tension [77], often causing it to coalesce
into droplets during processing, thereby increasing the manu-
facturing difficulty of the device [78]. Creating high-resolution
conductive patterns with liquid metal presents a challenging
task.
Fig. 4: Design of printable liquid metal conductive ink.
(a) Montmorillonite dispersion. (b) Liquid metal. (c) Printable
liquid metal-montmorillonite conductive ink.
In our work, we employed a montmorillonite dispersion to
facilitate the production of liquid metal conductive ink (as
shown in the Figure 4). 2g of montmorillonite was dispersed
in 20g of deionized water using an ultrasonic disruptor.
Subsequently, 10g of liquid metal (EGaIn) was added, and
the ultrasonic disruptor was used again to process the liquid
metal into micron-sized microspheres. Through centrifugation,
excess deionized water and a small amount of montmoril-
lonite were removed, leaving the precipitated liquid metal-
montmorillonite composite ink at the bottom. The ink was
loaded into syringes and mounted on a pneumatic printer.
By controlling the printing speed and extrusion pressure, pre-
designed patterns could be printed.

In the liquid metal-montmorillonite composite ink, the liq-
uid metal is maintained as micron-sized microspheres due to
the coating of the gallium oxide shell. However, the presence
of gallium oxide limits the conductivity of the composite
ink; patterns printed with this composite ink are initially
almost non-conductive. Heat treatment of the pattern causes
the water content in the ink to evaporate, reducing the pattern’s
thickness, and allowing the montmorillonite and liquid metal
microspheres to sediment densely. Under the sedimentation
pressure from the montmorillonite, the gallium oxide shells
on the liquid metal microspheres are compressed and rupture,
allowing the liquid metal to re-form interconnected conductive
pathways.
Through this design, we maximize the high conductivity and
fluidic properties of liquid metal, processing it into a printable
ink. We can pre-design the conductive pathways within the
device and directly print them onto a flexible substrate using
a pneumatic printer. Through a post-processing step, the ink
forms well-conducting paths on the substrate.
B. Design of Electrode Material
In similar works done before, metal electrodes were widely
used for sensing and stimulation on the skin surface [79].
Limited by the ductility and flexibility of metallic materials,
metal electrodes often do not contact sufficiently with the
skin, necessitating the application of conductive gel between
the electrode and the skin to ensure good electrical contact.
However, the effectiveness of the conductive gel deteriorates
rapidly after short-term use [80], meaning the device can-
not maintain long-term stability. Additionally, the application
of conductive gel increases the difficulty of wearing the
device [81]. Designing a stable, long-lasting, flexible, and
conformable electrode was a significant challenge we faced.
Considering that the device encapsulation material uses
silicone rubber (Smooth-On, Ecoflex 00-30), we selected a
composite material consisting of conductive fillers and silicone
rubber for the electrode. The silicone rubber serves as the
flexible outer encapsulation matrix. The conductive materials
were a combination of liquid metal and carbon nanotubes. 2g
of liquid metal, 1g of carbon nanotubes, and 10g of Ecoflex
00-30 Part A were added together and mixed using a planetary
mixer. Subsequently, 10g of Ecoflex 00-30 Part B was added,
and the mixture was homogenized again using the planetary
mixer. The well-mixed slurry was cast into a film and cured at
room temperature for 4 hours. After curing, it can be cut into
the required electrode shapes using a UV laser (LPKF U4) for
subsequent use.
C. Wrist-worn Electro-haptic Stimulator
The wrist-worn electro-haptic stimulator adopts a mini-
malist design to minimize the manufacturing cost, volume,
and weight of the control circuit as much as possible. It
can perform boost conversion and deliver current output to
15 electrodes. Crucially, it allows for control of the current
magnitude, thereby ensuring the safety of the electro-haptic
feedback.
Fig. 5: The wrist-worn electro-haptic stimulator. (a) Our
wrist-worn electro-haptic stimulator. (b) Schematics of our
custom electro-haptic stimulator.
1) Circuit Design: The complete dimensions of our hard-
ware circuit are 30mm × 60mm × 18mm, with a weight of
only 29g. As shown in the Figure 5, we use a 3.7V lithium
polymer battery to power the entire system. Through a boost
regulator (PW5100, PWChip), the 3.7V input voltage is raised
to 5V. The 5V voltage supplies the next stage DC-DC boost
converter (LT8365, Analog Devices) and the microcontroller
(ESP32-PICO-DevKitM-2, Espressif Systems). After voltage
conversion, the 5V voltage is boosted to 90V to generate suffi-
cient current for haptic perception. The microcontroller utilizes
an onboard LDO chip to convert the 5V supply to the 3.3V
required by the SoC chip. The microcontroller incorporates
a Bluetooth module for wireless communication. The 90V
high voltage is supplied to a MUX chip (TMUX9616, Texas
Instruments). Under the logical control of the microcontroller,
the 15 channels are selectively turned on to generate electrical
stimulation haptic sensations on the hand. The current from the
hand returns to the circuit through a virtual ground (VGND)
electrode. The current passing through the hand is controlled
by a constant current source circuit composed of an operational
amplifier (LMV358) and a BJT transistor (MMBT5551).
2) Generation of Electrical Stimulation Pulses: When our
microcontroller receives serial information from the host com-
puter via the Bluetooth module, it processes the information
and transmits it to the MUX to control the turning on and
off of the 15 channels. Through logical control input from
the microcontroller, the period and duty cycle of each pulse
signal can be precisely controlled, enabling us to achieve
more nuanced haptic feedback. Due to the excellent switching
performance of the MUX, each channel can switch states
within 1.5 microseconds, allowing us to design different pulse
patterns well within the temporal recognition threshold of
haptics. In our design, only one channel is active at any given
time, while the others remain off during this period. This
ensures better control over the haptic intensity and prevents
interference between multiple channels.
3) Safety Assurance: To ensure the safe operation of the
system, we use a constant current source circuit to control
the magnitude of the current flowing through the hand. The
microcontroller’s built-in DAC outputs a control voltage to the
non-inverting input of the operational amplifier. The output of
the operational amplifier is connected to the base of the BJT.

Fig. 6: Fabrication of our electro-haptic device. (a) An acrylic plate is prepared as a rigid substrate, and a thin PET sheet is
attached as the flexible base layer. (b) The predefined electrode positions are marked on the surface using a UV laser. (c) Sixteen
electrodes are precisely positioned on the substrate. (d) Protective PET discs are placed over each electrode. (e) A silicone layer
is applied to encapsulate the electrodes while aligning the FPCB ribbon cable. (f) Conductive liquid metal–montmorillonite
(LMM) ink is dispensed through a pneumatic nozzle. (g) The entire device is encapsulated. (h) The device is detached from
the substrate and flipped over, with the electrode side facing upward. (i) Silicone adhesive is applied to bond the device to the
skin. (j) Finally, the device is cut into a hand-shaped form using a UV laser.
The inverting input of the operational amplifier is connected
to the emitter of the BJT, and the collector of the BJT is
connected to the VGND electrode on the hand. A variable
resistor is connected between the emitter and ground for
manual adjustment of the current level. When the BJT is
conducting, the voltage across the variable resistor remains
constant, and the current flowing through the resistor is limited
by its resistance value. Since the current from the hand can
only flow through this loop, the current passing through the
hand is likewise constrained to a constant value. During
experiments, we set the maximum current to 3mA to ensure
user safety.
V. IMPLEMENTATION OF HIGHLY INTEGRATED
ELECTRO-HAPTIC DEVICE
A. Sequential Device Fabrication
Based on the device morphology design algorithm men-
tioned previously, a user’s hand image must first be acquired.
The image requirements are detailed in the earlier section.
After processing by the algorithm, the joint coordinates of
the user’s hand are obtained. These coordinates are used to
determine information such as palm width, finger length, and
electrode placement, thereby enabling the customized design
of the device. Considering potential issues during fabrication,
utilizing a standardized device morphology is essential. The
hand was simplified into a combination of straight lines and
arcs, and a CAD pattern was generated based on the hand
dimension information acquired from the algorithm.
Considering the impact of hand movement on the device
positioned on the palm, electrodes were placed on the finger-
tips, the areas of the fingers near the palm, and the finger root
regions to avoid separation of the electrodes from the hand
caused by motion. Based on the joint coordinates obtained
from the algorithm, a CAD file specifying the electrode posi-
tions was generated. Considering the electrical connections on
the device, the connection interface was uniformly designed
near the base of the palm close to the wrist. Conductive trace
paths were designed according to the correspondence between

electrodes and this interface. The paths must remain within the
boundaries of the device morphology and avoid crossings to
ensure correct device functionality. The trace paths were also
generated in CAD format to facilitate subsequent printing of
the conductors.
Figure 6 shows the fabrication steps of our electro-haptic
device. A 0.1mm thick PET sheet was attached to an acrylic
plate to serve as the substrate for device fabrication, aiding
subsequent processing steps. A UV laser system was used
at low power to mark the corresponding electrode positions
on this substrate. The electrode material was prepared as
described in the previous section, and 16 electrodes were
placed at their designated positions. Pre-cut 6mm diameter
PET discs were placed on top of each electrode. Subsequently,
the Ecoflex 00-30 precursor was coated onto the substrate
to form a 0.2mm thick film by a doctor blade. While the
silicone rubber was partially cured, the PET discs on the
electrodes were removed to ensure the electrode material
remained uncovered.
The device was then carefully placed on the platform
of a pneumatic dispenser. The pre-processed liquid metal-
montmorillonite composite conductive ink was printed onto
the device according to the conductor trace pattern. After
printing, the device was placed in an oven at 70°C for 2
hours. This post-processing step activates the conductivity of
the ink and establishes effective electrical connections with the
electrodes.
Prior to applying the encapsulating layer of silicone rubber,
a flexible printed circuit board (FPCB) ribbon cable was
positioned at the interface area of the device, ensuring tight
contact with the activated conductive traces. Similar to the
previous step, the silicone rubber precursor was doctor-bladed
to form a 0.2mm thick film, completely covering the entire
electrode and trace region and encapsulating the upper end of
the FPCB ribbon cable within the device. Notably, pigments
can be added to the silicone rubber as required to meet
aesthetic preferences. The silicone rubber was cured by letting
it sit at room temperature for four hours.
To better secure the device to the user’s hand, a skin-
safe silicone adhesive (Skin Tite, Smooth-On) was selected
as the adhesive layer. The device from the previous step was
detached from the substrate and flipped over, placing it with
the electrodes facing upwards. Analogous to earlier steps, pre-
cut PET discs were placed on the electrodes, and a 0.1mm
thick layer of the adhesive was doctor-bladed onto the device
surface. The PET discs were then removed from the electrodes,
and the assembly was left to cure for 20 minutes. Finally, the
device outline was cut using a UV laser system according to
the pre-designed file. The section covered by the FPCB was
manually cut using a cutting knife.
The connection between the device and the custom drive
system is achieved via the pre-installed FPCB ribbon cable,
accommodating wrist movement. To protect the circuit system
from potential failure due to factors like skin perspiration
during use, it was encapsulated within a silicone rubber mold,
leaving only necessary electrical connection openings exposed.
Fig. 7: Optical images of our electro-haptic device. (a, b)
Fabricated device from the front and back sides. (c, d) Side
view of the device, demonstrating its slim form factor. The
total thickness of the device is less than that of a standard
microscope slide.
Similarly, using the silicone adhesive, the circuit system can be
affixed to the arm without additional fixtures, thereby avoiding
any sense of restraint on the arm. The picture of our device
is Figure 7. The total weight of our device is only ∼48g.
B. Connect VR with Our Electro-haptic Device
Our VR application is developed with Unity3D for the Meta
Quest 2 headset and incorporates real-time hand tracking. We
utilize Unity’s physics engine to simulate realistic physical be-
haviors—such as gravity, inertia—on virtual objects, enabling
users to naturally grasp, release, and manipulate items within
the immersive environment. To further enhance realism, the
system dynamically adjusts object responses based on hand
velocity and applied force, allowing subtle interactions like
sliding, pushing, or tossing to feel intuitive and physically
grounded. Additionally, we have implemented an improved

collision detection algorithm between the hands and virtual
objects, ensuring that every contact point is captured with
high spatial precision. This refinement not only prevents visual
artifacts such as object penetration but also allows the system
to generate accurate symbolic representations of contact events
at the software layer. These signals are then transmitted as
serial input to the hardware interface, enabling the connected
stimulation module to respond with precise and low-latency
feedback.
VI. USER STUDY #1: WEARABILITY AND INTERFERENCE
OF OUR ELECTRO-HAPTIC DEVICE
A. Study Design
In this user study, we examined the impact of our electro-
haptic device on users’ hand-movement experiences. Common
haptic feedback devices include two-handed controllers (e.g.,
Xbox and PlayStation controllers), single-handed controllers
(e.g., VR controllers, Nintendo Switch Joy-Con), and glove-
based haptic devices (e.g., Haptic X1). Each participant was
asked to experience hand movements while wearing our
electro-haptic device and to compare these sensations with
three conditions: bare hand, glove, and VR controller. In
each trial, participants performed a series of predefined hand
movements, after which they rated the difficulty and comfort
of completing the actions. The study protocol was reviewed
and approved by our Institutional Review Board (IRB).
Fig. 8: Comparison of participant performing hand ges-
tures under different conditions: (a) bare hand, (b) wearing
the customized device, (c) wearing a glove, and (d) gripping
a VR controller.
a) Apparatus: Participants were seated comfortably and
extended the dominant hand to perform gestures. As shown
in Figure 8, each participant completed trials in and bare
hand and three interaction devices: bare hand (our base-
line), electro-haptic device worn on the palm (no current
in this study), regular cloth glove, VR handheld controller.
Participants were asked to perform five common gestures:
Thumbs-up, Number-one, Victory (V-sign), OK, and I-love-you
(ASL “ILY”). Note that there is no electrical stimulation was
delivered in this study; we isolated the effect of wearing the
hardware on motor performance and perceived comfort.
b) Participants: We recruited N = 8 participants from
our institution (5 identified as male, 3 as female; mean age
23.6, SD = 0.74). All were right-handed and received USD 25
compensation.
c) Procedure: We used a within-subjects design. Each
participant completed 40 trials (4 conditions with 5 gestures
for 2 repetitions) in randomized order. On each trial, a screen
prompt indicated the target gesture; participants executed it as
quickly and accurately as possible. After each trial, partici-
pants reported perceived difficulty and comfort. We recorded
gesture completion (binary) and completion time (from cue
onset to gesture completion). Short breaks were provided as
needed.
d) Interview Protocol: After the task, we conducted a
semi-structured interview to probe wearability and perceived
interference. Core prompts included:
• Which condition felt least and most burdensome for
executing gestures, and why?
• Relative to the bare-hand baseline, how does each condi-
tion differ?
• Specifically for our device, how does wearing it differ
from the bare-hand condition?
• Would you be willing to wear this device in practice? In
what scenarios and for how long?
• Do you have any additional comments about wearing our
device?
B. Qualitative Feedback
a) Effects of different devices on hand movement: All
eight participants ranked perceived interference across devices.
Seven of eight ranked our electro-haptic device as the least
interfering for producing gestures compared with bare-hand
baseline, and all eight ranked the VR controller as the most
interfering. Participants provided comments on our device,
e.g., “It felt like a thin face mask on my hand, at first I
thought it might slip, but it stayed put, so I could relax.” (P2);
“Pretty much the same as bare hand.” (P5). When asked about
willingness to wear the device, all eight indicated participants
they would be willing to wear it to obtain haptic feedback.
b) Comparisons with glove and VR controller: All eight
participants noted that our electro-haptic device imposed less
restriction on hand movement than the VR controller. Rep-
resentative comments included: “Gripping the VR controller
made it hard to form the gesture.” (P1); “With the electro-
haptic device I wasn’t worried about dropping anything; with

the controller I kept having to watch it.” (P5). Six participants
reported heat buildup with the glove that reduced comfort over
time, “I’d choose a glove in winter, but in summer it gets
stuffy.” (P8). One participant preferred the glove’s familiarity:
“Gloves feel natural to me since I wear them in real life; a
palm device keeps me aware of it and breaks immersion.” (P7).
c) Objective performance: Across gestures, completion
rate was 100% in both the electro-haptic device and glove
conditions (Figure 8). In terms of speed, wearing our device
doing gestures is slightly slower than bare hand yet substan-
tially faster than the VR controller.
In conclusion, the qualitative reports and performance data
indicate that the electro-haptic device introduces minimal
interference with hand movement and remains comfortable for
extended wear.
VII. USER STUDY #2: FINE-GRAINED MODULATE OF
ELECTRO-HAPTIC SENSATION
A. Study Design
In this user study, we measured how square-wave frequency
and duty cycle shape perceived tactile intensity. We targeted
the index fingertip and asked participants to rate perceived
intensity after each stimulus. We follow standard psychophys-
ical procedures previously used to study electro-haptic per-
ception [82]. Each trial tested one of 25 frequency–duty
cycle combinations, and participants were asked to report the
perceived intensity of the stimulation. The study followed
a traditional psychophysical methodology, which has been
widely applied in prior research on electro-haptic perception.
The experimental protocol was reviewed and approved by our
institutional review board (IRB).
a) Participants: We recruited N = 6 participants from
our institution (3 identified as male, 3 as female; mean age
23.5, SD = 1.05). All were right-handed and received USD 25
compensation.
b) Apparatus: Participants were seated at a desk with
their dominant hand placed palm-down on a cushioned arm-
rest for comfort. The electro-haptic device was attached to
the palm. To ensure good conductivity, participants were
instructed to clean their palms with hand sanitizer followed
by an alcohol wipe, and the device was attached once the
hands were fully dry.
c) Stimulus: Electrical stimulation was delivered using
conventional square-wave pulses, which targeted the index
fingertip. Stimulation frequency was set to one of five fixed
values (10 Hz, 25 Hz, 50 Hz, 100 Hz, 500 Hz), while duty
cycle was also fixed at one of five levels (2%, 5%, 10%, 25%,
50%).
d) Safety: To guarantee safety during the experiment, the
current amplitude was fixed at 1 mA, a value far below the
minimum threshold (10 mA) known to pose potential risks to
the human body [83]. Participants were not allowed to adjust
either the current or the device circuitry, thereby preventing
accidental changes.
Fig. 9: Perceived electro-haptic intensity across combi-
nations of stimulation frequency and duty cycle. The
3D surface shows mean subjective ratings on a five-level
categorical scale: No feeling (Level 1), Faint feeling (Level 2),
Moderate feeling (Level 3), Slight discomfort (Level 4), and
Pain (Level 5). Results indicate that lower frequencies and
larger duty cycles elicit stronger sensations, whereas higher
frequencies and smaller duty cycles produce weaker percepts.
This demonstrates that systematic modulation of temporal
parameters enables fine-grained and multi-dimensional control
of electro-haptic feedback.
e) Procedure: Each participant completed 75 trials pre-
sented in randomized order. The five frequency levels and five
duty cycles formed 25 distinct test combinations, each repeated
three times to ensure data reliability. Haptic sensations were
classified into five categories: No feeling, Faint feeling, Mod-
erate feeling, Slight discomfort, and Pain. Participants cate-
gorized each stimulation pattern according to their subjective
perception.
B. Results
a) Effect of frequency and duty cycle: As shown in Fig-
ure 9, perceived intensity increased with larger duty cycles and
decreased with higher frequencies, it means lower frequencies
can make participants have stronger feelings. This pattern
held consistently across participants. While absolute ratings
varied between individuals for a given stimulus, there were
no extreme cross-participant mismatches (e.g., one participant
reporting Pain while another reported No feeling for the same
stimulus).
b) Study interpretation: Our findings demonstrate that
frequency and duty cycle offer fine-grained modulation of
electro-haptic sensation beyond variations in current amplitude
alone. It also shows that even with a fixed, comfortable current
amplitude, systematic adjustment of these temporal parameters
can elicit a wide range of perceived qualities. Specifically,

frequency primarily influences the perceived temporal texture
of the stimulus, with lower frequencies producing a “buzzier”
or rougher sensation and higher frequencies yielding smoother
percepts, whereas duty cycle primarily alters apparent contact
force, such that lower duty cycles are associated with lighter
sensations, whereas higher duty cycles produce crisper and
stronger impressions.
In conclusion, according to the feedback of participants,
our electro-haptic device could offer fine-grained, multi-
dimensional and variable electro-haptic sensation.
Fig. 10: Examples of hand–object interactions played in
VR environments. The top row shows real-world grasping
motions, the middle row illustrates the corresponding VR
interactions, and the bottom row highlights the electrode
stimulation sites on the hand. (a) Adjusting a radio knob,
(b) grasping a bowling ball, (c) holding a mug, (d) holding a
remote control, (e) holding a flashlight, and (f) feeling airflow
from a fan.
VIII. APPLICATIONS: A LIGHTWEIGHT, PERSONALIZED
DEVICE FOR IMMERSIVE HAPTIC EXPERIENCES
A. Fine-grained and multi-dimensional electro-haptic feed-
back
One suitable testbed for our equipment is the virtual reality
(VR) environment. In VR, users often rely primarily on
vision to infer the state of hand–object interactions, which
can increase task difficulty and diminish immersion. Most
existing haptic devices provide either concentrate feedback
at the fingertips or apply uniform, whole-palm stimulation
due to limited haptic spatial resolution and integration. Our
electro-haptic device delivers multi-channel, location-specific
feedback across the hand, enabling more fine-grained tactile
differentiation.
As illustrated in Figure 10, users interact with different
virtual objects using different hand poses; stimulation sites
vary accordingly with contact location and gesture. We also
implemented invisible yet perceptible interaction, for example,
users can feel airflow from a virtual fan on the palm even
without a physical one. When the same object is approached
with different gestures, the stimulated regions differ, producing
distinct and reality tactile qualities that enhance human-object
interactions.
B. Haptic Timing Cues Enhance VR Basketball Task Perfor-
mance
Our electro-haptic device enables more precise and timely
actions in VR, thereby increasing realism and immersion. We
developed a VR free-throw mini-game (Figure 11) to evaluate
how our electro-haptic device supports shooting performance.
In this task, participants performed stationary shooting without
dribbling—they simply picked up a virtual basketball and
attempted to score. During each shot attempt, participants used
their right hand to grasp the ball from below while receiving
sustained, low-amplitude electro-haptic feedback indicating
maintained hand-ball contact. Upon ball release, the tactile
stimulation immediately ceased with a brief, distinct pulse
marking the moment of hand-ball separation. The virtual ball
then followed realistic physics, traveling toward the basket
with appropriate momentum and trajectory based on the
player’s throwing motion. After each shot attempt, regardless
of whether the ball scored or missed, participants pressed
a button to spawn a new basketball and reset for the next
attempt. The system automatically tracked shooting perfor-
mance, recording both successful scores and remaining ball
count throughout each session. This design enabled players
to focus entirely on shooting mechanics and aiming, using
electro-haptic feedback to precisely time their grip and release
without requiring visual attention to hand-ball interaction. The
event-contingent electrical cues supported critical shooting
parameters including grip stability and release timing, allowing
users to concentrate their visual focus on the target rather than
monitoring their hands.
Fig. 11: Examples of two applications. (a) A basketball mini-
game where users grasp and throw the ball to score. (b) A
drawing interface where users select colors and sketch on a
virtual canvas.

C. Haptic augmentation for VR painting
Our electro-haptic device could further function as an effec-
tive tool for haptic augmentation, broadening the range of tac-
tile experiences. We implemented a VR painting environment
(Figure 11) to explore how electro-haptic feedback enhances
creative digital tasks. The virtual workspace provided three
primary tools: a pen for drawing and writing, a fill tool for area
coloring, and an eraser for content removal. When participants
grasped the virtual pen, targeted electro-haptic stimulation
was delivered to simulate realistic pen-holding posture. This
tactile feedback guided users toward proper grip positioning
without visual cues, supporting natural writing and drawing
motions. The fill tool and eraser provided similar grip-specific
feedback patterns to differentiate tool selection through touch
alone. Color selection was facilitated through an RGB color
palette interface where users could mix primary colors to
customize both pen and fill tool outputs. The palette responded
to touch interactions, allowing intuitive color sampling and
tool customization during the creative process. To enhance the
sense of physical interaction, all tools incorporated velocity-
based force simulation. As users moved tools across the vir-
tual canvas, the system generated speed-dependent resistance
that mimicked real-world drawing dynamics—lighter, faster
strokes felt smoother while deliberate, slower movements
provided increased tactile resistance. This velocity-responsive
feedback helped users develop natural drawing rhythms and
pressure control. The painting surface consisted of a virtual
whiteboard where participants could freely draw, write, and
erase content. The combination of grip-specific tool feedback,
color mixing capabilities, and velocity-based force simulation
created a multimodal creative environment that supported
both precision tasks like writing and expressive activities like
artistic drawing, all while reducing dependence on visual tool
monitoring.
IX. USER STUDY #3: USER’S EXPERIENCE IN
APPLICATIONS
In User Studies #1 and #2, we examined how different
electrical stimulation patterns shape tactile perception and
assessed the comfort of wearing our electro-haptic device.
In this part, we next investigated whether the feedback de-
livered by our device could enhance users’ virtual reality
(VR) interaction experience. The motivation for this study
was informed by prior work exploring how wearable haptic
technologies influence tactile sensation and engagement in
VR environments. To this end, participants were asked to
interact with virtual objects while wearing our electro-haptic
device. We then conducted interviews to determine whether
the electro-haptic feedback provided by our device enhanced
or impeded their interactions with virtual objects.
A. Study Design
a) Participants: We recruited six participants (three iden-
tified as male, three as female, average age = 23.5 years,
SD = 1.05) from our institution; all six participants had
partaken in our first user study; All participants were right-
handed. Moreover, with the participants’ consent, we video-
taped and transcribed the study. Participants received USD 25
as compensation. The experimental protocol was reviewed and
approved by our institutional review board (IRB).
b) Tasks: Participants engaged with several VR scenarios
designed to evaluate electro-haptic feedback during interactive
tasks. These scenarios included tactile interaction with differ-
ent virtual objects, performing a VR free-throw basketball task,
and engaging in a VR painting experience. Participants were
free to complete all tasks at their own pace, and no fixed time
limits were imposed on task completion.
c) Interaction: The experimental tasks were designed to
ask participants to touch, grasp, or lift virtual objects while
perceiving tactile feedback from our device. The task sequence
was as follows: (1) In the first scenario, as shown in Figure 12,
participants were instructed to interact with as many different
virtual objects as possible, using a variety of hand gestures.
(2) In the second scenario, as shown in Figure 13, participants
picked up a basketball from the ground and attempted free-
throw shots. A reset button was provided to reposition the
ball, allowing multiple trials. Participants performed the task
both without tactile feedback and with electro-haptic feedback
enabled. (3) In the third scenario, as shown in Figure 13,
participants used a virtual brush to create drawings on a
digital canvas. As in the basketball task, they experienced the
drawing activity under both condition (without and with tactile
feedback).
Fig. 12: Four representative hand–object interaction ges-
tures and their corresponding tactile feedback. The top
row shows the real hand gestures, the middle row presents the
virtual interactions with a wine glass in VR, and the bottom
row illustrates the mapped electro-haptic stimulation points on
the hand diagram. Four gestures are: (a) Palm-up holding, (b)
finger pinch, (c) open-palm grasp, and (d) full-hand grip.
d) Apparatus: Participants wore a Meta Quest headset
along with our electro-haptic device. To ensure good conduc-

tivity, they were instructed to clean their palms with hand
sanitizer followed by an alcohol wipe. After their hands
were completely dry, the electro-haptic device was securely
attached.
e) Procedure: Before each task, the stimulation inten-
sity of the electro-haptic device was calibrated. The current
amplitude was adjusted to the level each participant reported
as most comfortable. During the experiment, the current level
remained constant to ensure that all tactile sensations stayed
within a comfortable range. This procedure also guaranteed
participant safety throughout the study.
f) Interview: After completing each task, we conducted
semi-structured interviews to explore participants’ experiences
of interacting with virtual objects in the VR scenarios. The
interviews began with two general questions: (1) “Can you
describe your perception of the tactile feedback while inter-
acting with virtual objects?” and (2) “Can you describe how
burdensome it felt to perform the tasks using our electro-haptic
device?”
We then asked scenario-specific follow-up questions. For
the first interaction scenario, participants were asked: “Which
object in the first scenario left the most memorable impression
on you?” For the basketball task, we asked: “Can you describe
the extent to which tactile feedback influenced your shooting
performance?” For the drawing task, participants were asked:
“Can you describe the extent to which tactile feedback in-
creased the burden of using the VR brush?”
In addition, for both the basketball and drawing tasks,
participants were asked the same question: “Would you prefer
to use our electro-haptic device when interacting in VR sce-
narios?” Finally, we concluded each interview with an open-
ended question: “Do you have any additional experiences you
would like to share with us?”
B. Qualitative Feedback
a) Tactile feedback during object interactions: Six par-
ticipants directly described their experiences of interacting
with virtual props. For example, one noted, “It felt as if I
were actually touching it in reality” (P2); another remarked,
“I felt that the objects had mass, rather than being weightless”
(P3); and a third commented, “I could perceive the shapes of
the objects more clearly” (P4). In particular, five participants
emphasized that the sensation of wind from a virtual fan was
especially memorable: “In typical VR scenarios, only visible
objects can be touched. With the haptic feedback device, I was
able to catch the wind, which felt novel and intriguing” (P3).
b) Tactile feedback in the basketball shooting task:
All six participants reported that tactile feedback was helpful
during the shooting task. Representative comments included:
“I could better sense the moment when the ball left my
hand” (P1) and “With tactile feedback, I felt I could control
the ball more effectively” (P3). We compared participants’
performance across the last five shots without tactile feedback
and the last five shots with tactile feedback (see Fig.). Overall,
the presence of tactile feedback improved shooting accuracy.
Fig. 13: Two scenarios for User Study #3. (a) Basketball
mini-game: Basketball shooting game via VR headset and
electro-haptic device. (b) Drawing interface: Writing and
drawing tasks via VR headset and electro-haptic device.
However, due to the inherent difficulty of the task, some
variability in individual performance was observed.
c) Tactile feedback in the drawing task: Five participants
noted that tactile feedback made the drawing process feel more
realistic. For instance, one commented, “I felt greater control
over the brush” (P2), while another remarked, “I could sense
the roughness of the canvas” (P6). As P4 explained, “Without
tactile feedback, it was difficult to judge the distance between
the brush and the canvas; the feedback helped me make
better contact with the surface.” However, one participant
expressed reservations, stating that the feedback was somewhat
exaggerated compared to real drawing: “The vibration of the
brush made it difficult to draw straight lines” (P5).
d) Conclusion: In summary, qualitative feedback from
participants shows that our device enhanced interaction in most
VR scenarios without imposing additional burdens. Partici-
pants did not report noticeable hand discomfort over extended
use, and the device did not interfere with fine motor control
of the hand.
X. FUTURE WORK
The focus of this paper has been on developing a highly
integrated and flexible user-customized electro-haptic device
capable of delivering precise and multi-dimensional feedback.
While the current study demonstrates the feasibility and effec-
tiveness of our approach, there is room for follow-up research
and exploration.
a) Multi-modality feedback integration: Our current de-
vice primarily provides electro-haptic feedback. Future works
could integrate additional modalities such as thermal feedback
(temperature cues) and mechanical feedback (e.g., pressure or
vibration). Combining these modalities would enable richer

and more immersive haptic experiences, further enhancing
realism in virtual and augmented environments.
b) Sensor integration for enhanced interaction: Incorpo-
rating integrated sensors (ee.g., motion tracking, force sensing,
or bio-signals such as EMG/EEG) into the device would allow
for more precise detection of hand position, gestures, and fine
motor control. Such functionality could be particularly useful
when visual tracking is limited—for example, in low-light
conditions or when the user’s hands are out of camera of head-
set, supporting accurate reconstruction of hand interactions in
virtual spaces.
c) Applications in AR and XR: While the present work
focuses on VR scenarios, extending the device to augmented
reality (AR) and extended reality (XR) applications would
broaden its potential impact. In AR, for example, the device
could support tactile cues for interacting with virtual overlays
on real-world objects, while in XR it could contribute to hy-
brid workspaces, medical simulations, or remote collaboration
environments where precise tactile cues are important.
XI. CONCLUSION
We introduced a untethered, ultra-thin, and user-customized
electro-haptic device that advances immersive human–machine
interaction. Fabricated with soft silicone substrates and print-
able liquid metal-montmorillonite ink , the device conforms to
the hand while remaining lightweight and minimally interfer-
ing. A palm-wide, addressable electrode array combined with
waveform modulation enables spatially precise, fine-grained,
and multi-dimensional haptic feedback.
Our user studies demonstrate that: (1) the electro-haptic
device introduces minimal interference with hand movement
and remains comfortable for extended wear; (2) it provides
fine-grained, multi-dimensional, and variable electro-haptic
sensations; and (3) it enhances interaction in most VR sce-
narios without imposing additional burdens. Furthermore, we
show that the device can improve task performance and serve
as an effective tool for haptic augmentation in VR applications.
We believe that our electro-haptic device can be applied
to a broader range of human–computer interaction scenarios
and contribute to the advancement of next-generation haptic
technologies.
ACKNOWLEDGMENT
This work was supported by National Natural Science Foun-
dation of China (22574106, T2522023), the Science and Tech-
nology Commission of Shanghai Municipality (24490710900),
and ShanghaiTech University (2023F0209-000-02).
REFERENCES
[1] Jose Daniel Azofeifa, Julieta Noguez, Sergio Ruiz,
Jos´e Mart´ın Molina-Espinosa, Alejandra J. Magana, and
Bedrich Benes.
Systematic review of multimodal hu-
man–computer interaction. Informatics, 9(1), 2022.
[2] Eloy Irigoyen, Mikel Larrea, and Manuel Gra˜na.
A
narrative review of haptic technologies and their value for
training, rehabilitation, and the education of persons with
special needs. Sensors (Basel, Switzerland), 24(21):6946,
2024.
[3] Sebastian Vizcay, Panagiotis Kourtesis, Ferran Arge-
laguet, Claudio Pacchierotti, and Maud Marchal. Elec-
trotactile feedback for enhancing contact information in
virtual reality. arXiv preprint arXiv:2102.00259, 2021.
[4] Xian Wang, Diego Monteiro, Lik-Hang Lee, Pan Hui,
and Hai-Ning Liang.
Vibroweight: Simulating weight
and center of gravity changes of objects in virtual reality
for enhanced realism. In 2022 IEEE haptics symposium
(HAPTICS), pages 1–7. IEEE, 2022.
[5] M Reza Motamedi, Jean-Philippe Roberge, and Vincent
Duchaine.
The use of vibrotactile feedback to restore
texture recognition capabilities, and the effect of subject
training.
IEEE Transactions on Neural Systems and
Rehabilitation Engineering, 25(8):1230–1239, 2016.
[6] Unnikrishnan Radhakrishnan, Lisheng Kuang, Konstanti-
nos Koumaditis, Francesco Chinello, and Claudio Pac-
chierotti. Haptic feedback, performance and arousal: A
comparison study in an immersive vr motor skill training
task. IEEE transactions on haptics, 17(2):249–262, 2023.
[7] Panagiotis Kourtesis, Sebastian Vizcay, Maud Marchal,
Claudio Pacchierotti, and Ferran Argelaguet.
Action-
specific perception & performance on a fitts’s law task
in virtual reality: The role of haptic feedback.
IEEE
Transactions on Visualization and Computer Graphics,
28(11):3715–3726, 2022.
[8] Yunxiang Zhang, Benjamin Liang, Boyuan Chen, Paul M
Torrens, S Farokh Atashzar, Dahua Lin, and Qi Sun.
Force-aware interface via electromyography for natural
vr/ar interaction. ACM Transactions on Graphics (TOG),
41(6):1–18, 2022.
[9] Jessica Yin, Ronan Hinchet, Herbert Shea, and Carmel
Majidi.
Wearable soft technologies for haptic sens-
ing and feedback.
Advanced Functional Materials,
31(39):2007428, 2021.
[10] Joshua J Fleck, Zane A Zook, Janelle P Clark, Daniel J
Preston, Darren J Lipomi, Claudio Pacchierotti, and Mar-
cia K O’Malley. Wearable multi-sensory haptic devices.
Nature Reviews Bioengineering, pages 1–15, 2025.
[11] Yuyu Gao, Kuanming Yao, Shengxin Jia, Ya Huang,
Guangyao Zhao, Binbin Zhang, Yiming Liu, and Xinge
Yu. Advances in materials for haptic skin electronics.
Matter, 7(9):2826–2845, 2024.
[12] Bingjian Huang, Paul H Dietz, and Daniel Wigdor.
Investigating the effects of intensity and frequency on
vibrotactile spatial acuity. IEEE Transactions on Haptics,
17(3):405–416, 2024.
[13] Ziliang Zhou, Yicheng Yang, Jinbiao Liu, Jia Zeng,
Xiaoxin Wang, and Honghai Liu.
Electrotactile per-
ception properties and its applications: A review. IEEE
transactions on haptics, 15(3):464–478, 2022.
[14] Rahul Kumar Ray, Madhan Kumar Vasudevan, and
M Manivannan. Electrotactile displays: taxonomy, cross-
modality, psychophysics and challenges.
Frontiers in
Virtual Reality, 5:1406923, 2024.

[15] Keigo Ushiyama and Pedro Lopes. Feetthrough: electro-
tactile foot interface that preserves real-world sensations.
In Proceedings of the 36th Annual ACM Symposium on
User Interface Software and Technology, pages 1–11,
2023.
[16] Kyeonghee Lim, Hunkyu Seo, Won Gi Chung, Hayoung
Song, Myoungjae Oh, Seoung Young Ryu, Younhee Kim,
and Jang-Ung Park. Material and structural considera-
tions for high-performance electrodes for wearable skin
devices. Communications Materials, 5(1):49, 2024.
[17] Mingyu Kim, Changyu Jeon, and Jinmo Kim. A Study on
Immersion and Presence of a Portable Hand Haptic Sys-
tem for Immersive Virtual Reality. Sensors, 17(5):1141,
May 2017.
[18] Eleftherios Triantafyllidis, Christopher Mcgreavy, Ji-
acheng Gu, and Zhibin Li.
Study of Multimodal In-
terfaces and the Improvements on Teleoperation. IEEE
Access, 8:78213–78227, 2020.
[19] Shan-Yuan Teng, Pengyu Li, Romain Nith, Joshua Fon-
seca, and Pedro Lopes. Touch&Fold: A Foldable Haptic
Actuator for Rendering Touch in Mixed Reality.
In
Proceedings of the 2021 CHI Conference on Human
Factors in Computing Systems, pages 1–14, Yokohama
Japan, May 2021. ACM.
[20] Xiaobin Ji, Xinchang Liu, Vito Cacucciolo, Yoan Civet,
Alae El Haitami, Sophie Cantin, Yves Perriard, and
Herbert Shea. Untethered Feel-Through Haptics Using
18-µm Thick Dielectric Elastomer Actuators. Advanced
Functional Materials, 31(39):2006639, September 2021.
[21] Ulrike Gollner, Tom Bieling, and Gesche Joost. Mobile
Lorm Glove: introducing a communication device for
deaf-blind people. In Proceedings of the Sixth Interna-
tional Conference on Tangible, Embedded and Embodied
Interaction, pages 127–130, Kingston Ontario Canada,
February 2012. ACM.
[22] Nicholas Caporusso. A wearable Malossi alphabet inter-
face for deafblind people. In Proceedings of the working
conference on Advanced visual interfaces, pages 445–
448, Napoli Italy, May 2008. ACM.
[23] Oliver Ozioko, William Taube, Marion Hersh, and Ravin-
der Dahiya. SmartFingerBraille: A tactile sensing and
actuation based communication glove for deafblind peo-
ple. In 2017 IEEE 26th International Symposium on In-
dustrial Electronics (ISIE), pages 2014–2018, Edinburgh,
United Kingdom, June 2017. IEEE.
[24] Dengfeng Li, Jiahui He, Zhen Song, Kuanming Yao,
Mengge Wu, Haoran Fu, Yiming Liu, Zhan Gao, Jingkun
Zhou, Lei Wei, Zhengyou Zhang, Yuan Dai, Zhaoqian
Xie, and Xinge Yu.
Miniaturization of mechanical
actuators in skin-integrated electronics for haptic in-
terfaces.
Microsystems & Nanoengineering, 7(1):85,
October 2021.
[25] Xinge Yu, Zhaoqian Xie, Yang Yu, Jungyup Lee, Abra-
ham Vazquez-Guardado, Haiwen Luan, Jasper Ruban,
Xin Ning, Aadeel Akhtar, Dengfeng Li, Bowen Ji, Yim-
ing Liu, Rujie Sun, Jingyue Cao, Qingze Huo, Yishan
Zhong, ChanMi Lee, SeungYeop Kim, Philipp Gutruf,
Changxing Zhang, Yeguang Xue, Qinglei Guo, Aditya
Chempakasseril, Peilin Tian, Wei Lu, JiYoon Jeong,
YongJoon Yu, Jesse Cornman, CheeSim Tan, BongHoon
Kim, KunHyuk Lee, Xue Feng, Yonggang Huang, and
John A. Rogers.
Skin-integrated wireless haptic in-
terfaces for virtual and augmented reality.
Nature,
575(7783):473–479, November 2019.
[26] Ronan Hinchet, Velko Vechev, Herbert Shea, and Otmar
Hilliges. DextrES: Wearable Haptic Feedback for Grasp-
ing in VR via a Thin Form-Factor Electrostatic Brake.
In Proceedings of the 31st Annual ACM Symposium on
User Interface Software and Technology, pages 901–912,
Berlin Germany, October 2018. ACM.
[27] Cathy Fang, Yang Zhang, Matthew Dworman, and Chris
Harrison. Wireality: Enabling Complex Tangible Geome-
tries in Virtual Reality with Worn Multi-String Haptics.
In Proceedings of the 2020 CHI Conference on Human
Factors in Computing Systems, pages 1–10, Honolulu HI
USA, April 2020. ACM.
[28] Ryohei Michikawa, Takahiro Endo, and Fumitoshi Mat-
suno. A Multi-DoF Exoskeleton Haptic Device for the
Grasping of a Compliant Object Adapting to a User’s
Motion Using Jamming Transitions. IEEE Transactions
on Robotics, 39(1):373–385, February 2023.
[29] J. Blake and H.B. Gurocak.
Haptic Glove With MR
Brakes for Virtual Reality. IEEE/ASME Transactions on
Mechatronics, 14(5):606–615, October 2009.
[30] Harshal Arun Sonar and Jamie Paik.
Soft Pneumatic
Actuator Skin with Piezoelectric Sensors for Vibrotactile
Feedback. Frontiers in Robotics and AI, 2, January 2016.
[31] Harshal A. Sonar, Aaron P. Gerratt, St´ephanie P. Lacour,
and Jamie Paik. Closed-Loop Haptic Feedback Control
Using a Self-Sensing Soft Pneumatic Actuator Skin. Soft
Robotics, 7(1):22–29, February 2020.
[32] Vito Cacucciolo, Jun Shintake, Yu Kuwajima, Shingo
Maeda, Dario Floreano, and Herbert Shea. Stretchable
pumps for soft machines. Nature, 572(7770):516–519,
August 2019.
[33] Vivian Shen, Tucker Rae-Grant, Joe Mullenbach, Chris
Harrison, and Craig Shultz.
Fluid Reality: High-
Resolution, Untethered Haptic Gloves using Electroos-
motic Pump Arrays. In Proceedings of the 36th Annual
ACM Symposium on User Interface Software and Tech-
nology, pages 1–20, San Francisco CA USA, October
2023. ACM.
[34] Seung-Chan Kim, Chong-Hui Kim, Gi-Hun Yang, Tae-
Heon Yang, Byung-Kil Han, Sung-Chul Kang, and
Dong-Soo Kwon.
Small and lightweight tactile dis-
play(SaLT) and its application. In World Haptics 2009 -
Third Joint EuroHaptics conference and Symposium on
Haptic Interfaces for Virtual Environment and Teleoper-
ator Systems, pages 69–74, Salt Lake City, UT, USA,
March 2009. IEEE.
[35] Qi Wang and V. Hayward. Compact, Portable, Modular,
High-performance, Distributed Tactile Transducer Device

Based on Lateral Skin Deformation.
In 2006 14th
Symposium on Haptic Interfaces for Virtual Environment
and Teleoperator Systems, pages 67–72, Alexandria, VA,
USA, 2006. IEEE.
[36] Minglu Zhu, Zhongda Sun, Zixuan Zhang, Qiongfeng
Shi, Tianyiyi He, Huicong Liu, Tao Chen, and Chengkuo
Lee. Haptic-feedback smart glove as a creative human-
machine interface (HMI) for virtual/augmented reality
applications.
Science Advances, 6(19):eaaz8693, May
2020.
[37] Mitsuru
Nakajima,
Keisuke
Hasegawa,
Yasutoshi
Makino, and Hiroyuki Shinoda. Spatiotemporal Pinpoint
Cooling Sensation Produced by Ultrasound-Driven Mist
Vaporization on Skin.
IEEE Transactions on Haptics,
14(4):874–884, October 2021.
[38] Euan Freeman and Graham Wilson. Perception of Ul-
trasound Haptic Focal Point Motion. In Proceedings of
the 2021 International Conference on Multimodal Inter-
action, pages 697–701, Montr´eal QC Canada, October
2021. ACM.
[39] Benjamin Long, Sue Ann Seah, Tom Carter, and Sriram
Subramanian.
Rendering volumetric haptic shapes in
mid-air using ultrasound. ACM Transactions on Graph-
ics, 33(6):1–10, November 2014.
[40] K.A. Kaczmarek, J.G. Webster, P. Bach-y Rita, and W.J.
Tompkins.
Electrotactile and vibrotactile displays for
sensory substitution systems.
IEEE Transactions on
Biomedical Engineering, 38(1):1–16, January 1991.
[41] Hiroyuki Kajimoto, Naoki Kawakami, Taro Maeda, and
Susumu Tachi. Tactile Feeling Display using Functional
Electrical Stimulation.
[42] Yei Hwan Jung, Jae-Hwan Kim, and John A. Rogers.
Skin-Integrated Vibrohaptic Interfaces for Virtual and
Augmented Reality (Adv. Funct. Mater. 39/2021). Ad-
vanced Functional Materials, 31(39):2170291, Septem-
ber 2021.
[43] Arianna Mazzotta, Marco Carlotti, and Virgilio Mattoli.
Conformable on-skin devices for thermo-electro-tactile
stimulation: materials, design, and fabrication. Materials
Advances, 2(6):1787–1820, 2021.
[44] M. Ercan Altinsoy and Sebastian Merchel. Electrotactile
Feedback for Handheld Devices with Touch Screen and
Simulation of Roughness. IEEE Transactions on Haptics,
5(1):6–13, January 2012.
[45] Vibol Yem, Kevin Vu, Yuki Kon, and Hiroyuki Kajimoto.
Effect of Electrical Stimulation Haptic Feedback on
Perceptions of Softness-Hardness and Stickiness While
Touching a Virtual Object.
In 2018 IEEE Conference
on Virtual Reality and 3D User Interfaces (VR), pages
89–96, Reutlingen, March 2018. IEEE.
[46] Michele Germani, Maura Mengoni, and Margherita Pe-
ruzzini. Electro-tactile device for material texture simu-
lation. The International Journal of Advanced Manufac-
turing Technology, 68(9-12):2185–2203, October 2013.
[47] Colin V. Keef, Laure V. Kayser, Stazia Tronboll, Cody W.
Carpenter, Nicholas B. Root, Mickey Finn, Timothy F.
O’Connor, Sami N. Abuhamdieh, Daniel M. Davies,
Rory Runser, Ying Shirley Meng, Vilayanur S. Ra-
machandran, and Darren J. Lipomi.
Virtual Texture
Generated Using Elastomeric Conductive Block Copoly-
mer in a Wireless Multimodal Haptic Glove. Advanced
Intelligent Systems, 2(4):2000018, April 2020.
[48] Yahya Abbass, Strahinja Dosen, Lucia Seminara, and
Maurizio Valle. Full-hand electrotactile feedback using
electronic skin and matrix electrodes for high-bandwidth
human–machine interfacing. Philosophical Transactions
of the Royal Society A: Mathematical, Physical and
Engineering Sciences, 380(2228):20210017, July 2022.
[49] Weikang Lin, Dongsheng Zhang, Wang Wei Lee, Xue-
long Li, Ying Hong, Qiqi Pan, Ruirui Zhang, Guoxiang
Peng, Hong Z. Tan, Zhengyou Zhang, Lei Wei, and
Zhengbao Yang. Super-resolution wearable electrotactile
rendering system.
Science Advances, 8(36):eabp8738,
September 2022.
[50] Devin Murphy, Yichen Li, Crystal Elaine Owens, Layla
Stanton, Paul Pu Liang, Yiyue Luo, Antonio Torralba,
and Wojciech Matusik. Fits like a flex-glove: Automatic
design of personalized fpcb-based tactile sensing gloves.
In Proceedings of the Extended Abstracts of the CHI
Conference on Human Factors in Computing Systems,
CHI EA ’25, New York, NY, USA, 2025. Association
for Computing Machinery.
[51] Ismail Ben Abdallah, Yassine Bouteraa, and Chokri
Rekik. Design and development of 3d printed myoelec-
tric robotic exoskeleton for hand rehabilitation. Interna-
tional journal on smart sensing and intelligent systems,
10(2):341, 2017.
[52] Nicola Secciani, Chiara Brogi, Marco Pagliai, Francesco
Buonamici, Filippo Gerli, Federica Vannetti, Massimo
Bianchini, Yary Volpe, and Alessandro Ridolfi. Wearable
robots: An original mechatronic design of a hand ex-
oskeleton for assistive and rehabilitative purposes. Fron-
tiers in Neurorobotics, 15:750385, 2021.
[53] Anik Kumar Saha, Md Abrar Jahin, Md Rafiquzzaman,
and Muhammad Firoz Mridha.
Ergonomic design of
computer laboratory furniture: Mismatch analysis utiliz-
ing anthropometric data of university students. Heliyon,
10(14), 2024.
[54] Daniele Esposito, Jessica Centracchio, Emilio Andreozzi,
Sergio Savino, Gaetano D Gargiulo, Ganesh R Naik, and
Paolo Bifulco. Design of a 3d-printed hand exoskeleton
based on force-myography control for assistance and
rehabilitation. Machines, 10(1):57, 2022.
[55] Yudai Tanaka, Alan Shen, Andy Kong, and Pedro Lopes.
Full-hand electro-tactile feedback without obstructing
palmar side of hand. In Proceedings of the 2023 CHI
Conference on Human Factors in Computing Systems,
CHI ’23, New York, NY, USA, 2023. Association for
Computing Machinery.
[56] Anusha Withana, Daniel Groeger, and J¨urgen Steimle.
Tacttoo: A thin and feel-through tattoo for on-skin tac-
tile output.
In Proceedings of the 31st Annual ACM

Symposium on User Interface Software and Technology,
UIST ’18, page 365–378, New York, NY, USA, 2018.
Association for Computing Machinery.
[57] Mei-ying Kwan, Kit-lun Yick, Lung Chow, Annie Yu,
Sun-pui Ng, and Joanne Yip. Impact of postural variation
on hand measurements: Three-dimensional anatomical
analysis. PloS one, 16(4):e0250428, 2021.
[58] Clayton Leite, Petr Byvshev, Henry Mauranen, and
Yu Xiao.
Simulation-driven design of smart gloves
for gesture recognition. Scientific Reports, 14(1):14873,
2024.
[59] Weiya Chen, Chenchen Yu, Chenyu Tu, Zehua Lyu, Jing
Tang, Shiqi Ou, Yan Fu, and Zhidong Xue. A survey
on hand pose estimation with wearable sensors and
computer-vision-based methods.
Sensors, 20(4):1074,
2020.
[60] Javier Romero, Dimitrios Tzionas, and Michael J. Black.
Embodied hands: Modeling and capturing hands and
bodies together. ACM Transactions on Graphics, (Proc.
SIGGRAPH Asia), 36(6), November 2017.
[61] Xiong Zhang, Qiang Li, Hong Mo, Wenbo Zhang, and
Wen Zheng.
End-to-end hand mesh recovery from a
monocular rgb image. 2019.
[62] Hanwen Jiang, Shaowei Liu, Jiashun Wang, and Xiao-
long Wang. Hand-object contact consistency reasoning
for human grasps generation.
In Proceedings of the
International Conference on Computer Vision, 2021.
[63] Baowen Zhang, Yangang Wang, Xiaoming Deng, Yinda
Zhang, Ping Tan, Cuixia Ma, and Hongan Wang. Inter-
acting two-hand 3d pose and shape reconstruction from
single color image.
In Proceedings of the IEEE/CVF
International Conference on Computer Vision (ICCV),
pages 11354–11363, October 2021.
[64] Xingyu Chen, Yufeng Liu, Chongyang Ma, Jianlong
Chang, Huayan Wang, Tian Chen, Xiaoyan Guo, Pengfei
Wan, and Wen Zheng. Camera-space hand mesh recovery
via semantic aggregation and adaptive 2d-1d registra-
tion. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR), pages
13274–13283, June 2021.
[65] Xingyu Chen, Yufeng Liu, Dong Yajiao, Xiong Zhang,
Chongyang Ma, Yanmin Xiong, Yuan Zhang, and Xi-
aoyan Guo.
Mobrecon: Mobile-friendly hand mesh
reconstruction from monocular image. In Proceedings
of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), 2022.
[66] Pengfei Xie, Wenqiang Xu, Tutian Tang, Zhenjun Yu,
and Cewu Lu. Ms-mano: Enabling hand pose tracking
with biomechanical constraints. In Proceedings of the
IEEE/CVF conference on computer vision and pattern
recognition, pages 2382–2392, 2024.
[67] Ziwei Yu, Chen Li, Linlin Yang, Xiaoxu Zheng,
Michael Bi Mi, Gim Hee Lee, and Angela Yao. Over-
coming the trade-off between accuracy and plausibility
in 3d hand shape reconstruction. In Proceedings of the
IEEE/CVF conference on computer vision and pattern
recognition, pages 544–553, 2023.
[68] Yu Lei, Yi Deng, Lin Dong, Xiaohui Li, Xiangnan Li,
and Zhi Su. A novel sensor fusion approach for precise
hand tracking in virtual reality-based human—computer
interaction. Biomimetics, 8(3):326, 2023.
[69] Xingyu Chen, Yufeng Liu, Yajiao Dong, Xiong Zhang,
Chongyang Ma, Yanmin Xiong, Yuan Zhang, and Xi-
aoyan Guo.
Mobrecon: Mobile-friendly hand mesh
reconstruction from monocular image. In Proceedings
of the IEEE/CVF conference on computer vision and
pattern recognition, pages 20544–20554, 2022.
[70] Shantonu Biswas and Yon Visell.
Emerging material
technologies for haptics. Advanced Materials Technolo-
gies, 4(4):1900042, 2019.
[71] Yufeng Qin, Xueqiong Ouyang, Yang Lv, Wencai Liu,
Qing Liu, and Shuangxi Wang.
A review of carbon-
based conductive inks and their printing technologies for
integrated circuits. Coatings, 13(10):1769, 2023.
[72] Vicente Orts Mercadillo, Kai Chio Chan, Mario Caironi,
Athanassia Athanassiou, Ian A Kinloch, Mark Bissett,
and Pietro Cataldi. Electrically conductive 2d material
coatings for flexible and stretchable electronics: a com-
parative review of graphenes and mxenes.
Advanced
Functional Materials, 32(38):2204772, 2022.
[73] Leily Majidi, Dmitry Gritsenko, and Jie Xu. Gallium-
based room-temperature liquid metals: Actuation and
manipulation of droplets and flows.
Frontiers in Me-
chanical Engineering, 3:9, 2017.
[74] Yifan Deng, Fan Bu, Yujie Wang, Pei Song Chee, Xi-
angye Liu, and Cao Guan. Stretchable liquid metal based
biomedical devices.
npj Flexible Electronics, 8(1):12,
2024.
[75] Michael D Dickey. Stretchable and soft electronics using
liquid metals.
Advanced materials, 29(27):1606425,
2017.
[76] Wuzhou Zu, Hugo E Carranza, and Michael D Bartlett.
Enhancing electrical conductivity of stretchable liquid
metal–silver composites through direct ink writing. ACS
Applied Materials & Interfaces, 16(18):23895–23903,
2024.
[77] Yiran Ding, Mengqi Zeng, and Lei Fu. Surface chemistry
of gallium-based liquid metals. Matter, 3(5):1477–1506,
2020.
[78] Ziang Cui, Yiqing Zhang, Siyuan Chen, Xingming Wen,
Yining Zhao, Yitao Ma, Qihang Yan, Zixiong Wu, Yuxi
He, Guohui Wang, et al.
A printable liquid metal-
montmorillonite ink for high-resolution stretchable bio-
electronics. Journal of Materials Chemistry C, 2025.
[79] Hao Wu, Ganguang Yang, Kanhao Zhu, Shaoyu Liu, Wei
Guo, Zhuo Jiang, and Zhuo Li. Materials, devices, and
systems of on-skin electrodes for electrophysiological
monitoring and human–machine interfaces.
Advanced
Science, 8(2):2001938, 2021.
[80] Hailing Xue, Dongyang Wang, Mingyan Jin, Hanbing
Gao, Xuhui Wang, Long Xia, Dong’ang Li, Kai Sun,
Huanan Wang, Xufeng Dong, et al.
Hydrogel elec-

trodes with conductive and substrate-adhesive layers for
noninvasive long-term eeg acquisition. Microsystems &
Nanoengineering, 9(1):79, 2023.
[81] Yulin Fu, Jingjing Zhao, Ying Dong, and Xiaohao Wang.
Dry electrodes for human bioelectrical signal monitoring.
Sensors, 20(13):3651, 2020.
[82] Stefan Manoharan and Hangue Park.
Characterization
of perception by transcutaneous electrical stimulation
in terms of tingling intensity and temporal dynamics.
Biomedical Engineering Letters, 14(1):35–44, 2024.
[83] Michael R Zemaitis, Lisa A Foris, Richard A Lopez, and
Martin R Huecker. Electrical injuries. 2017.
