1
Judicial Sentencing Prediction Based on Hybrid Models and
Two-Stage Learning Algorithms
Ruifen Dai, Xin Zheng, Fang Wang, and Lei Guo, Fellow, IEEE
Abstract—The investigation of legal judgment prediction
(LJP), such as sentencing prediction, has attracted broad
attention for its potential to promote judicial fairness,
making the accuracy and reliability of its computation
result an increasingly critical concern. In view of this,
we present a new sentencing model that shares both legal
logic interpretability and strong prediction capability by
introducing a two-stage learning algorithm. Speciﬁcally, we
ﬁrst construct a hybrid model that synthesizes a mechanism
model based on the main factors for sentencing with
a neural network modeling possible uncertain features.
We then propose a two-stage learning algorithm: First,
an adaptive stochastic gradient (ASG) algorithm is used
to get good estimates for the unknown parameters in
the mechanistic component of the hybrid model. Then,
the Adam optimizer tunes all parameters to enhance
the predictive performance of the entire hybrid model.
The asymptotic convergence of the ASG-based adaptive
predictor is established without requiring any excitation
data conditions, thereby providing a good initial parameter
estimate for prediction. Based on this, the fast-converging
Adam optimizer further reﬁnes the parameters to enhance
overall prediction accuracy. Experiments on a real-world
dataset of intentional injury cases in China show that
our new hybrid model combined with our two-stage ASG-
Adam algorithm, outperforms the existing related methods
in sentencing prediction performance, including those based
on neural networks and saturated mechanism models.
Index Terms—Sentencing Prediction, Saturated Mecha-
nism Model, Neural Network, Two-Stage ASG-Adam Algo-
rithm, Prediction Error Minimization.
I. INTRODUCTION
I
N recent years, the investigation of various problems
in legal judgment prediction (LJP), such as sentencing
prediction, has attracted broad research attention due
to its vital role in enhancing fairness in the judicial
This paper was supported by the National Natural Science Founda-
tion of China under Grant Nos. T2293773, 72371145 and 12288201,
the National Key Research and Development Program under Grant No.
2024YFC3307200, the Special Funds for Taishan Scholars Project of
Shandong Province, China, under Grant No. tsqn202211004. (Corre-
sponding Author: Fang Wang, Lei Guo.)
Ruifen
Dai
and
Fang
Wang
are
with
the
Data
Science
Institute,
Shandong
University,
Jinan
250100,
China.
(e-mails:
dairuifen@mail.sdu.edu.cn, wangfang226@sdu.edu.cn).
Xin Zheng and Lei Guo are with the State Key Laboratory of Mathe-
matical Sciences, Academy of Mathematics and Systems Science, Chi-
nese Academy of Sciences, Beijing 100190, China, and also with the
School of Mathematical Sciences, University of Chinese Academy of
Sciences, Beijing 100049, China. (e-mails: zhengxin2021@amss.ac.cn,
lguo@amss.ac.cn).
system ( [2]- [10]). Among these problems, ensuring
the high reliability and accuracy of sentencing prediction
results is an important requirement in judicial practice.
This requirement calls for sentencing models that inte-
grate the sentencing logic for interpretability and capture
case-speciﬁc uncertainties not speciﬁed explicitly in law
for prediction capability. However, such models have
been rarely developed in the literature. Moreover, most
existing theories on the current mainstream gradient-
based learning algorithms are not directly applicable
to sentencing prediction, since they rely on common
yet stringent statistical assumptions on the data, such
as the independent and identically distributed (i.i.d.)
data assumption, which are not the case for real-world
judicial datasets. Therefore, developing sentencing pre-
diction models based on judicial logic and establishing
the performance guarantees of the associated learning
algorithms, hold signiﬁcant value in both theory and
practice.
Although most existing LJP studies have not ade-
quately addressed the aforementioned challenges, their
efforts toward achieving high-precision sentencing pre-
diction offer valuable insights (see, e.g., [1]– [7], [11]–
[12], [17], [18]), which can be broadly summarized in
terms of model construction and algorithm design in the
following:
First, extensive research has been conducted on using
machine learning models for sentencing prediction. For
example, [1] introduced a convolutional neural network
(CNN)-based model for sentencing classiﬁcation predic-
tion. To address the need to model subtask dependencies,
[2] employed a multi-task learning framework TopJudge
that represents the dependencies among LJP subtasks
using a directed acyclic graph. To further capture the
relationships between subtasks, [3] proposed a multi-
perspective bi-feedback network model enhanced by a
word collocation attention mechanism, which reﬂects
subtask dependencies through a topology-aware design.
Subsequently, [4] modeled LJP as a node classiﬁcation
problem over a global consistency graph. [5] presented
the LADAN model, which combines a graph neural net-
work (GNN) and an attention mechanism to distinguish
confusing law articles for more accurate LJP. In addition,
[6] introduced a NeurJudge model that sets BERT (see
[13]) as a judgment encoder and leverages intermediate
arXiv:2511.15374v1  [math.DS]  19 Nov 2025

2
subtask results to partition fact descriptions into circum-
stances for guiding subsequent subtask predictions. [7]
presented a QAjudge model composed of a question net
and an answer net to visualize the prediction processes.
Despite the widespread application of the machine
learning sentencing models, they fail to fully incorporate
the sentencing logic in the sentencing guidelines. In view
of this, [11] proposed an interpretable saturated mecha-
nism model based on the sentencing logic of “starting
point—benchmark sentence—announced sentence”, and
applied it to sentencing prediction for the crime of inten-
tional injury. To improve sentencing prediction accuracy,
[12] incorporated saturated boundaries to ensure that neu-
ral network–predicted sentences fall within the statutory
sentencing range. [31] and [32] reﬁned the sentencing
mechanism model proposed in [11] by incorporating
the temporal logic underlying sentencing adjustments
for benchmark sentences. The impact that not explicitly
encoded in sentencing guidelines, although potentially
varying across different cases, is coarsely represented by
a ﬁxed constant in [31] and [32].
Second, many efforts have been devoted to designing
algorithms for sentencing prediction. For instance, [17]
proposed a two-step Newton-type adaptive algorithm and
analyzed the related performances for both parameter
estimation and sentencing prediction, without resorting to
the traditional persistence of excitation (PE) on the sys-
tem data. Subsequently, [18] designed a more robust two-
step weighted l1-based Newton-type algorithm to im-
prove prediction performance and established its global
convergence. Both algorithms in [17]- [18] were applied
to sentencing prediction tasks based on the saturated
mechanism model proposed in [11]. However, all the
above algorithms incur high computational costs when
processing large-scale and high-dimensional judicial data
due to their second-order nature. Different from the
Newton-type algorithms, the gradient descent algorithms
and their variants, such as Adam [15], Adadelta [16],
and AdamW [14], are also used for sentencing prediction
based on neural network models (e.g., [1]- [7], [12]).
However, neural networks are just mathematical approx-
imation and can hardly provide judicial interpretability
for the sentencing results.
To overcome the aforementioned shortcomings, we
establish a new sentencing model that possesses both
high legal interpretability and strong predictive capability
by introducing a two-stage gradient algorithm. The main
contributions can be summarized as follows:
• We will introduce a hybrid model that integrates
the sentencing-logic-based mechanism model with
a neural network, which can not only reﬂect the
main factors for sentencing, but also can reﬂect the
inﬂuence of possible uncertain factors not explicitly
encoded in the sentencing guidelines.
• We will propose a two-stage learning (TSL) algo-
rithm for the prediction of the hybrid sentencing
model. To be speciﬁc, an adaptive stochastic gra-
dient (ASG) algorithm will provide a good initial
value of the mechanistic component parameters for
the Adam optimizer in the next stage to ﬁne-tune
all parameters to improve the sentencing prediction
performance.
• We will rigorously establish the global asymptotic
convergence of the ASG-based adaptive predictor
without requiring any excitation data conditions.
This theoretical guarantee ensures that the ASG-
based initialization provides a reliable approxima-
tion to globally optimal prediction, thereby offering
a solid basis for the reﬁned prediction by the Adam
optimizer.
• Empirical experiments using a real-world judgment
dataset for the crime of intentional injury (CII)
will show that our proposed hybrid model and
two-stage algorithm can achieve high accuracy in
sentencing prediction, outperforming other known
related methods.
The structure of this paper is as follows: Section II
will introduce the new sentencing model. Section III will
present the two-stage ASG-Adam algorithm. Section IV
will provide the global asymptotic convergence theory
of the ASG algorithm whose proof will be shown in
the appendix. In Section V, we will demonstrate the
advantages of the proposed model and algorithm using
a real-world sentencing dataset. The concluding remarks
will be presented in the ﬁnal section.
II. A HYBRID SMNN MODEL
In this section, we propose a hybrid model that
integrates the sentencing mechanism (SM) in Chinese
Criminal Law with a neural network (NN) accounting
for possible uncertainties in sentencing, abbreviated as
SMNN model, as follows:
zk+1 = Sk
 h
ak + bx(1)
k
+ cx(2)
k
i
|
{z
}
benchmark sentence
×
m1
Y
i=1
(1 + piv(i)
k )
|
{z
}
inﬂuence of primary factors
×

1 +
m2
X
j=1
qju(j)
k
+ ek


|
{z
}
inﬂuence of other factors
+wk+1

,
(1)
where the time-varying bias term ek and the saturated
function Sk(·) are deﬁned respectively as follows:
ek = Γσ

Bσ

Aηk + b(1)
+ b(2)
+ b(3),
(2)

3
Sk(x) =





Lk,
x < Lk;
x,
Lk ≤x ≤Nk;
Nk,
x > Nk,
(3)
and where zk ∈R is the pronounced sentence, ak ∈R
is the sentencing starting point, and x(i)
k
∈R, i = 1, 2,
represent the factors determining penalty amounts, e.g.,
in the CII 1, they represent the number of seriously and
minorly injured victims, respectively. b, c ∈R quantify
the additional sentence for the offender corresponding to
a one-unit increase in x(i)
k . v(i)
k , i = 1, · · · , m1 denote
primary sentencing factors with application priority, and
u(j)
k , j = 1, · · · , m2 denote other sentencing factors.
pi, i = 1, · · · , m1 and qj, j = 1, · · · , m2 are unknown
weighting parameters for v(i)
k
and u(j)
k , respectively. m1
and m2 are the number of primary sentencing factors
and other sentencing factors, respectively. wk
∈R
denotes potential random noise effects. ek
∈R in
(2) is the bias term reﬂecting the comprehensive in-
ﬂuence of possible factors not speciﬁed explicitly in
the law, and A ∈Rm×m3, B ∈Rm×m, Γ ∈R1×m
are unknown weight parameter matrices or vectors, and
b(1) ∈Rm, b(2) ∈Rm, b(3) ∈R are unknown bias
parameters in the neural network. Here, m represents
the number of neurons in each of the two hidden layers.
m3 denotes the number of possible factors that not
speciﬁed in the law. ηk ∈Rm3 denotes the vector of
factors that not explicitly encoded in the law of the k-th
case’s sentencing. σ(X) is an activation function, such
as the Rectiﬁed Linear Unit (ReLU) function, deﬁned
as (max(x1, 0), max(x2, 0), . . . , max(xm, 0))τ with xi
being the element of X in the i-th row, i = 1, · · · , m.
Lk ∈R and Nk ∈R in (3) are the lower and upper
bounds for the announced sentence, respectively, which
are prescribed in Chinese Criminal Law and may vary
for different crimes and criminal cases.
Remark 1 The SMNN model (1) is mainly based on
Chinese Criminal Law and sentencing guidelines2, it
speciﬁcally follows the sentencing logic of “starting
point—benchmark sentence—announced sentence” and
incorporates temporal adjustments for benchmark sen-
tences (see [31], [32] for more details). Moreover, the
model employs a neural network to approximate the
comprehensive inﬂuences of factors that are not explicitly
encoded in the law. Unlike treating the bias term as a
ﬁxed constant in previous studies ( [31] and [32]), the
neural network can approximate the case-speciﬁc inﬂu-
ences, enhancing the model’s ﬂexibility and predictive
performance.
1Related deﬁnition and interpretation for the crime of intentional
injury can be found in Article 234 of Chinese Criminal Law, available
on the website https://ﬂk.npc.gov.cn/.
2See https://ﬂk.npc.gov.cn/ and https://www.court.gov.cn/.
The SMNN model (1) will degenerate to the mechanism
model in [11], if we take v(i)
k
= 0, i = 1, · · · , m1 and
replace ek with a constant e.
Remark 2 The saturated function (3) ensures that the
sentences are restricted to the statutory penalty range,
and when a sentence exceeds the upper limit Nk or falls
below the lower limit Lk, the ﬁnal judgment is capped
at Nk or Lk, respectively.
Besides, the saturated phenomena described by (3)
are also commonly found in various application ﬁelds,
including engineering systems ( [26]- [27]), economic
behavior analysis ( [28]- [29]), biomedical systems (
[30]), and others. These applications collectively empha-
size the importance of saturated scenarios in complex
nonlinear modeling and analysis.
Remark 3 The SMNN model mainly comprises two
parts: (i) a mechanistic component grounded in the sen-
tencing logic, and (ii) a neural network that captures the
inﬂuence of possible residual factors (RF) not explicitly
encoded in sentencing law. Since the mechanistic com-
ponent already encodes the factors and rules explicitly
stated in the sentencing law, which plays a dominating
role in sentencing, the inﬂuence of the RF may not
be signiﬁcant. Therefore, we ﬁrst assume the bias term
ek = e to be a constant reﬂecting the averaged effect
of the RF, in order to facilitate a more straightforward
estimation of the mechanistic component. After this stage,
the highly nonlinear neural network will be introduced
to enhance the prediction accuracy for each case.
To avoid non-convex optimization problems to get bet-
ter estimators of the mechanistic component parameters,
we rewrite the internal structure of (1) as a linearly
parameterized regression by increasing the dimension
of both regression vectors and parameter vectors. Here
the bias term ek = e. To be speciﬁc, set the expanded
regressor and parameter vector as follows:
φk =

akφT
1k, ak(φ2k ⊗φ1k)T , x(1)
k φT
1k,
x(1)
k (φ2k ⊗φ1k)T , x(2)
k φT
1k, x(2)
k (φ2k ⊗φ1k)T T ,
(4)
θ =

(1 + e)ϑT
1 , (ϑ2 ⊗ϑ1)T , b(1 + e)ϑT
1 ,
b(ϑ2 ⊗ϑ1)T , c(1 + e)ϑT
1 , c(ϑ2 ⊗ϑ1)T T ,
(5)
where
φ1k =[1, z(1)
k , · · · , z(m1)
k
, z(1)
k z(2)
k , · · · ,
z(m1−1)
k
z(m1)
k
, · · · , z(1)
k
· · · z(m1)
k
]T ,
(6)
φ2k =[u(1)
k , u(2)
k , · · · , u(m2)
k
]T ,
(7)
ϑ1 =[1, p1, · · · , pm1, p1p2, · · · , pm1−1pm1,
· · · , p1 · · · pm1]T ,
(8)
ϑ2 =[q1, · · · , qm2]T ,
(9)

4
and the Kronecker product of two vectors is deﬁned
as a ⊗b = [a1b, a2b, · · · , amb]. Then (1) can be
rewritten as follows:
zk+1 = Sk(φT
k θ + wk+1).
(10)
For the above new parameterized model (10), the
dimension of the unknown parameter θ is 2m1(3+3m2),
which grows exponentially with m1, resulting in a huge
demand for computational resources to handle such high-
dimensional inputs. Taking the CII example as detailed
below, the dimension of unknown parameter vector is
565,248, rendering many Newton-type methods (e.g.,
[17], [18]) computationally infeasible due to excessive
memory and time complexity.
III. A GRADIENT-BASED TWO-STAGE ALGORITHM
In this section, we propose the two-stage gradient
learning algorithm for the SMNN model (1).
To better introduce the algorithm, we ﬁrst introduce
the following notations and assumptions.
A. Notations and Assumptions
Notations. Throughout the sequel, ∥·∥1 and ∥·∥denote
the 1-norm and Euclidean norm of vectors or matrices,
respectively. The maximum and minimum eigenvalues
of a square matrix X are denoted by λmax{X} and
λmin{X}, respectively. Let {Fk} be a non-decreasing
sequence of σ-algebras, along with the associated condi-
tional expectation operator E[· | Fk]. Moreover, for any
two sequences {an}, {bn} with bn > 0, an = O(bn)
means that there exists a constant N > 0 such that
|an|/bn ≤N for all n > 0, and an = o(bn) means
that an/bn →0 as n →∞.
Assumption 1 The regressor φk is Fk-measurable and
bounded. Also, there is a known constant L > 0 such
that ∥θ∥1 ≤L.
Under Assumption 1, there exists a positive bounded
sequence {Mk} such that
max
1≤i≤2m1 (3+3m2) |φk,i| ≤Mk
for all k ≥0, where φk,i is the i-th component of φk
and Mk is bigger than the natural constant e. The time-
varying bound Mk will be used in the subsequent design
of the algorithm.
Assumption 2 The thresholds Lk and Nk deﬁned in (3)
are Fk-measurable, uniformly bounded with respect to
the sampling path, and strictly ordered, satisfying Lk <
Nk for all k.
Note that Assumption (2) is quite general for ensuring
the saturated property of the function Sk(·).
Assumption 3 The random noise {wk, Fk} is a mar-
tingale difference sequence, and satisﬁes
sup
k≥0
E

|wk+1|4|Fk

< ∞,
a.s.
(11)
And the conditional expectation function Gk(x)
≜
E[Sk(x+wk+1)|Fk] is differentiable, and its derivation
function G
′
k(x) satisﬁes
0 < g =
inf
|x|<C,k≥0 G
′
k(x) ≤
sup
|x|<C,k≥0
G
′
k(x) = g < ∞,
(12)
where C > 0 is any constant.
For convenience of analysis, we also introduce the fol-
lowing notations used in the subsequent sections:
˜θk = θ −θk,
(13)
vk+1 = zk+1 −Gk(φτ
kθ),
(14)
ψk = Gk(φτ
kθ) −Gk
 φτ
kθk

,
(15)
gk =
inf
|x|≤max{MkL,Mk∥θk∥1} G
′
k(x),
(16)
¯gk =
sup
|x|≤max{MkL,Mk∥θk∥1}
G
′
k(x),
(17)
where θk, k ≥0 is the estimate for θ, which is obtained
by our algorithm introduced below.
B. A Gradient-Based Two-Stage Algorithm
Now, we propose our two-stage gradient algorithm,
the details of this algorithm are outlined in Algorithm 1
below.
In Algorithm 1, the Adam algorithm in the sec-
ond stage is based on the following loss for the h-
th batch of training data during the l-th epoch (h =
1, · · · , ⌊n/T ⌋, l = 1, · · · , N):
1
T
hT
X
k=(h−1)T +1
|z(l)
k −ˆz(l)
k |
z(l)
k
+ γ

1
T
hT
X
k=(h−1)T +1
ˆe(l)
k −¯e
,
(25)
where
z(l)
k
denotes
the
actual
sentence
of
the
k-th
case
in
the
l-th
epoch,
and
ˆz(l)
k
= Sk

[ak + ˆb(l)
h−1x(1)
k
+ ˆc(l)
h−1x(2)
k ]× Qm1
i=1
 1 +
(ˆp(i)
h−1)(l)v(i)
k

×

1 + Pm2
j=1(ˆq(j)
h−1)(l)u(j)
k
+ ˆe(l)
k

denotes the corresponding predictive sentence, ˆe(l)
k
=
ˆΓ(l)
h−1σ

ˆB(l)
h−1σ

ˆA(l)
h−1ηk + (ˆb(1)
h−1)(l)
+ (ˆb(2)
h−1)(l)
+
(ˆb(3)
h−1)(l) denotes the corresponding predictive time-
varying
bias
term,
where
ˆb(l)
h−1,
ˆc(l)
h−1,
(ˆp(i)
h−1)(l),
(ˆq(j)
h−1)(l), ˆΓ(l)
h−1, ˆB(l)
h−1, ˆA(l)
h−1, (ˆb(1)
h−1)(l), (ˆb(2)
h−1)(l) and
(ˆb(3)
h−1)(l) are the estimates of the true parameters in the
model (1) after training on the (h −1)-th batch data
in the l-th epoch. ¯e is the ASG-based estimate of the

5
Algorithm 1 Two-Stage Learning (TSL) Algorithm
1: Input: The temporally ordered training dataset D1 = {φk, zk+1}n−1
k=0 , the held-out testing dataset D2 =
{φk, zk+1}n2
k=1, the arbitrarily chosen initial estimates θ0 ∈Rp×1, ˆΓ0 ∈R1×m, ˆB0 ∈Rm×m, ˆA0 ∈Rm×m3,
ˆb(1)
0
∈Rm, ˆb(2)
0
∈Rm, ˆb(3)
0
∈R, the epoch count of N, the batch size T (T ≤n), hyper-parameters α > 1,
η1 > 0, ε > 0, µ ∈(0, 1] , β1 ∈(0, 1) and β2 ∈(0, 1).
2: Output: The ﬁnal parameter estimate ˆΘ(N)
⌊n/T ⌋, the predictive sentences for sentencing cases in D2.
3: # Stage 1: ASG-based initialization for the unknown mechanistic parameter in the model (1).
4:
for k = 0 to n −1 do
θk+1 = θk +
µ¯gkφk
r
1
2
k log
α
2 rk
zk+1 −Gk(θT
k φk),
(18)
rk = M4p2 +
k
X
i=1
¯g2
i ∥φi∥2, r0 = M4p2,
(19)
5:
end for
6:
Calculate the parameter estimates of the mechanistic part in (1) and the bias term by using the estimate θn:
b0 = θ(2m1 (1+m2)+1)
n
θ(1)
n
,
c0 = θ(2m1 (2+2m2)+1)
n
θ(1)
n
,
¯e = θ(1)
n
−1,
(20)
pi0 = θ(i+1)
n
θ(1)
n
,
qj0 = θ(2m1 j+1)
n
,
(21)
7: # Stage 2: Adam-based estimation for all unknown parameters in the model (1).
8:
for l = 1 to N do
9:
if l = 1 then
ˆΘ(1)
0
= [b0, c0, p10, · · · , pm10, q10, · · · , qm20, vec(ˆΓ0)T , vec( ˆB0)T , vec( ˆ
A0)T , (ˆb(1)
0
)T , (ˆb(2)
0 )T ,ˆb(3)
0 ]T ,
m(1)
0
= 0, v(1)
0
= 0.
10:
else
ˆΘ(l)
0
= ˆΘ(l−1)
⌊n/T ⌋, m(l)
0
= m(l−1)
⌊n/T ⌋, v(l)
0
= v(l−1)
⌊n/T ⌋.
11:
end if
12:
for h = 1 to ⌊n/T ⌋do
ˆΘ(l)
h
= ˆΘ(l)
h−1 +
η1
ε +
s
v(l)
h
1−βh
2
·
m(l)
h
1 −βh
1
,
(22)
m(l)
h
= β1m(l)
h−1 + (1 −β1)g(l)
h ,
(23)
v(l)
h
= β2v(l)
h−1 + (1 −β2)[g(l)
h ]2,
(24)
13:
end for
14:
end for
15: Calculate the predictive sentences in D2 by using the ﬁnal estimate ˆΘ(N)
⌊n/T ⌋.
averaged bias term obtained by (20). The regularization
coefﬁcient γ is determined to guide the neural network
output towards matching the averaged bias term.
Moreover, as for other related notations in Algo-
rithm 1, p ≜2m1(3 + 3m2) in (19) is the dimension
of unknown parameters θ deﬁned in (5), θ(ξ)
n
(ξ =
1, · · · , p) in (20)-(21) is the ξ-th component of the
estimate θn. g(l)
h
in (23)-(24) denotes the negative gra-
dient of the loss function (25) evaluated at ˆΘ(l)
h−1 =
ˆb(l)
h−1, ˆc(l)
h−1, (ˆp(1)
h−1)(l), · · · , (ˆp(m1)
h−1 )(l), (ˆq(1)
h−1)(l), · · · ,
(ˆq(m2)
h−1 )(l), vec(ˆΓ(l)
h−1)T , vec( ˆB(l)
h−1)T , vec( ˆA(l)
h−1)T ,

(ˆb(1)
h−1)(l)T ,

(ˆb(2)
h−1)(l)T , (ˆb(3)
h−1)(l)T with vec(·) de-
noting the vectorization of a matrix. Besides, the addi-
tion, multiplication, and division operations in the Adam
algorithm are performed element-wise.
The essence of Algorithm 1 is that the ASG algorithm
in the ﬁrst stage generates parameter estimates close to
the prediction-error minimizer for the mechanism model,
which are then used to initialize the Adam algorithm
for the hybrid model in the second stage, thereby en-
hancing overall sentencing prediction performance. It is
worth noting that, in order to ensure that the neural
network serves only as a compensatory component for

6
the mechanistic model, the loss function (25) of the
Adam algorithm incorporates a penalty on the deviation
of the averaged neural network output from the bias term
¯e estimated by the ASG algorithm in the ﬁrst stage.
Remark 4 The ASG algorithm speciﬁed in (18)-(19) is
an adaptive algorithm, i.e., the algorithm updates the pa-
rameter estimate θk+1 using only the current online data
{φk, zk+1} and the current estimate θk. The algorithm
is motivated by the classical ASG algorithm studied in
[20]- [22], but achieves a faster theoretical convergence
rate of the averaged regret due to the use of a larger
adaptation rate, which will be proven in the subsequent
theoretical analysis.
Remark 5 The estimate θk obtained by the ASG-type
algorithm (18)-(19) is bounded. Moreover, according to
Assumption 3 and the deﬁnition of gk, ¯gk, it follows that
inf
k≥0{gk} > 0,
sup
k≥0
{¯gk} < ∞.
(26)
Remark 6 For the proposed TSL algorithm, in Stage 1,
the ASG method is proposed since it can provide good
initial estimates for prediction in Stage 2. Speciﬁcally, the
predictor based on the ASG method possesses a global
asymptotic convergence property, as established in Sec-
tion IV below, thereby providing good initial parameter
estimates close to the prediction-error minimizer for the
mechanism model—a guarantee typically absent in most
machine learning algorithms. Moreover, the expanded
regression vector in (4) is very high-dimensional in
sentencing prediction, making stochastic-gradient–type
methods particularly suitable for handling such cases,
since the computational load of the gradient algorithms
is much lower than that of the Newton-type algorithms.
In Stage 2, once the bias term e is replaced by a neural
network, the Adam algorithm is applied to improve the
overall predictive capability of the model, as Adam
is widely recognized as one of the most appropriate
optimization algorithms for neural networks [33]. The
advantages of using Adam are also conﬁrmed by the
experimental results presented in Section V.
IV. PREDICTION THEORY OF THE ASG ALGORITHM
In this section, we establish the global asymptotic con-
vergence of the ASG-based predictor without requiring
any excitation data conditions.
To facilitate the theoretical analysis, we ﬁrst introduce
the corresponding best predictor. By (10) and the deﬁni-
tion of Gk(·), one can deduce that the best prediction of
zk+1 given Fk in the mean square sense is as follows:
E[zk+1|Fk] = Gk(θT φk).
(27)
Since θ is unknown a priori, we replace the unknown
parameter θ by its estimates θk and deﬁne the adaptive
prediction for zk+1 at time k as follows:
ˆzk+1 = Gk(θT
k φk).
(28)
From the above, we deﬁne the difference between the
best prediction and the adaptive prediction for the satu-
rated sentence zk+1 as “regret”, which can be expressed
as follows:
Rk = [E[zk+1|Fk] −ˆzk+1]2 = [ψk]2.
(29)
Naturally, we expect the regret for zk+1 to decrease as
k increases, ideally vanishing to zero. The following
theorem shows that this can be achieved in the averaged
sense without requiring any data excitation condition,
such as the i.i.d. condition, etc.
Theorem 1 Under Assumptions 1-3, the accumulated
regrets have the following upper bounds:
n−1
X
k=0
Rk = o

n
1
2 log
α
2 n

,
a.s.
(30)
where rk and α are deﬁned in Algorithm 1.
Corollary 1 If the bounded condition on φk,i in As-
sumption 1 is relaxed to |φk,i| ≤Mkǫ, 0 < ǫ < 1
2 for any
1 ≤i ≤p, and ¯gk and rk in the algorithm (18)-(19) are
replaced by ¯gk =
sup
|x|≤max{LMkǫ,Mkǫ∥θk∥1}
G
′
k(x) and
rk = M 4k4ǫp2 + Pk
i=1 ¯g2
i ∥φi∥2, respectively, then the
accumulated regrets possess the following upper bound:
n−1
X
k=0
Rk = o

n
1
2 +ǫ log
α
2 n

,
a.s.
(31)
It can been seen that the averaged regrets 1
n
Pn−1
k=0 Rk in
both Theorem 1 and Corollary 1 will converge to zero
almost surely as n →∞. The proofs of the above results
will be shown in the Appendix below.
V. SENTENCING EXPERIMENTS
In this section, we demonstrate the superiority of the
proposed model and algorithm based on a real-world CII
dataset. First, the experimental settings and the baseline
models for comparison are described, followed by a
detailed analysis of the results.
A. Experimental Settings
We conduct judicial sentencing experiments based on
an available CII real-world dataset obtained from China
Judgements Online3, which contains 87,588 original
minor injury judgment documents, as well as 9,228
original serious injury judgment documents from the
3https://wenshu.court.gov.cn/

7
period 2019 to 2024. These data are processed through
feature extraction and quantiﬁcation to facilitate subse-
quent experiments.
We provide a detailed explanation of the output bound-
ary selection and feature interpretation for the SMNN
model. Regarding the output boundaries, Article 234 of
Chinese Criminal Law prescribes a ﬁxed-term imprison-
ment ranging from six months to three years for minor
injury cases and three years to ten years for serious injury
cases, so we let the statutory penalty ranges Lk ≡6,
Nk ≡36 and Lk ≡36, Nk ≡120 for minor and serious
cases in (3), respectively (Unit: Month). According to the
sentencing guidelines for the CII, penalty-determining
factors x(i)
k , i = 1, 2 in the model (1) represent the
number of seriously and minorly injured victims, re-
spectively. Primary sentencing adjust factors v(i)
k , i =
1, · · · , 13 in the model (1) include “juveniles aged 16–18
years,” “juveniles aged 12–16 years,” “elderly individuals
over 75 years of age,” “mentally disordered persons
with diminished criminal responsibility,” “deaf-mute and
blind individuals,” “excessive self-defense,” “excessive
act of necessity,” “preparatory acts for crime,” “attempted
crime,” “voluntary cessation of crime,” “accessories,”
“coerced accomplices,” and “instigators.” Other sentenc-
ing adjust factors u(j)
k , j = 1, · · · , 22 in the model
(1) include “grade I serious injury cases,” “grade II
serious injury cases,” “grade I minor injury cases,” “grade
II minor injury cases,” “voluntary surrender,” “confes-
sion,” “criminal reconciliation,” “active compensation,”
“victim pardon,” “principal offender,” “crimes targeting
vulnerable groups,” “victim’s contributory fault,” “civil
dispute-related offenses,” “recidivism,” “prior criminal
records,” “ﬁrst-time offenders,” “courtroom confession,”
“plea agreement acceptance,” “armed affray,” “mutual
combat,” “meritorious service,” and “probation,” among
others.
The prediction accuracy metric adopts a relative accu-
racy with discretion (RAD), which is deﬁned as follows:
RAD = 1 −1
n2
n2
X
k=1
˜zk
zk
I(˜zk > max{20%zk, 2}), (32)
where ˜zk = |zk−ˆzk| with zk denoting the actual sentence
for the k-th judicial case, and ˆzk representing its pre-
dicted value. n2 is the total number of criminal cases in
the testing set. The threshold max{20%zk, 2} represents
the degree of adjustment allowed during the judges’
sentencing process, indicating the judicial discretion.
Here the component 20%zk is based on the sentencing
guidelines 4, while the ﬁxed value 2 is derived from
interviews with judges and reﬂects practical discretion
in real-world judicial decision-making. Compared to the
prediction accuracy metrics employed in previous related
4See https://www.court.gov.cn/.
studies (e.g., classiﬁcation metrics in [1]- [2], [6]), the
metric (32) is both legally compatible and practically
reasonable.
Moreover, the sentencing starting point ak in the
model (1) is set as the lower bound of the sentencing
starting range prescribed in law based on a series of
comparative experiments(see [11]). The dataset is split
into a training set and a testing set with a ratio of
4 : 1. Some hyper-parameters for the ASG algorithm
are conﬁgured as follows: the constant α in Algorithm 1
is set to 1.02, µ and ¯gk are set to 1, and the random
noise sequence {wk} is assumed to be i.i.d. following a
normal distribution N(0, 25).
Additionally, other common hyper-parameters for the
Adam algorithm involved in relevant experiments are set
as follows: a batch size of 245, an epoch count of 30, a
learning rate of 0.001, exponential decay rates for the ﬁrst
and second moment estimates of β1 = 0.9, β2 = 0.999,
a smoothing coefﬁcient of ε = 10−8. The hidden layer is
conﬁgured with 128 nodes. Importantly, during training
across different epochs, data are fed in chronological
order without shufﬂing to preserve the temporal structure
inherent in the dataset. The regularization coefﬁcient γ
in (25) is set to 0.2 and 1.4 for minor and serious
injury cases respectively, based on comparative exper-
iments of prediction accuracy. All experiments involving
random initialization are conducted 10 times, with the
best-performing initialization selected to optimize overall
performance.
B. Baseline Models
1)
SM Model with ASG-Based Algorithm: First, we
consider the SM model (see [31]), where the bias term
in (1) is a ﬁxed unknown constant e. Speciﬁcally, the
model is as follows.
zk+1 =Sk
 h
ak + bx(1)
k
+ cx(2)
k
i
×
m1
Y
i=1
(1 + piv(i)
k )
×

1 +
m2
X
j=1
qju(j)
k
+ e

+ wk+1

.
(33)
The proposed ASG algorithm (18)–(19) will be used for
optimization based on the model (33).
2) SNN Model with Adam-Based Algorithm: Second,
we conduct experiments utilizing a saturated neural net-
work (SNN) model (see [12]) speciﬁed as follows.
zk
=Sk
h
W (3)σ
 W (2)σ(W (1)Xk + B(1)) + B(2)
+ B(3)i
,
(34)

8
where W (i), B(i), i = 1, 2, 3 are unknown weighting
parameters, and Xk is the input data composed of various
sentencing factors. Other notations are consistent with
those deﬁned in Section II. The Adam algorithm (22)-
(24) will be used for optimization based on the model
(34).
3) SMNN Model with Adam-Based Algorithm: Third,
we train our SMNN model (1) by Adam optimizer
(22)–(24) with all the parameters being initialized ran-
domly.
4)
SMNN Model with TSL Algorithm: Fourth, we
train the SMNN model (1) by our TSL optimizer de-
scribed in Algorithm 1, where the mechanistic parame-
ters are initialized using the ASG algorithm in the ﬁrst
stage, and other parameters are initialized randomly.
C. Comparison Experiments on Sentencing Prediction
To further improve the sentencing prediction accuracy
for CII in the existing literature (e.g., [11], [31], [32]),
we perform comparison experiments to demonstrate the
improved accuracy of our SMNN model and the TSL
algorithm compared to the above baseline methods using
the same available data.
Figs. 1-2 illustrate the prediction accuracy trends
of our method in comparison to other related known
methods on the testing set for minor and serious cases,
respectively. It can be shown that:
• The SMNN model with the ASG-Adam algorithm
consistently achieves the highest prediction accu-
racy of 86.66% and 95.25% for minor and serious
cases respectively, surpassing the SM model with
the ASG algorithm (80.69%; 90.59%) and the SNN
model with the Adam algorithm (85.66%; 94.38%).
This demonstrates the advantages of combining
both the SM model with the NN model as well
as integrating the ASG algorithm with the Adam
algorithm, allowing for more accurate sentencing
prediction.
• The SMNN model with our ASG-Adam algorithm
outperforms the same model with the Adam algo-
rithm with random initialization (86.46%; 93.29%),
which demonstrates that our ASG algorithm (18)-
(19) in the ﬁrst stage provides good initial parameter
estimates for the Adam optimizer (22)-(24) in the
second stage, thereby improving prediction accu-
racy. This advantage stems from the ASG-based
initialization, which guides the optimization process
toward the global error minimum. In contrast, ran-
dom initialization requires exploring a broader solu-
tion space and is more prone to local error minima,
often resulting in inferior prediction accuracy.
2000
4000
6000
8000
10000
12000
14000
16000
Data Size
0.78
0.79
0.8
0.81
0.82
0.83
0.84
0.85
0.86
0.87
Prediction Accuracy
The trend of average sentencing accuracy for different methods in the  minor testing set.
SM + ASG
SNN + Adam
SMNN + Adam
SMNN + ASG-Adam
Fig. 1.
The trend of average sentencing accuracy of minor cases for
different methods in the testing set.
200
400
600
800
1000
1200
1400
1600
1800
Data Size
0.88
0.89
0.9
0.91
0.92
0.93
0.94
0.95
0.96
Prediction Accuracy
The trend of average sentencing accuracy for different methods in the  serious testing set.
SM + ASG
SNN + Adam
SMNN + Adam
SMNN + ASG-Adam
Fig. 2.
The trend of average sentencing accuracy of serious cases for
different methods in the testing set.
VI. CONCLUSION
Motivated by the imperative demand in judicial prac-
tice for highly accurate and reliable sentencing pre-
diction, this paper proposed a SMNN hybrid model,
which integrates the sentencing logic model with a
neural network. The ASG algorithm is applied to update
the parameters of the mechanistic component within
the SMNN model, after which the Adam algorithm is
utilized to further optimize the SMNN model with the
aim of enhancing predictive accuracy. Both theoretical
analysis and sentencing experiments demonstrate that the
estimates produced by the ASG algorithm in the ﬁrst
stage can provide good enough initial values for the
implementation of the prediction algorithm in the second
stage. Moreover, sentencing experiments also reveal that
the neural networks introduced in the hybrid model is
indeed helpful for improving the prediction accuracy in

9
the second stage. For future investigation, it would be
interesting to establish the global convergence of the
Adam algorithm in the second stage, and to apply our
prediction algorithms to other judicial crimes other than
the intentional injury studied here.
VII. APPENDIX
Lemma 1 ( [23] Theorem 1.3.2)
Let {fk, Fk} and
{αk, Fk} be two non-negative adapted sequences. If
E[fk+1|Fk] ≤fk + αk, a.s. for any k ≥1 and
P∞
i=1 αi < ∞, a.s., then fk will converge to a ﬁnite
limit a.s.
Lemma 2 ( [23] Theorem 1.2.15)
Let Dk = C +
Pk
j=1 dj, dj ≥0 and D0 = C with C > 1 being any
constant, then we have
∞
X
j=1
dj
Dj logα Dj
< ∞, ∀α > 1.
(35)
Lemma 3 ( [25])
Let {ωn, Fn} be a martingale dif-
ference sequence and {fn, Fn} an adapted sequence. If
sup
n E [|ωn+1|α | Fn] < ∞, a.s.
(36)
for some α ∈(0, 2], then as n →∞, we have ∀η > 0,
n
X
i=0
fiωi+1 = O

sn(α) log
1
α +η (sα
n(α) + e)

a.s.,
(37)
where sn(α) =
 nP
i=0
|fi|α
 1
α
.
Inspired by the analysis ideas mentioned in [23], [17],
and [18], etc, the proof of Theorem 1 is as follows:
Proof of Theorem 1. By the algorithm (18)-(19) and
the differential mean value theorem, we have
˜θk+1 = ˜θk −
µ¯gkφk
r
1
2
k log
α
2 rk
h
G
′
k(ξk)φT
k ˜θk + vk+1
i
=
 
I −µ¯gkG
′
k(ξk)φkφT
k
r
1
2
k log
α
2 rk
!
˜θk −
µ¯gkφk
r
1
2
k log
α
2 rk
vk+1,
(38)
where ξk ∈(min{θτφk, θτ
kφk}, max{θτφk, θτ
kφk}). By
this and the elementary inequality we have
˜θT
k+1˜θk+1
=
( 
I −µ¯gkG
′
k(ξk)φkφT
k
r
1
2
k log
α
2 rk
!
˜θk −
µ¯gkφk
r
1
2
k log
α
2 rk
vk+1
)T
( 
I −µ¯gkG
′
k(ξk)φkφT
k
r
1
2
k log
α
2 rk
!
˜θk −
µ¯gkφk
r
1
2
k log
α
2 rk
vk+1
)
=˜θT
k ˜θk −2
µ¯gkG
′
k(ξk)
h
˜θT
k φk
i2
r
1
2
k log
α
2 rk
−2 µ¯gk˜θT
k φk
r
1
2
k log
α
2 rk
vk+1
+
µ2¯g2
k[G
′
k(ξk)]2∥φk∥2 h
˜θT
k φk
i2
rk logα rk
+ 2µ2¯g2
kG
′
k(ξk)∥φk∥2˜θT
k φk
rk logα rk
vk+1 + µ2¯g2
k∥φk∥2
rk logα rk
v2
k+1
≤˜θT
k ˜θk −2
µ¯gkG
′
k(ξk)
h
˜θT
k φk
i2
r
1
2
k log
α
2 rk
−2 µ¯gk˜θT
k φk
r
1
2
k log
α
2 rk
vk+1
+ (1 + b)
µ2¯g2
k[G
′
k(ξk)]2∥φk∥2 h
˜θT
k φk
i2
rk logα rk
+

1 + 1
b
 µ2¯g2
k∥φk∥2
rk logα rk
v2
k+1,
(39)
where 0 < b < 1 is a constant. since S
′
k(x) ≤1, ∀x ∈
R implies 0 ≤¯gkG
′
k(ξk) ≤1, summing up both sides
of (39) from k = 0 to n −1, and noticing ∥φk∥2 <
r
1
2
k log
α
2 rk for all k ≥0, we know that
∥˜θn∥2 + (1 −b)
n−1
X
k=0
µ¯gkG
′
k(ξk)
h
˜θT
k φk
i2
r
1
2
k log
α
2 rk
=O
 n−1
X
k=0
¯gk˜θT
k φk
r
1
2
k log
α
2 rk
vk+1
!
+ O
 n−1
X
k=0
¯g2
k∥φk∥2
rk logα rk
v2
k+1
!
.
(40)
Now we analyze the RHS of (40) term by term. Note
that by (11), the elementary inequality 2ab ≤a2 + b2
and the inequality E4[|x||Fk] ≤E[|x|4|Fk], we have
E

|vk+1|4 | Fk

=O

E
Sk(θτφk + wk+1) −Sk(θτφk)
4Fk

+O

E
Sk(θτφk) −E[Sk(θτφk + wk+1)
Fk]
4Fk

=O

E
Sk(θτφk + wk+1) −Sk(θτφk)
4Fk

+ O(1)
=O

E

|wk+1|4Fk

+ O(1) = O(1),
a.s.
(41)
Note that by the deﬁnition of vk+1, we have
E (vk+1 | Fk)
=E [Sk (θτφk + wk+1) | Fk]
−E [E [Sk (θτφk + wk+1) | Fk] | Fk] = 0.
(42)
So by (41), (42) and Lemma 3, we have
n−1
X
k=0
¯gk˜θT
k φk
r
1
2
k log
α
2 rk
vk+1 = o



n−1
X
k=0
¯g2
k
h
˜θT
k φk
i2
r
1
2
k log
α
2 rk


+ O(1), a.s.
(43)

10
Moreover, by (41), (42) and Lemma 2 and Lemma 3, we
have
n−1
X
k=0
¯g2
k∥φk∥2
rk logα rk
v2
k+1
≤
n−1
X
k=0
¯g2
k∥φk∥2
rk logα rk

v2
k+1 −E[v2
k+1|Fk]

+ sup
k≥0
E[v2
k+1|Fk] ·
n−1
X
k=0
¯g2
k∥φk∥2
rk logα rk
=O
 n−1
X
k=0
¯g2
k∥φk∥2
rk logα rk
!
+ O(1)
=O(1),
a.s.
(44)
Combining (43)-(44) with (40), we have
n−1
X
k=0
¯gkG
′
k(ξk)
h
˜θT
k φk
i2
r
1
2
k log
α
2 rk
= O(1),
a.s.
(45)
Note that since φk is bounded, we have rk = O(k).
Moreover, if rk →∞as k →∞, then we have by (45)
and the Kronecker Lemma, we obtain
n−1
X
k=0
Rk = o

n
1
2 log
α
2 n

,
a.s.
(46)
Otherwise, if rk ↛∞, then denominator of (45) is
bounded, and (46) is also satisﬁed.
Proof of Remark 5. By (18), we have
˜θT
k+1˜θk+1 =
"
˜θk −
µ¯gkφk
r
1
2
k log
α
2 rk

zk+1 −Gk
 φT
k θk

#T
"
˜θk −
µ¯gkφk
r
1
2
k log
α
2 rk

zk+1 −Gk
 φT
k θk

#
.
(47)
Set sup
k≥0
max{|Lk|, |Nk|} ≤U < ∞, from (14) and (15)
we know that
˜θk+1

2
=
˜θk

2
−2
µ¯gk
r
1
2
k log
α
2 rk

zk+1 −Gk
 φT
k θk
 ˜θT
k φk
+ µ2¯g2
k

zk+1 −Gk
 φT
k θk
2
rk logα rk
∥φk∥2
≤
˜θk

2
−2
µ¯gk
r
1
2
k log
α
2 rk
[vk+1 + ψk] ˜θT
k φk
+
4U 2¯g2
k
rk logα rk
∥φk∥2 .
(48)
Take the conditional expectation for both sides of
(48), and by (42) and differential mean value theorem,
we know that there exists a random variable ξk
∈
(min{θτφk, θτ
kφk}, max{θτφk, θτ
kφk}) such that
E
˜θk+1

2
|Fk

≤
˜θk

2
−2µ¯gkG
′
k(ξk)(˜θT
k φk)2
r
1
2
k log
α
2 rk
+ 4U 2¯g2
k ∥φk∥2
rk logα rk
≤
˜θk

2
+ 4U 2¯g2
k ∥φk∥2
rk logα rk
.
(49)
Moreover, by Lemma 2 we obtain
nP
k=1
¯g2
k∥φk∥2
rk logα rk = O(1),
by this, (49) and Lemma 1, we know that there exists a
constant S ≥0 such that ∥˜θk∥→S < ∞as k →∞.
Combining this with the boundedness of θ, we can easily
obtain the estimate θk is bounded.
Proof of Corollary 1. Note that ∥φk∥2 ≤r
1
2
k log
α
2 rk,
similar to the analysis of (40) and (43)-(44), we have
n−1
X
k=0
¯gkG
′
k(ξk)
h
˜θT
k φk
i2
= o(n
1
2 +ǫ log
α
2 n), a.s.,
(50)
which implies that (31) holds.
REFERENCES
[1] Kim, Y. “Convolutional neural networks for sentence classiﬁ-
cation,” Proceedings of Conference on Empirical Methods in
Natural Language Processing, 2014, pp. 1746–1751.
[2] Zhong, H., Guo, Z., Tu, C., et al. “Legal judgment prediction via
topological learning,” Proceedings of Conference on Empirical
Methods in Natural Language Processing, 2018, pp. 3540–3549.
[3] Yang, W., Jia, W., Zhou, X., et al. “Legal judgment predic-
tion via multi-perspective bi-feedback network,” Proceedings of
IEEE Joint International Information Technology and Artiﬁcial
Intelligence Conference, 2019, pp. 4085–4091.
[4] Dong, Q., and Niu, S. “Legal judgment prediction via relational
learning,” Proceedings of International ACM SIGIR Conference
on Research and Development in Information Retrieval, 2021,
pp. 983–992.
[5] Xu, N., Wang, P., Chen, L., et al. “Distinguish confusing law
articles for legal judgment prediction,” Proceedings of the An-
nual Meeting of the Association for Computational Linguistics,
2020, pp. 3086–3095.
[6] Yue, L., Liu, Q., Jin, B., et al. “Neurjudge: A circumstance-
aware neural framework for legal judgment prediction,” Pro-
ceedings of the International ACM SIGIR Conference on Re-
search and Development in Information Retrieval, 2021, pp.
973–982.
[7] Zhong, H., Wang, Y., Tu, C., et al. “Iteratively questioning
and answering for interpretable legal judgment prediction,”
Proceedings of the AAAI Conference on Artiﬁcial Intelligence,
2020, pp. 1250–1257.
[8] Yang, S., Tong, S., Zhu, G., et al. “MVE-FLK: A multi-task
legal judgment prediction via multi-view encoder fusing legal
keywords,” Knowledge-Based Systems, 2022, 239: 107960.
[9] Zhao, Q., Gao, T., and Guo, N. “LA-MGFM: A legal judgment
prediction method via semi-enhanced graph neural networks
and multi-graph fusion mechanism,” Information Processing &
Management, 2023, 60(5): 103455.
[10] Li, L., Liu, D., Zhao, L., et al. “Evidence mining for inter-
pretable charge prediction via prompt learning,” IEEE Transac-
tions on Computational Social Systems, 2024, 11(4): 4556–4566.

11
[11] Wang, F., Zhang, L., & Guo, L. “Applications of nonlinear
recursive identiﬁcation theory in the analyses of sentencing
data,” Scientia Sinica Informationis, 52(10), 1837–1852, 2022.
[12] Dai, R., Wang, F., & Guo, L. “A New Adaptive Prediction
Algorithm for Judicial Sentencing with Empirical Studies,”
Journal of Systems Science and Complexity, 38(1), 3-20, 2025.
[13] Devlin, J., Chang, M., Lee, K., et al. “BERT: Pre-training of
deep bidirectional transformers for language understanding,”
Proceedings of Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language
Technologies, 2019, pp. 4171–4186.
[14] Loshchilov, I., Hutter, F. “Decoupled Weight Decay Regular-
ization,” Proceedings of International Conference on Learning
Representations, 2019.
[15] Kingma, D. P., and Ba, J. “Adam: A method for stochastic opti-
mization,” Proceedings of International Conference on Learning
Representations (ICLR), 2015.
[16] Zeiler, M. D. “Adadelta: an adaptive learning rate method,” arXiv
preprint arxiv:1212.5701, 2012.
[17] Zhang, L., & Guo, L. “Adaptive identiﬁcation with guaran-
teed performance under saturated observation and non-persistent
excitation,” IEEE Transactions on Automatic Control, 69(3),
1584–1599, 2023.
[18] Zheng, X., & Guo, L. “L1-based adaptive identiﬁcation with
saturated observations,” IEEE Transactions on Automatic Con-
trol, 70(9), 5836-5847, 2025.
[19] Zhang, L., & Guo, L. “Adaptive tracking control with binary-
valued output observations,” arXiv preprint, arXiv:2411.05975,
2024.
[20] Chen, H. F., & Guo, L. “Consistency of parameter estimates for
discrete-time linear systems,” Journal of Systems Science and
Mathematical Sciences, 5(2), 81–93, 1985.
[21] Chen, H. F., & Guo, L. “Strong consistency of recursive iden-
tiﬁcation without persistent excitation condition,” Acta Mathe-
maticae Applicatae Sinica, 2(2), 133–145, 1985.
[22] Chen, H. F., & Guo, L. “The limit of stochastic gradient algo-
rithm for identifying systems excited non-persistently,” Kexue
Tongbao (Science Bulletin), 6–9, 1986.
[23] Guo, L. Time-varying stochastic systems: Stability and adaptive
theory (2nd ed.), Science Press, Beijing, China, 2020.
[24] Chen, H. F. Stochastic approximation and its applications,
Kluwer Academic Publishers, Dordrecht, Netherlands, 2002.
[25] Chen, H. F., & Guo, L. Identiﬁcation and stochastic adaptive
control, Birkh¨auser, Boston, MA, 1991.
[26] Sun, J., Kim, Y. W., & Wang, L. “Aftertreatment control
and adaptation for automotive lean burn engines with HEGO
sensors,” International Journal of Adaptive Control and Signal
Processing, 18(2), 145–166, 2008.
[27] Appadwedula, S., Veeravalli, V. V., & Jones, D. L. “Decentral-
ized detection with censoring sensors,” IEEE Transactions on
Signal Processing, 56(4), 1362–1373, 2008.
[28] Tobin, J. “Estimation of relationships for limited dependent
variables,” Econometrica: Journal of the Econometric Society,
26(1), 24–36, 1958.
[29] Jeon, M. S., & Lee, J. H. “Estimation of willingness-to-pay
for premium economy class by type of service,” Journal of Air
Transport Management, 84, 28–35, 2020.
[30] Clark, T. G., Bradburn, M. J., Love, S. B., & Altman, D. G.
“Survival analysis part I: Basic concepts and ﬁrst analyses,”
British Journal of Cancer, 89(2), 232–238, 2003.
[31] Guo, L. “The Integration of Law and Cybernetics in the Digital
Age: An Exploration of Sentencing Research,” The 3rd Annual
Conference on Computational Law, Weihai, China, October 13,
2024.
[32] Jin, Y., Zheng, X., & Guo, L. “Adaptive sentencing prediction
with
guaranteed
accuracy
and
legal
interpretability,”
arXiv
preprint
arXiv:2505.14011,
2025.
Available:
https://doi.org/10.48550/arXiv.2505.14011
[33] Schmidt, R. M., Schneider, F., & Hennig, P. “Descending
through a crowded valley—Benchmarking deep learning opti-
mizers,” Proceedings of the International Conference on Ma-
chine Learning, PMLR, 2021, pp. 9367-9376.
