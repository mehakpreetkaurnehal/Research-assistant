Prepared for submission to JCAP
Deep Learning Analysis of Ions
Accelerated at Shocks
P. Swierc,a D. Caprioli,a,b L. Orusa,c,d and M. Cernetica
aDepartment of Astronomy & Astrophysics, University of Chicago,
5640 S Ellis Ave, Chicago IL, 60637, USA
bEnrico Fermi Institute, University of Chicago,
5640 S Ellis Ave, Chicago IL, 60637, USA
cDepartment of Astronomy and Columbia Astrophysics Laboratory, Columbia University,
538 West 120th Street, New York NY, 10027, USA
dDepartment of Astrophysical Sciences, Princeton University,
4 Ivy Ln, Princeton NJ, 08544, USA
E-mail: pswierc@uchicago.edu, caprioli@uchicago.edu, luca.orusa@princeton.edu,
cernetic@uchicago.edu
Abstract. We study the application of deep learning techniques to the analysis and clas-
sification of ions accelerated at collisionless shocks in hybrid (kinetic ions–fluid electrons)
simulations. Ions were classified as thermal, suprathermal, or nonthermal, depending on the
energy they achieved and the acceleration regime they fell under. These classifications were
used to train deep learning models to predict which particles are injected into the accelera-
tion process with high accuracy (> 90%), using only time series of the local magnetic field
they experienced during their initial interaction with the shock. An autoencoder architecture
was also tested, for which time series of various parameters were reconstructed from encoded
representations. This study shows the potential of applying machine learning techniques to
extract physical insights from kinetic plasma simulations and sets the groundwork for future
applications, including the construction of sub-grid models in fluid approaches.
arXiv:2511.17363v1  [astro-ph.HE]  21 Nov 2025

Contents
1
Introduction
1
2
Data Set
3
2.1
Perpendicular Shock Simulation
4
2.2
Parallel Shock Simulation
4
3
Machine Learning Algorithms
4
3.1
Convolutional Neural Network
4
3.2
Multilayer Perceptron with Manual Features
6
3.3
Autoencoder
6
4
Classification Experiments
7
4.1
Perpendicular Dataset Classification (SDA)
7
4.2
Parallel Dataset Classification (DSA)
10
5
Autoencoder Experiments
11
6
Discussion
15
6.1
Ion Injection at Shocks
15
6.2
Construction of Kinetic Sub-Grid Models
15
7
Conclusions
16
1
Introduction
Diffusive shock acceleration [DSA 1–4] at non-relativistic shocks is a prominent mechanism
for producing high-energy particles, hereafter, cosmic rays (CRs). DSA is a form of Fermi
acceleration, in which particles gain energy by being repeatedly scattered across a shock; its
application to supernova remnants is a promising mechanism to explain the origin of Galactic
CRs up to ≲1017eV [5–8].
DSA’s strength is its prediction of a power-law in the momentum-space distribution,
which depends only on the shock compression ratio r = ρ2/ρ1, i.e., the ratio of the downstream
to upstream plasma density. For strong shocks in a monoatomic gas with adiabatic index
γ = 5/3, r →4, which yields a momentum slope q =
3r
r−1 →4. This generally corresponds
to an energy spectrum ∝E−2 for relativistic particles. When the corrections induced by
efficient CR acceleration are included [9–14], spectra become slightly softer (q ≃2.2 −3), in
agreement with the phenomenology of shock-powered systems and the CR fluxes observed at
Earth [15, 16].
DSA is a highly non-linear process – accelerated ions drive upstream turbulence and
magnetic field amplification, which further enhances acceleration [17–19]. Therefore, studying
the process requires complex modeling that accounts for the non-linear interactions between
particles and electromagnetic fields. One approach is to simulate a collisionless plasma with
fully kinetic codes based on the Particle-In-Cell (PIC) or Vlasov methods. Such techniques
are able to include all relevant physics [e.g., 20–27], but require both electrons and ions to be
– 1 –

fully resolved. Given the order of magnitude difference in proton and electron mass, choosing
to resolve the electron scale poses computational limits on the size of the simulation, and
importantly the ability to model an ion’s long-term evolution.
To solve this, the hybrid approach [28] treats electrons as a massless neutralizing fluid,
while ions are retained as kinetic-macro particles. This approach has successfully been used
to model non-relativistic collisionless shocks and DSA [e.g., 18, 29–38].
Such simulations
have revealed that acceleration efficiency at shocks is highly dependent on the inclination of
the magnetic field θ relative to the shock normal. Specifically, DSA only occurs efficiently
for parallel to quasi-parallel shocks (i.e., θ ≲45◦) [33, 39]. Consider instead the case of a
perpendicular shock (θ = 90◦). Here, a particle encountering the shock is confined to gyrate
the ordered magnetic field and cannot otherwise enter the upstream.
However, during a
gyration the particle may still gain momentum ∝
v
vsh , where v is the initial particle velocity
and vsh is the velocity of the shock.
This form of acceleration is known as shock drift
acceleration (SDA) [40]. In the case of SDA, the self-generation of upstream turbulence is
suppressed, as a particle undergoing SDA will only reach at most one gyro-radius upstream.
If the shock magnetization is sufficiently low, the direction of the upstream magnetic field is
less important and acceleration can proceed beyond a few cycles of SDA and produce power-
law ion tails, generally steeper than DSA ones [24, 41]. In this case, 3D hybrid simulations
are needed to capture the cross-field diffusion that allows some protons to come back from
downstream [35–37]. SDA also plays a crucial role in quasi-parallel shocks, effectively acting
as a bootstrap for injection into DSA [33, 39, 42, 43].
Despite significant recent advancements, there are still unanswered questions in shock
acceleration theory – examples include a complete understanding of either electron injection
into DSA as a function of shock parameters [see 44, and references therein] or the long-term
evolution of quasi-perpendicular and oblique shocks. In both cases, increasing complexity of
simulations poses a bottleneck. For electron injection, this is due to the necessity of resolving
the electron scale. For the long-term evolution of quasi-perpendicular and oblique shocks,
this is because injection can only occur in a fully 3D simulation [36].
Additionally, state-of-the-art PIC/hybrid simulations can encompass > 1010 particles,
of which it is reasonable to track and record > 106 at a time. However, given this scale, it
is not feasible for humans to manually analyze all particle trajectories individually. While
simulations provide information such as spectra, acceleration efficiency, and magnetic field
development very easily, leveraging the well of potentially untapped information requires
original avenues, such as machine learning methodology.
In the last two decades, the use of machine learning in science has experienced significant
growth, with astrophysics being one of the prominent fields to adopt such methods [45]. Some
of the most common subfields in which it is applied include stellar [46] and galactic analysis
[e.g., 47–51], as well as cosmology [e.g., 52, 53]. It has also been used in the context of CRs,
with applications such as recreating CR energy from shower data [e.g., 54, 55] or detecting
CRs in astronomical images [56]. Machine learning has also been used in a variety of scientific
fields to emulate and speed up otherwise slow simulations [e.g., 57–60], potentially allowing
for results that were previously infeasible due to computational limits. Torralba Paz et al.
[61] considered a 2D PIC simulation of a perpendicular shock and used a convolutional neural
network to predict the maximum energy achieved by electrons during recorded tracks, starting
from the corresponding time series of momentum and electric fields.
In this work, we take the first steps towards applying machine learning to better un-
derstand ion injection and acceleration in non-relativistic shocks, considering both quasi-
– 2 –

Figure 1. Evolution of the postshock energy spectrum for the 2D parallel M = 10 shock. The
distribution begins as a Maxwellian, but over time it develops a distinct nonthermal power-law tail.
perpendicular and quasi-parallel configurations. The paper will be organized as follows –
Section 2 describes the two datasets used in the study. Section 3 describes the three types of
deep learning networks employed (two classification networks and one autoencoder network).
Section 4 details the classification experiments on both datasets and Section 5 describes the
autoencoder experiments. Finally, Section 6 discusses insight into the process of injection
into DSA gained through this study, as well as potential applications of machine learning to
shock acceleration simulation as a whole.
2
Data Set
Simulations in this study were conducted using the massively parallel hybrid code dHybridR
[62], the successor of dHybrid [31], which includes the relativistic dynamics of ions, though
all the simulations presented here are effectively in the non-relativistic regime.
Shocks are modeled by sending a supersonic flow (along −ˆx) against a reflecting wall set
at x = 0. Reflected particles then interact with the incoming ones, resulting in the formation
of a shock, which propagates away from the wall; transverse boundary conditions are periodic.
For all simulations we retain all the three spatial components of momenta and fields
and a set of normalized units are used: distance is measured in units of ion skin depth
di ≡c/ωp, where c is the speed of light and ωp ≡
p
4πne2/m is the ion plasma frequency,
with n, e, and m referring to the ion number density, charge, and mass respectively; time
is measured in units of inverse cyclotron time ω−1
c
≡mc/eB0, where B0 is the magnitude
of the initial background magnetic field; velocity and energy are normalized respectively to
the Alfvén speed vA = B0/
√
4πmn = cωc/ωp and to the kinetic energy of upstream particles
Esh ≡m(MAvA)2/2. Here MA ≡vsh/vA, where vsh is the upstream speed in the simulation
frame, is the Alfvénic Mach number. Since we consider initial Maxwellian ion distributions
with thermal speed vth = vA, we also have a sonic Mach number Ms = MA/√γ, where
γ = 5/3 is the plasma adiabatic index. In the following we will refer to both Mach numbers
as MA ≈Ms = M. Finally, electrons are assumed to be an adiabatic fluid with γ = 5/3,
initially in thermal equilibrium with the ions [63].
Two distinct datasets were generated for this study, corresponding to a perpendicular
and a quasi-parallel shock, as discussed below.
– 3 –

2.1
Perpendicular Shock Simulation
We first consider a perpendicular shock (θ = 90◦) to perform initial tests with the machine
learning methods; this is a relatively simple regime because only SDA occurs [18].
The
simulation was conducted in 3D in a box with size 3000 × 50 × 50 (di)3, with 2.5 cells per di,
and 8 particles per cell. The much larger size in the x axis is to allow enough travel distance
for the shock to develop a sufficient suprathermal population of ions via SDA. The supersonic
flow has Mach number M = 100. The simulation timestep was fixed at 7.5 × 10−4ω−1
c
and
tracks were recorded with a time step resolution of t = 7.5×10−2ω−1
c . The simulation ran for
15ω−1
c , over which about 2.3 × 105 particle trajectories were recorded. This limited timescale
is due to the 3D simulation setup, which is computationally very expensive. However, for a
perpendicular shock it is sufficient to generate a large population of suprathermal particles,
since only about one ion gyration is needed, as we will show later. Following [18, 39], we
define thermal particles as those whose final energy is E/Esh ≤2, about 60% of the recorded
ones; the remaining 40% encompasses suprathermal ions with E/Esh > 2.
2.2
Parallel Shock Simulation
In the second dataset we simulate the full process of DSA using a parallel shock, with θ = 0◦
and M = 10. In this case, a much larger box is needed to encompass the diffusion length of
higher and higher energy ions, and it takes longer for the simulation to develop an extended
nonthermal tail, as shown in Figure 1. For these reasons, the simulation was run in 2D, which
is sufficient to capture all the relevant physics [18]. The box measures 40000 × 250di, with
2.5 cells per di, and 4 particles per cell. The simulation ran for a total of 1000ω−1
c , with
a timestep of 4.0 × 10−3ω−1
c . We collected 1.2 × 105 particle tracks with a time resolution
of 8.0 × 10−2ω−1
c , with the data evenly split between thermal (E/Esh ≤2), suprathermal
(2 < E/Esh ≤10), and nonthermal (E/Esh > 10) particles, following the classification in
Refs. [33, 39, 64].
The evolution of the postshock energy spectrum for this simulation is
reported in Figure 1.
3
Machine Learning Algorithms
Machine learning is a term that encompasses many computational techniques for data anal-
ysis. This study specifically focuses on deep learning, a subfield of machine learning in which
networks are designed with "hidden" layers between the input and output. With the combi-
nation of nonlinear functions between layers, deep learning networks are able to use high-level
abstraction to learn complex patterns in data. Training a network has a high upfront cost,
but is amortized over time, as the network becomes highly efficient at processing further data
afterwards. This regime makes deep learning ideal for highly nonlinear processes, such as ac-
celeration at shocks. Three types of deep learning models were tested in this study, discussed
below.
3.1
Convolutional Neural Network
The model primarily used in this study is a convolutional neural network (CNN) [65]. CNNs
learn filters that extract informative patterns or features from the input data. While they are
most commonly employed for image analysis, they can also be applied to other data types
such as time series. For more comprehensive overviews, see Refs. [66, 67].
In this study, we train a CNN to determine whether a particle remains in the thermal
population or becomes accelerated. For each input, the network outputs the probability that
– 4 –

Figure 2. Visualization of the CNN architecture used for classification tasks. Blue blocks represent
1D arrays in convolutional layers, with longer blocks representing arrays of larger lengths. Green
circles represent nodes in fully connected layers and the red circle represents the final output of the
neural network. Within labels, c is the number of output channels from a convolutional layer, k is
kernel size, p is the probability of dropping for a dropout layer, s is the stride, o is the output size for
the adaptive pooling layer, and n is the number of nodes in a linear layer. All convolutional layers
have a stride of 1.
the particle will undergo acceleration. The CNN architecture used in this study is visualized
in Figure 2.
On a technical level, a CNN operates by extracting features through convolutional layers,
which learn kernels (filters) that are convolved with the data in strides. Each convolutional
layer is then followed by a block of accompanying layers. Though the ordering of these lay-
ers may vary, the sequence we use is batch-normalization →activation function →pooling.
These are defined as follows: the batch-normalization layer helps stabilize training by nor-
malizing the outputs of each layer over a mini-batch of data (the set of data samples used
in a training step); an activation function is used to introduce non-linearity, with a common
example being the Rectified Linear Unit (ReLU) [68], which sets negative values to zero; and
finally the pooling layer reduces the dimensionality of the data (e.g., by shortening the length
of a filtered time series). A typical CNN architecture includes multiple instances of these
blocks, represented by the blue components in Figure 2. After passing through the convo-
lutional blocks, the filtered and reduced data can be flattened into a vector of features. An
adaptive pooling layer may also be added before flattening to further compress the feature
set. Following this, fully connected layers (matrix multiplications) use the extracted features
to produce an output; these are represented by the green components of Figure 2. For binary
classification tasks, a sigmoid function is applied to convert the raw scores (logits) produced
by the network into a probability, represented by the final red node in Figure 2. Dropout may
also be applied between layers, randomly turning off a fraction of neurons to help prevent the
– 5 –

network from overfitting (i.e., memorizing the training data).
To train the network, a loss function must be chosen, which quantifies performance on
the given task. Backpropagation, which computes gradients of the loss function with respect
to all network parameters, is applied by an optimization algorithm to make updates. For
this classification problem, we use the Binary Cross-Entropy (BCE) loss function, which is
defined as follows: for input data with a true label of y ∈{0, 1}, where 0 corresponds to a
thermal particle and 1 corresponds to an accelerated particle, and an output from the model
ˆy = P(y = 1), which is the predicted probability that a particle has been accelerated, then
BCE loss is defined as:
ℓBCE = −[y log(ˆy) + (1 −y) log(1 −ˆy)].
(3.1)
Given that CNNs are typically trained in batches of data, the average loss over a batch of N
samples is given by:
LBCE = 1
N
N
X
i=1
ℓBCE(yi, ˆyi).
(3.2)
The model is trained by feeding a batch of input data to get a batch of predictions, which
are used with the true labels to compute LBCE. The gradient of the loss is then computed
and the optimizer is used to adjust model weights as to minimize the loss.
In this study, we only consider the classification problem of whether a particle will be
accelerated, rather than the regression problem of predicting the exact energy that a particle
will finally achieve [61].
This is because the energies of nonthermal particles are always
truncated by the finite length of the simulation. Also, many of the suprathermal particles
eventually rejoin the thermal population.
3.2
Multilayer Perceptron with Manual Features
The next network tested in this study, a multilayer perceptron (MLP), is a simpler approach to
classification than a CNN. They consist of only fully connected layers (matrix multiplications)
with non-linearity functions between them. To this end, they are functionally the same as the
final part of a CNN, without any of the preceding convolutional blocks (i.e., just the green
nodes in Figure 2). MLPs often lack the robustness of CNNs to process higher dimensional
and more complex data; this can be partially remedied by manually choosing features of the
input data to give the MLP, instead of directly feeding it more complex data. In the context
of this study, this means choosing a number of statistics (such as mean, median, or variance)
derived from the time series data. These statistics are then fed to the MLP, instead of the
entire time series. The same loss function is used for both the CNN and MLP.
3.3
Autoencoder
An autoencoder is a type of neural network that is trained unsupervised, meaning that it does
not need access to labeled data. Its general design is to take data (such as particle track time
series) and compress it into a certain number of features, then decompress those variables,
recreating the original input data. In this way, it learns a lower dimension encoding of more
complex data. An autoencoder is composed of two parts: an encoder that compresses data
into a chosen number of features, and a decoder, which decompresses the features back into
a recreation of the inputted data. CNNs are often used as encoders because they are efficient
at producing features. For a more comprehensive autoencoder review, see Ref. [69].
– 6 –

In this study, we use the CNN architecture in Figure 2 for the encoder. The only dif-
ference is the final output layer, which consists of 64 features instead of a single node. The
decoder then takes the same architecture as the encoder, but in reverse, replacing convo-
lutional layers with convolutional transpose layers. Also, pooling layers are removed in the
decoder. Instead, the convolutional transpose layers have a stride of 2, meaning that the data
is effectively doubled in length after each transpose.
The loss function used for the autoencoder is the mean square error (MSE) loss, which
is defined as follows: the inputs to this function are the true vector time series, labeled as t,
and the vector of predictions generated by the model, labeled as ˆt. If D is the total size of ˆt,
then the loss is computed as:
ℓMSE = 1
D
D
X
i=1
(ˆti −ti)2
(3.3)
and the average loss over a batch of N samples is given by:
LMSE =
1
ND
N
X
n=1
D
X
i=1
(ˆti,n −ti,n)2.
(3.4)
4
Classification Experiments
The classification problem is defined as predicting if an ion will be accelerated based on its
initial interaction with the shock. This is motivated by the manual inspection of individual
ion trajectories in hybrid simulations [36, 39], which demonstrated that the fate of a particle
is determined by its first gyrations around the shock. Three different types of input data
are considered, which include a time series of the ion’s momentum (p); the local magnetic
field an ion experienced along its path (B); or the local electric field an ion experienced along
its path (E).
Experiments for both CNN and MLP classification models were conducted
on an NVIDIA Quadro RTX 6000 (Turing, 24GB VRAM) GPU. Training one of the CNN
models takes approximately 30 minutes, while training an MLP model takes approximately
15 minutes.
4.1
Perpendicular Dataset Classification (SDA)
First, we present the experiments conducted with the simpler 3D perpendicular shock dataset,
described in Section 2.1, where the acceleration regime is purely SDA, i.e., particles gain
energy by experiencing a net motional electric field while gyrating around the shock [35,
40, 70]. For this dataset, we define the two classes as thermal particles (E/Esh ≤2) and
suprathermal particles (E/Esh > 2).
These energy distinctions are inspired by the fact
that in a single cycle of SDA, an ion may approximately double its energy, entering the
suprathermal population.
In all experiments, the time series for 2.3 × 105 particles were
split via random sampling between training data, validation data used to assess performance
during training, and test data reserved for final performance analysis. The split was 80%
training, 5% validation, and 15% test.
Our first experiments task the CNN architecture reported in Figure 2 to predict if a
particle will stay in the thermal population or become suprathermal. The set of training
hyperparameters for the CNN include: a learning rate of α = 10−4, which specifies the size
of each update to the network’s internal parameters; no weight decay, which, when present,
pushes model weights towards zero during training to help prevent overfitting; a batch size
– 7 –

of 64, which defines how many samples are processed in one training step; and the Adam
optimizer [71], which dictates how the model updates its internal parameters during training.
The optimizer specific hyperparameters were kept at their default values.
These include
β1 = 0.9, which controls how much the direction of the gradient is smoothed; β2 = 0.999,
which controls how much the size of the gradient is smoothed; and ϵ = 1 × 10−8, which is
an added constant to avoid division by zero. 1D dropout layers with a probability of 0.1
are also used within each convolution block and node level dropout layers with a probability
of 0.2 are used after the first fully connected layer. The addition of these layers controls
overfitting (see Figure 3), where the model begins to memorize training data. The architecture
and hyperparameters were chosen through a parameter search on the parallel dataset using
Optuna [72], in which the loss on validation data was minimized. The model was optimized
with magnetic field data as the input. These choices were also found to be optimal for the
perpendicular dataset.
Figure 3. Left: History of training and validation loss for the CNN trained on magnetic field time
series from the perpendicular shock (§2.1). Validation loss eventually starts performing worse than
training loss, which indicates overfitting. Actual model used in final tests is taken at the best epoch
(39). Center: History of training and validation accuracy. Right: ROC curve for the CNN trained
on magnetic field time series from the perpendicular shock.
For all types of input data (p, B, and E), the time series were given in 3D. Out of the
three types of input data, momentum was used as a baseline test, as it gives the network
direct access to how the energy changes over time. The input data of primary focus in this
study is then the local magnetic field.
Unlike an input of direct momentum time series,
one cannot easily derive a particle’s energy from solely the magnetic field it experienced,
making the classification problem strongly nontrivial. Most diagnostic plots, unless otherwise
stated, deal with magnetic field input data. While the electric field input was also tested, it
yielded similar results to the magnetic field input in all cases. For all types of data, the time
series consists of the first 86 time steps after the ion encountered the shock, with each step
∆t = 7.5 × 10−2ω−1
c . This corresponds to about the time 2π/ωc it would take for a particle
to make one gyration around the shock (i.e., its first interaction).
The overall performance on test data is reported in Table 1. This includes the accuracy
as a basic binary accuracy; precision, which is the fraction of positive predictions that were
actually positive (i.e., the fraction of predictions that a particle would become suprather-
mal that were correct); recall, which is the fraction of positive samples that were correctly
predicted; and the F1 score, which is the harmonic mean of the precision and recall.
Unsurprisingly, the model trained with momentum time series performs the best, with an
accuracy of 98.91%. However, the model trained with magnetic field data also performs well,
– 8 –

with an accuracy of 94.72%. The model trained on electric field data performed comparably
to the magnetic field case, with an accuracy of 94.56%.
Training and validation accuracy and loss for the model trained with magnetic field data
are reported in Figure 3, which also shows the receiver operating characteristic (ROC) curve
3. This metric describes how the model’s true positive rate varies with its false positive rate.
The closer it gets to forming a right angle at the upper leftmost side of the plot, the better.
The area under the ROC curve (AUC), is another metric shown. The AUC ranges from 0
to 1, with a perfect score being 1. The ROC curve and AUC confirm that performance was
consistent between the two classes, i.e., the model was not significantly better at predicting
thermal or suprathermal particles.
CNN
MLP
Input Data
p
B
E
p
B
E
Accuracy
.9891
.9472
.9456
.9308
.8948
.9093
Precision
.9892
.9481
.9434
.9262
.8987
.9040
Recall
.9882
.9423
.9437
.9318
.8826
.9102
F1-score
.9887
.9449
.9436
.9287
.8888
.9066
Table 1. Perpendicular dataset: Classification metrics for models trained with time series inputs
of either momentum, local magnetic field, or local electric field. CNN models are given on the left
and MLP models on the right.
Finally, we examine how shorter time series inputs affect model performance, in the case
of magnetic field input. This is reported in Figure 4. Optimal accuracy seems to be reached at
around 0.75 gyro periods. The network maintained good (> 90%) accuracy for as few as 0.5
gyro periods, at which point the accuracy decreased to 85% for as few as 25 time steps. This
suggests that the time corresponding to roughly half to three quarters of the first gyration
around the shock is most critical for determining if a particle undergoes SDA.
Next, we briefly discuss classification with the MLP network. The problem definition is
the same as before but, instead of being fed an entire time series, the MLP is given twelve
statistics for each dimension of the time series. These include:
1. Minimum value
2. Maximum value
3. Mean value
4. Root mean squared
5. 25th percentile
6. 50th percentile
7. 75th percentile
8. Mean absolute change
9. Number of 0 crossings
10. Number of peaks
11. Skew
12. Kurtosis
As previously described, the MLP architecture is the same as the fully connected portion
of the CNN in Figure 2. It was tested using the momentum, magnetic field, and electric field
input option over 86 time steps, for which the aforementioned statistics were calculated in
each of the dimensions and fed to the neural network. The same optimizer, batch size, and
learning rate as in the CNN were used. The MLP was able to achieve an accuracy of 89.48%
on the test set (Table 1) for magnetic field input data, meaning it underperformed compared
to the CNN. However, this is still a relatively high accuracy given the significant simplification
in network complexity compared to the CNN.
Another type of deep learning network, known as a Long Short-Term Memory (LSTM)
model [73], was considered for this study. LSTMs are a type of recurrent neural network
– 9 –

Figure 4. For the perpendicular dataset, with magnetic field input data, this shows multiple CNNs
trained with varying number of time steps. Time is given in gyro periods, defined as 2πω−1
c . One
gyro period is about the time it takes to complete a cycle of SDA. Performance begins to deteriorate
at less than 0.75 gyro periods.
(RNN). Compared to a traditional feed-forward neural network, such as the aforementioned
CNN, where data is processed as a whole, RNNs take in data sequentially, allowing inference
on later data points to be influenced by the context of earlier data points.
This makes
them especially well fit for time series data, such as particle tracks.
However, in all of
our experiments, LSTMs underperformed compared to CNNs and even to the simple MLP
architecture with manually-selected statistics. This means that the temporal ordering of data
points in the time series may not be the most important factor in predicting particle outcome,
as opposed to the statistics presented above.
4.2
Parallel Dataset Classification (DSA)
Next, we present the classification experiments conducted with the more complex 2D par-
allel shock dataset, described in Section 2.2. For this dataset, we define two classes: ther-
mal+suprathermal particles (E/Esh ≤10) and nonthermal particles (E/Esh > 10), i.e., the
particles that join the DSA tail, which grows with time [33].
Suprathermal particles are
considered together with thermal particles since, given enough time, most of them are ther-
malized, rather than being injected into DSA. For typical quasi-parallel shocks, about 25% of
the ions crossing the shock become suprathermal, compared to ∼1% that achieve nonthermal
energies [39].
For classification with a CNN network, the same model architecture, hyperparameters,
and loss function were used as in the perpendicular case: input time series were used to
cast the binary prediction of whether a particle reached a nonthermal energy. Performance
based on the three types of input time series (p, B, and E) are given in Table 2. The model
with momentum inputs performed the best with an accuracy of 92.56%, but the model with
magnetic field inputs was also able to achieve an accuracy of 91.70%. The model with electric
field inputs only performed slightly worse, with an accuracy of 89.64%.
For all three CNN models, longer time series of 238 time steps were used in training,
which roughly corresponds to three gyro periods. Figure 6, which reports the testing accuracy
– 10 –

Figure 5. Left: History of training and validation accuracy for the CNN trained on magnetic field
time series from the parallel dataset. Actual model used in final tests is taken at the best epoch (21).
Center: History of training and validation loss. Right: ROC curve, with AUC shown in legend.
of models trained on time series of varying lengths, demonstrates that this is a threshold for
good accuracy (> 90%). The potentially interesting physical implications of this threshold
are discussed in Section 6.1. It should also be noted that the majority of nonthermal particles
(approximately 55%) does not reach E/Esh ≥10 within the 238 time steps given.
This
means that it is a true predictive problem for those particles, even with momentum time
series inputs.
The training history (Figure 5) and ROC curve (Figure 5) are also reported for the
CNN model trained on magnetic field inputs. This model suffers from more severe overfitting
compared to the perpendicular case, likely due to the smaller dataset (1.2 × 105 particles
with the same training, validation, and test split as in the perpendicular dataset, that had
2.3 × 105 particles).
CNN
MLP
Input Data
p
B
E
p
B
E
Accuracy
.9256
.9170
.8964
.9227
.8986
.8665
Precision
.9168
.9029
.8824
.9152
.8867
.8539
Recall
.9055
.9101
.8807
.9079
.8800
.8354
F1-score
.9108
.9064
.8815
.9114
.8832
.8435
Table 2. Parallel dataset: Classification metrics for models trained with time series inputs of either
p, B, or E. CNN models are on the left and MLP on the right.
The same MLP network as in Section 4.1 was also tested on the parallel dataset. For
the two dimensions of either p, B, or E, the same statistics as in the previous section were
used as features, calculated over 238 time steps. The MLP network performed with slightly
reduced accuracy compared to the CNN; with the magnetic field time series input, it achieved
a testing accuracy of 89.86% (Table 2).
5
Autoencoder Experiments
We considered the autoencoder architecture discussed in Section 3.3, using as input time
series of p, B, and E; for each of them, we tried to recreate all of the three time series as
output. For each combination, a separate model was trained. Hyperparameters were kept
the same as with classification, save for the loss function (MSE) and learning rate, which
was increased to α = 3 × 10−3. Dropout was only used in the encoder and not the decoder.
– 11 –

Figure 6.
Accuracy of multiple CNNs trained with varying numbers of magnetic field time steps
for the parallel dataset. Performance severely deteriorates if less than three gyro periods are used.
A smaller hyperparameter optimization over validation loss for these choices was again run
with Optuna [72], but only on the baseline model trained to take an input of p and recreate
that same time series on the parallel dataset. For the perpendicular case, all models were
tasked with recreating time series in 3D over the first 86 time steps after an ion encountered
the shock. This length was chosen because it corresponds to the time necessary to optimally
predict if a particle is accelerated via SDA, as discussed in Section 4.1. The autoencoder
experiments were repeated for the parallel dataset with everything kept the same, save for
the time series being in 2D and of length 238 (§4.2).
All autoencoder experiments were
conducted on an NVIDIA Quadro RTX 6000 (Turing, 24GB VRAM) GPU. Training one of
the autoencoder models takes approximately 45 minutes.
Because MSE is a scaled value and differs greatly based on the parameter that is being
recreated, the metric we use to compare autoencoders is the symmetric mean absolute per-
centage error (sMAPE). This gives a percentage or relative error, scaled from 0% to 200%,
with a lower score corresponding to better performance (i.e., 0% is a perfect score). Over N
samples, the sMAPE is given by
LsMAPE = 100%
ND
N
X
n=1
D
X
i=1
2
ˆti,n −ti,n

ˆti,n
 +
ti,n

(5.1)
The symmetric version was chosen over the regular mean absolute percentage error
because the latter blows up when the true time series approaches zero, even for models with
good performance. All of the data used in this study oscillates around zero, so this happens
often. Samples of recreated time series that scored various sMAPE values are shown in Figure
7. Models that achieved an average sMAPE score of less than 100 on the testing dataset can
capture at least some of the time series morphology.
The sMAPE performance of all nine autoencoders for both parallel and perpendicular
cases is reported in Figure 8. Each panel shows the distribution of scores each autoencoder,
and the mean sMAPE over the testing dataset is given in the legend; performance across the
thermal and accelerated particle populations is also separated, to check possible biases.
– 12 –

Figure 7. Samples from the parallel case, demonstrating performance at various sMAPE values in
the x dimension. The model type in the titles describes input →output parameter. Qualitatively,
performance at scores < 25 is extremely strong. Scores < 75 capture general morphology, but make
systematic errors. Scores < 100 capture some morphology, but make large errors. Finally, scores
> 100 are completely wrong.
For these samples, the sMAPE was only computed via the model
output in the x dimension, as to match the visualized plots.
In general, the majority of models perform better when recreating the tracks of acceler-
ated particles, which is the focus of the study. Strong performance on the parallel dataset is
preferable over the perpendicular dataset, because acceleration via DSA is of higher interest
than SDA, which is why the autoencoder setup was optimized on the parallel case.
For the parallel case, models that take and recreate the same type of data (either p,
B, or E) perform well across the board, with mean sMAPE scores < 75. For a qualitative
visualization of this score, see Figure 7. Additionally, the model that takes electric field input
data and recreates momentum time series performs well on the nonthermal population of
particles in the parallel dataset, with a score of 75.49. The models that take momentum and
recreate magnetic field time series; take magnetic field and recreate momentum time series;
and take electric field and recreate magnetic field time series are all able to capture some
general morphology as well, with scores around ≈100 on the nonthermal population of the
parallel dataset. For the perpendicular dataset, the only strong performance was the baseline
model that both took and recreated momentum time series. However, it should be noted
that the autoencoder architecture was only optimized for the base case of momentum input
data being used to recreate the same momentum time series for the parallel dataset. The
additional results on other problem setups are shown, but these are likely suboptimal results.
Overfitting also posed a bottleneck on all models, so future studies that optimize architectures
– 13 –

Figure 8. Test dataset distribution of sMAPE scores for all networks. Distributions are split between
the thermal and accelerated particle populations of both datasets, with each column representing one
such population. Each row is a distinct model type, defined by the type of input and output data the
model was tasked with recreating. A kernel density estimation (KDE) of the distribution is plotted
over the binned density values.
– 14 –

for each type of data and work with larger datasets may yield better results. Nonetheless, it is
significant that even the unoptimized models with electric field and magnetic input data were
able to recover morphology of momentum time series they never had access to, for particles
accelerated via DSA in the parallel dataset.
6
Discussion
6.1
Ion Injection at Shocks
An important result of this study is the insight it gives into the process of injection into DSA.
Ref. [33] puts forward a minimal model that explains ion injection for quasi-parallel shocks,
which was based on the analysis of many individual trajectories in a hybrid simulation.
This study proposed that the first two/three gyrations after the first encounter with
the shock are crucial to determine the fate of a particle in DSA. We locate a particle’s first
encounter with the shock by determining the first point in time at which B ≥5B0, where B is
the modulus of the local magnetic field at that point in time and B0 of the initial background
magnetic field. After an initial reflection off the quasi-periodically reforming shock barrier
[74], which occurs for about 25% of the particles impinging on the shock, particles gain energy
and become suprathermal. Depending on the shock inclination, some of them can outrun the
shock and escape upstream, while the rest is re-caught by the shock. Every shock encounter
is lossy, in the sense that a smaller and smaller fraction of the ions is able to perform more
and more gyrations. Above some critical energy ¯E(θ) all particles can overrun the shock and
must rely on diffusion upstream to go back, effectively entering DSA. For all quasi-parallel
shocks ¯E ∼10Esh, which justifies our choice for the nonthermal threshold.
This theory is reflected perfectly in the classification results with the two datasets. For
the perpendicular shock, in which particles are only accelerated to suprathermal status via
SDA, strong performance is achieved with as little as half a gyro period of time series data,
corresponding to a single interaction with the shock. On the other hand, at parallel shocks
at least three gyro periods of time series data are required to get comparable classification
results. This corroborates the findings that an initial 2–3 cycles of SDA are critical for a
particle to be injected into the full DSA process and that the initial reflection alone is not
sufficient for injection.
While the physical implications of the proof-of-principle analysis presented here offer a
new, model-agnostic, take on the already-solved problem of ion injection, the technique is
promising for unraveling much more complicated problems, such as electron injection. In
fact, despite the progress that came from full-PIC simulations, [e.g., 24, 42–44, 75–80], a
comprehensive theory for the relative normalization of electron and ion power-law tails is still
missing. It also remains to be assessed whether there are instances where electron DSA alone
may occur [81].
6.2
Construction of Kinetic Sub-Grid Models
Using autoencoders, we found that the time series for some key parameters defining the track
of a particle undergoing acceleration may be compressed and recreated. A possible alternative
would be transitioning to a variational autoencoder (VAE). This architecture replaces the
discrete feature encoding with a continuous distribution, which may be sampled to generate
new, synthetic data. However, in this study, the autoencoders struggled to recreate some
of the parameters with more complex time series. Overfitting was an issue in training such
– 15 –

autoencoders, meaning that larger datasets may be able to improve performance. This, along
with the use of VAEs, will be the topic of future study.
A potentially interesting application of machine learning to DSA simulations would be
to add sub-grid kinetic physics to fluid treatments, e.g., the electron fluid in hybrid, or the
thermal plasma in MHD-PIC approaches, in which a kinetic CRs population is superimposed
on a magneto-hydrodynamical fluid [e.g., 82–87]. These kinds of codes can follow the evolu-
tion of a collisionless shock for more macroscopic timescales than PIC codes, but requires a
prescription for the injection of macroparticles at the shock, a non-trivial task especially for
high-Mach cases in which the shock transition is spread over many cells. Machine learning
tuned to kinetic simulations, possibly with coarse sampling to mimic the reduced MHD-PIC
resolution and/or MLP architectures, looks like a very promising way to handle particle in-
jection in an agnostic but self-consistent way; a similar approach could be used to include
electron injection and acceleration into hybrid simulations. These will be the object of future
studies.
7
Conclusions
This study puts forward the first —to our knowledge— attempt to analyze injection and
acceleration at non-relativistic collisionless shocks with deep learning methods.
We constructed a convolutional neural network (CNN) able to predict with high accuracy
(> 90%) whether a particle from a simulated shock dataset is going to be accelerated out
of the thermal population, utilizing only a time series of the locally experienced magnetic
field. For perpendicular shocks, a time series of about one gyro-period that starts at the
first interaction of the particle with the shock can classify thermal and suprathermal particles
with an accuracy > 94% (§4.1). For quasi-parallel shocks, a longer time series of about 3
cyclotron times is needed to achieve an accuracy > 90% in classifying thermal and nonthermal
particles, namely those who are injected into DSA. These findings confirm in an independent
fashion the results obtained with manual inspection of particle trajectories that the first 2-3
interactions with the shock are critical for a particle to be promoted into DSA [39].
We have also experimented with a multilayer perceptron (MLP) network fed with re-
duced statistical properties of the time series, rather than the time series themselves. While
generally performing worse than our CNN, this neural network can still achieve ∼85 −93%
accuracy in the cases considered, which suggests that —with further optimizations— it may
be possible to predict particle injection from coarser samples of the shock electromagnetic
structure.
Additionally, an autoencoder’s ability to capture the morphology of momentum, mag-
netic field, and electric field time series of particles accelerated via DSA was demonstrated.
Each autoencoder model was trained to take one type of data (momentum, electric field, or
magnetic field time series) as input and another as output. Some of these configurations
performed much better than others, with the errors quantified in Figure 8.
These results demonstrate the potential success of machine learning applied to under-
standing particle acceleration at shocks. As computational techniques and simulations further
develop, we expect that deep learning techniques will facilitate the continued extraction of
key insight into the process of acceleration at shocks and the development of subgrid models
for embedding kinetic physics into fluid plasma simulations.
– 16 –

Acknowledgments
The authors thank Aleksandra Ciprijanovic and Harley Katz for their advice and suggestions.
They also thank The University of Chicago Research Computing Center for providing the
computational resources to conduct this research. P.S. was supported by the University of
Chicago Jeff Metcalf Internship Program. D.C. was partially supported by NASA (grants
80NSSC24K0173 and 80NSSC23K1481) and NSF (grants AST-2510951 and AST-2308021).
L.O. acknowledges the support of the Multimessenger Plasma Physics Center (MPPC), NSF
grants PHY2206607 and PHY2206609.
References
[1] G. Krymskii, A regular mechanism for the acceleration of charged particles on the front of a
shock wave, in Akademiia Nauk SSSR Doklady, vol. 234, pp. 1306–1308, 1977.
[2] A. Bell, The acceleration of cosmic rays in shock fronts–i, Monthly Notices of the Royal
Astronomical Society 182 (1978) 147.
[3] R.D. Blandford and J.P. Ostriker, Particle acceleration by astrophysical shocks, Astrophysical
Journal, Part 2-Letters to the Editor, vol. 221, Apr. 1, 1978, p. L29-L32. 221 (1978) L29.
[4] W. Axford, Acceleration of cosmic rays by shock waves, in Invited Papers: Vol. 12, pp. 155–203,
Springer (1977).
[5] G. Morlino and D. Caprioli, Strong evidence for hadron acceleration in tycho’s supernova
remnant, Astronomy & Astrophysics 538 (2012) A81.
[6] D. Caprioli, Cosmic-ray acceleration in supernova remnants: non-linear theory revised, Journal
of cosmology and astroparticle physics 2012 (2012) 038.
[7] A.M. Hillas, TOPICAL REVIEW: Can diffusive shock acceleration in supernova remnants
account for high-energy galactic cosmic rays?, Journal of Physics G Nuclear Physics 31 (2005)
95.
[8] P. Blasi, The origin of galactic cosmic rays, A&ARv 21 (2013) 70 [1311.7346].
[9] V.N. Zirakashvili and V.S. Ptuskin, Diffusive Shock Acceleration with Magnetic Amplification by
Nonresonant Streaming Instability in Supernova Remnants, ApJ 678 (2008) 939 [0801.4488].
[10] D. Caprioli, P. Blasi, E. Amato and M. Vietri, Dynamical Effects of Self-Generated Magnetic
Fields in Cosmic-Ray-modified Shocks, ApJ 679 (2008) L139 [0804.2884].
[11] D. Caprioli, P. Blasi, E. Amato and M. Vietri, Dynamical feedback of self-generated magnetic
fields in cosmic ray modified shocks, MNRAS 395 (2009) 895 [0807.4261].
[12] D. Caprioli, Cosmic-ray acceleration in supernova remnants: non-linear theory revised, JCAP
7 (2012) 38 [1206.1360].
[13] C.C. Haggerty and D. Caprioli, Kinetic Simulations of Cosmic-Ray-modified Shocks. I.
Hydrodynamics, ApJ 905 (2020) 1 [2008.12308].
[14] D. Caprioli, C.C. Haggerty and P. Blasi, Kinetic Simulations of Cosmic-Ray-modified Shocks.
II. Particle Spectra, ApJ 905 (2020) 2 [2009.00007].
[15] D. Caprioli, Cosmic-ray acceleration and propagation, in 34th International Cosmic Ray
Conference (ICRC2015), A.S. Borisov, V.G. Denisova, Z.M. Guseva, E.A. Kanevskaya,
M.G. Kogan, A.E. Morozov et al., eds., vol. 34 of International Cosmic Ray Conference, p. 8,
July, 2015 [1510.07042].
[16] R. Diesing and D. Caprioli, Steep Cosmic-Ray Spectra with Revised Diffusive Shock
Acceleration, ApJ 922 (2021) 1 [2107.08520].
– 17 –

[17] B. Reville and A.R. Bell, A filamentation instability for streaming cosmic rays, MNRAS 419
(2012) 2433 [1109.5690].
[18] D. Caprioli and A. Spitkovsky, Simulations of ion acceleration at non-relativistic shocks. i.
acceleration efficiency, The Astrophysical Journal 783 (2014) 91.
[19] D. Caprioli, A.-R. Pop and A. Spitkovsky, Simulations and theory of ion injection at
non-relativistic collisionless shocks, The Astrophysical Journal Letters 798 (2014) L28.
[20] C.K. Birdsall and A.B. Langdon, Particle simulation techniques, in Computer Applications in
Plasma Science and Engineering, pp. 7–41, Springer (1991).
[21] A. Bell, A. Robinson, M. Sherlock, R. Kingham and W. Rozmus, Fast electron transport in
laser-produced plasmas and the kalos code for solution of the vlasov–fokker–planck equation,
Plasma Physics and controlled fusion 48 (2006) R37.
[22] T. Amano and M. Hoshino, Electron injection at high mach number quasi-perpendicular shocks:
surfing and drift acceleration, The Astrophysical Journal 661 (2007) 190.
[23] A. Spitkovsky, Simulations of relativistic collisionless shocks: shock structure and particle
acceleration, in Astrophysical Sources of High Energy Particles and Radiation, T. Bulik,
B. Rudak and G. Madejski, eds., vol. 801 of American Institute of Physics Conference Series,
pp. 345–350, Nov., 2005, DOI [astro-ph/0603211].
[24] L. Sironi and A. Spitkovsky, Particle Acceleration in Relativistic Magnetized Collisionless
Electron-Ion Shocks, ApJ 726 (2011) 75 [1009.0024].
[25] J. Niemiec, M. Pohl, A. Bret and V. Wieland, Nonrelativistic parallel shocks in unmagnetized
and weakly magnetized plasmas, The Astrophysical Journal 759 (2012) 73.
[26] M.A. Riquelme and A. Spitkovsky, Electron injection by whistler waves in non-relativistic
shocks, The Astrophysical Journal 733 (2011) 63.
[27] M. Palmroth, U. Ganse, Y. Pfau-Kempf, M. Battarbee, L. Turc, T. Brito et al., Vlasov methods
in space physics and astrophysics, Living reviews in computational astrophysics 4 (2018) 1.
[28] A.S. Lipatov, The hybrid multiscale simulation technology: an introduction with application to
astrophysical and laboratory plasmas, Springer Science & Business Media (2013).
[29] D. Winske, Hybrid simulation codes with application to shocks and upstream waves, Space
Science Reviews 42 (1985) 53.
[30] J. Giacalone, Large-scale hybrid simulations of particle acceleration at a parallel shock, The
Astrophysical Journal 609 (2004) 452.
[31] L. Gargaté, R. Bingham, R.A. Fonseca and L.O. Silva, dhybrid: A massively parallel code for
hybrid simulations of space plasmas, Computer Physics Communications 176 (2007) 419.
[32] F. Guo and J. Giacalone, The acceleration of thermal protons at parallel collisionless shocks:
three-dimensional hybrid simulations, The Astrophysical Journal 773 (2013) 158.
[33] D. Caprioli, A.-R. Pop and A. Spitkovsky, Simulations and theory of ion injection at
non-relativistic collisionless shocks, The Astrophysical Journal Letters 798 (2014) L28.
[34] D. Caprioli, C.C. Haggerty and P. Blasi, Kinetic simulations of cosmic-ray-modified shocks. ii.
particle spectra, The Astrophysical Journal 905 (2020) 2.
[35] L. Orusa and D. Caprioli, Fast particle acceleration in 3d hybrid simulations of
quasiperpendicular shocks, Physical Review Letters 131 (2023) 095201.
[36] L. Orusa, D. Caprioli, L. Sironi and A. Spitkovsky, The role of three-dimensional effects on ion
injection and acceleration in perpendicular shocks, arXiv preprint arXiv:2507.13436 (2025) .
– 18 –

[37] L. Orusa and V. Valenzuela-Villaseca, Criteria for ion acceleration in laboratory magnetized
quasi-perpendicular collisionless shocks: When are 2D simulations enough?, Physics of Plasmas
32 (2025) 052901 [2503.00163].
[38] D. Caprioli, L. Orusa, M. Cernetic, C.C. Haggerty and B. Ostler, Acceleration of heavy ions at
nonrelativistic collisionless shocks, The Astrophysical Journal Letters 993 (2025) L1.
[39] D. Caprioli, A. Pop and A. Spitkovsky, Simulations and Theory of Ion Injection at
Non-relativistic Collisionless Shocks, ApJ 798 (2015) 28 [1409.8291].
[40] L. Ball and D. Melrose, Shock drift acceleration of electrons, Publications of the Astronomical
Society of Australia 18 (2001) 361.
[41] A.R. Bell, K.M. Schure and B. Reville, Cosmic ray acceleration at oblique shocks, MNRAS 418
(2011) 1208 [1108.0582].
[42] J. Park, D. Caprioli and A. Spitkovsky, Simultaneous Acceleration of Protons and Electrons at
Nonrelativistic Quasiparallel Collisionless Shocks, Physical Review Letters 114 (2015) 085003
[1412.0672].
[43] S. Gupta, D. Caprioli and A. Spitkovsky, Electron Acceleration at Quasi-parallel Nonrelativistic
Shocks: A 1D Kinetic Survey, ApJ 976 (2024) 10 [2408.16071].
[44] S. Gupta, D. Caprioli and A. Spitkovsky, Speed-dependent Threshold for Electron Injection into
Diffusive Shock Acceleration, arXiv e-prints (2025) arXiv:2506.09134 [2506.09134].
[45] J.-V. Rodríguez, I. Rodríguez-Rodríguez and W.L. Woo, On the application of machine
learning in astronomy and astrophysics: A text-mining-based scientometric analysis, Wiley
Interdisciplinary Reviews: Data Mining and Knowledge Discovery 12 (2022) e1476.
[46] G. Li, Z. Lu, J. Wang and Z. Wang, Machine learning in stellar astronomy: Progress up to
2024, arXiv preprint arXiv:2502.15300 (2025) .
[47] S. Gharat and Y. Dandawate, Galaxy classification: a deep learning approach for classifying
sloan digital sky survey images, Monthly Notices of the Royal Astronomical Society 511 (2022)
5120.
[48] J.Y. Soo, I.Y.K.A. Shuaili and I.M. Pathi, Machine learning applications in astrophysics:
Photometric redshift estimation, in AIP Conference Proceedings, vol. 2756, AIP Publishing,
2023.
[49] G. Stein, J. Blaum, P. Harrington, T. Medan and Z. Lukić, Mining for strong gravitational
lenses with self-supervised learning, The Astrophysical Journal 932 (2022) 107.
[50] G. Khullar, B. Nord, A. Ćiprijanović, J. Poh and F. Xu, Digs: deep inference of galaxy spectra
with neural posterior estimation, Machine Learning: Science and Technology 3 (2022) 04LT04.
[51] A. Ćiprijanović, D. Kafkes, K. Downey, S. Jenkins, G.N. Perdue, S. Madireddy et al.,
Deepmerge–ii. building robust deep learning algorithms for merging galaxy identification across
domains, Monthly Notices of the Royal Astronomical Society 506 (2021) 677.
[52] C. Dvorkin, S. Mishra-Sharma, B. Nord, V.A. Villar, C. Avestruz, K. Bechtol et al., Machine
learning and cosmology, arXiv preprint arXiv:2203.08056 (2022) .
[53] K. Moriwaki, T. Nishimichi and N. Yoshida, Machine learning for observational cosmology,
Reports on Progress in Physics 86 (2023) 076901.
[54] M. Erdmann, J. Glombitza and D. Walz, A deep learning-based reconstruction of cosmic
ray-induced air showers, Astroparticle Physics 97 (2018) 46.
[55] A. Alvarado, T. Capistrán, I. Torres, J. SacahuÍ and R. Alfaro, Cosmic-ray energy
reconstruction using machine learning techniques, arXiv preprint arXiv:2310.06938 (2023) .
[56] C. Xu, C. McCully, B. Dong, D.A. Howell and P. Sen, Cosmic-conn: a cosmic-ray detection
deep-learning framework, data set, and toolkit, The Astrophysical Journal 942 (2023) 73.
– 19 –

[57] M.F. Kasim, D. Watson-Parris, L. Deaconu, S. Oliver, P. Hatfield, D.H. Froula et al., Building
high accuracy emulators for scientific simulations with deep neural architecture search, Machine
Learning: Science and Technology 3 (2021) 015013.
[58] J.L. Peterson, K.D. Humbird, J.E. Field, S.T. Brandon, S.H. Langer, R.C. Nora et al., Zonal
flow generation in inertial confinement fusion implosions, Physics of Plasmas 24 (2017) .
[59] J. Kwan, K. Heitmann, S. Habib, N. Padmanabhan, E. Lawrence, H. Finkel et al., Cosmic
emulation: fast predictions for the galaxy power spectrum, The Astrophysical Journal 810
(2015) 35.
[60] F. Brockherde, L. Vogt, L. Li, M.E. Tuckerman, K. Burke and K.-R. Müller, Bypassing the
kohn-sham equations with machine learning, Nature communications 8 (2017) 872.
[61] G. Torralba Paz, A. Bohdan and J. Niemiec, Neural networks for the analysis of traced
particles in kinetic plasma simulations, AIP Advances 15 (2025) .
[62] C.C. Haggerty and D. Caprioli, dhybridr: A hybrid particle-in-cell code including relativistic ion
dynamics, The Astrophysical Journal 887 (2019) 165.
[63] D. Caprioli, H. Zhang and A. Spitkovsky, Diffusive shock re-acceleration, JPP (2018)
[1801.01510].
[64] A. Johlander, M. Battarbee, A. Vaivads, L. Turc, Y. Pfau-Kempf, U. Ganse et al., Ion
Acceleration Efficiency at the Earth’s Bow Shock: Observations and Simulation Results, ApJ
914 (2021) 82.
[65] Y. LeCun, L. Bottou, Y. Bengio and P. Haffner, Gradient-based learning applied to document
recognition, Proceedings of the IEEE 86 (2002) 2278.
[66] Z. Li, F. Liu, W. Yang, S. Peng and J. Zhou, A survey of convolutional neural networks:
analysis, applications, and prospects, IEEE transactions on neural networks and learning
systems 33 (2021) 6999.
[67] M. Krichen, Convolutional neural networks: A survey, Computers 12 (2023) 151.
[68] V. Nair and G.E. Hinton, Rectified linear units improve restricted boltzmann machines, in
Proceedings of the 27th international conference on machine learning (ICML-10), pp. 807–814,
2010.
[69] K. Berahmand, F. Daneshfar, E.S. Salehi, Y. Li and Y. Xu, Autoencoders and their
applications in machine learning: a survey, Artificial intelligence review 57 (2024) 28.
[70] J. Park, J.C. Workman, E.G. Blackman, C. Ren and R. Siller, Particle-in-cell simulations of
particle energization from low Mach number fast mode shocks, Physics of Plasmas 19 (2012)
062904 [1203.0074].
[71] D.P. Kingma and J. Ba, Adam: A method for stochastic optimization, arXiv preprint
arXiv:1412.6980 (2014) .
[72] T. Akiba, S. Sano, T. Yanase, T. Ohta and M. Koyama, Optuna: A next-generation
hyperparameter optimization framework, in Proceedings of the 25th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining, 2019.
[73] S. Hochreiter and J. Schmidhuber, Long short-term memory, Neural computation 9 (1997)
1735.
[74] V.A. Thomas, D. Winske and N. Omidi, Re-forming supercritical quasi-parallel shocks. I - One-
and two-dimensional simulations, JGR 95 (1990) 18809.
[75] T. Amano and M. Hoshino, Electron Injection at High Mach Number Quasi-perpendicular
Shocks: Surfing and Drift Acceleration, ApJ 661 (2007) 190 [arXiv:astro-ph/0612204].
– 20 –

[76] X. Guo, L. Sironi and R. Narayan, Non-thermal electron acceleration in low mach number
collisionless shocks. i. particle energy spectra and acceleration mechanism, ApJ 794 (2014) 153
[1406.5190].
[77] X. Guo, L. Sironi and R. Narayan, Non-thermal electron acceleration in low mach number
collisionless shocks. ii. firehose-mediated fermi acceleration and its dependence on pre-shock
conditions, ApJ 797 (2014) 47 [1409.7393].
[78] R. Xu, A. Spitkovsky and D. Caprioli, Electron Acceleration in One-dimensional
Nonrelativistic Quasi-perpendicular Collisionless Shocks, ApJ 897 (2020) L41 [1908.07890].
[79] A. Bohdan, J. Niemiec, M. Pohl, Y. Matsumoto, T. Amano and M. Hoshino, Kinetic
Simulations of Nonrelativistic Perpendicular Shocks of Young Supernova Remnants. I. Electron
Shock-surfing Acceleration, ApJ 878 (2019) 5 [1904.13153].
[80] A. Marcowith, G. Ferrand, M. Grech, Z. Meliani, I. Plotnikov and R. Walder, Multi-scale
simulations of particle acceleration in astrophysical systems, Living Reviews in Computational
Astrophysics 6 (2020) 1 [2002.09411].
[81] G. Brunetti and T.W. Jones, Cosmic rays in galaxy clusters and their nonthermal emission,
International Journal of Modern Physics D 23 (2014) 1430007 [1401.7519].
[82] S. Lucek and A. Bell, Non-linear amplification of a magnetic field driven by cosmic ray
streaming, Monthly Notices of the Royal Astronomical Society 314 (2000) 65.
[83] X.-N. Bai, D. Caprioli, L. Sironi and A. Spitkovsky, Magnetohydrodynamic-particle-in-cell
method for coupling cosmic rays with a thermal plasma: application to non-relativistic shocks,
The Astrophysical Journal 809 (2015) 55.
[84] A. Mignone, G. Bodo, B. Vaidya and G. Mattia, A particle module for the pluto code: I - an
implementation of the mhd-pic equations, The Astrophysical Journal 859 (2018) .
[85] A.J. van Marle, F. Casse and A. Marcowith, On magnetic field amplification and particle
acceleration near non-relativistic astrophysical shocks: particles in mhd cells simulations,
Monthly Notices of the Royal Astronomical Society 473 (2018) 3394.
[86] Y. Dubois, B. Commerçon, A. Marcowith and L. Brahimi, Shock-accelerated cosmic rays and
streaming instability in the adaptive mesh refinement code ramses, Astronomy & Astrophysics
631 (2019) A121.
[87] X. Sun and X.-N. Bai, The magnetohydrodynamic-particle-in-cell module in ATHENA++:
implementation and code tests, Monthly Notices of the Royal Astronomical Society 523 (2023)
3328.
– 21 –
