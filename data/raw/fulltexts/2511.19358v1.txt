Black-Box Lifting and Robustness Theorems for
Multi-Agent Contracts∗
Paul D¨utting†
Tomer Ezra‡
Michal Feldman§
Thomas Kesselheim¶
Abstract
Multi-agent contract design has largely evaluated contracts through the lens of pure Nash
equilibria (PNE). This focus, however, is not without loss: In general, the principal can strictly
gain by recommending a complex, possibly correlated, distribution over actions, while preserving
incentive compatibility. In this work, we extend the analysis of multi-agent contracts beyond
pure Nash equilibria to encompass more general equilibrium notions, including mixed Nash
equilibria as well as (coarse-)correlated equilibria (CCE). The latter, in particular, captures the
limiting outcome of agents engaged in learning dynamics.
Our main result shows that for submodular and, more generally, XOS rewards, such complex
recommendations yield at most a constant-factor gain: there exists a contract and a PNE whose
utility is within a constant factor of the best CCE achievable by any contract. This provides
a black-box lifting: results established against the best PNE automatically apply with respect
to the best CCE, with only a constant factor loss. For submodular rewards, we further show
how to transform a contract and a PNE of that contract into a new contract such that any of
its CCEs gives a constant approximation to the PNE. This yields black-box robustness: up to
constant factors, guarantees established for a specific contract and PNE automatically extend
to the modified contract and any of its CCEs. We thus expand prior guarantees for multi-agent
contracts and lower the barrier to new ones. As an important corollary, we obtain poly-time
algorithms for submodular rewards that achieve constant approximations in any CCE, against
the best CCE under the best contract. Such worst-case guarantees are provably unattainable for
XOS rewards. Finally, we bound the gap between different equilibrium notions for subadditive,
supermodular, and general rewards.
1
Introduction
A classic contract setting features a principal who must incentivize a self-interested agent to take
costly actions that generate value for the principal. Examples include a firm designing incentive
schemes for employees or a platform rewarding contributors. The central difficulty is that actions
∗This project has been partially funded by the European Research Council (ERC) under the European Union’s
Horizon Europe Program (FACT, grant agreement No. 101170373), by an Amazon Research Award, by the NSF-
BSF (grant number 2020788), by the Israel Science Foundation Breakthrough Program (grant No. 2600/24), and by
a grant from TAU Center for AI and Data Science (TAD). T. Ezra is supported by the Harvard University Center of
Mathematical Sciences and Applications.
†Google Research, Z¨urich, Switzerland. Email: duetting@google.com
‡Harvard University, Cambridge, USA. Email: tomer@cmsa.fas.harvard.edu
§Tel Aviv University, Tel Aviv, Israel. Email: mfeldman@tauex.tau.ac.il
¶University of Bonn, Bonn, Germany. Email: thomas.kesselheim@uni-bonn.de
1
arXiv:2511.19358v1  [cs.GT]  24 Nov 2025

are typically hidden: the principal cannot directly monitor actions and must instead align incentives
through payments that depend only on observable outcomes.
In recent years, many such relationships have migrated to computational platforms.
These
environments are large-scale and complex, calling for an algorithmic treatment. Algorithmic con-
tract design has therefore emerged at the intersection of economics and computation, developing
models and schemes for designing incentives in these settings (we refer to D¨utting, Feldman, and
Talgam-Cohen, 2024 for a comprehensive survey).
A natural focal point in this literature is combinatorial contracts: the principal may interact
with teams of agents, a single agent may choose among combinations of actions, and the overall
reward depends on the joint selection through a combinatorial reward function that can exhibit
both substitutability and complementarity (e.g., Babaioff, Feldman, and Nisan, 2006; Castiglioni,
Marchesi, and Gatti, 2023; Deo-Campo Vuong, Dughmi, Patel, and Prasad, 2024; D¨utting, Ezra,
Feldman, and Kesselheim, 2021, 2023, 2025; D¨utting, Feldman, and Gal-Tzur, 2024; D¨utting,
Feldman, Gal-Tzur, and Rubinstein, 2026; Ezra, Feldman, and Schlesinger, 2024; Feldman, 2025;
Hann-Caruthers and Goel, 2024). The principal’s objective is to select a contract that maximizes
her expected utility given the agents’ equilibrium behavior.
A key limitation of much of this literature is its (near) exclusive focus on pure Nash equilibria
(PNE). In multi-agent settings this restriction is not without loss of generality. As observed by
Babaioff, Feldman, and Nisan (2010), the gap can arise already for submodular rewards (see Ex-
ample A.1). In particular, a principal can sometimes do strictly better by inducing agents to play a
distribution over actions from which no agent wishes to deviate. This raises a natural question: how
much additional utility can the principal obtain by moving beyond PNE to richer equilibrium con-
cepts that allow randomization or correlation? This question is especially salient because natural
learning dynamics typically converge to these broader, and often correlated, equilibrium notions.
1.1
Model and Research Problem
We consider the multi-agent combinatorial contracts model of D¨utting, Ezra, Feldman, and Kessel-
heim, 2025, which generalizes the models of D¨utting, Ezra, Feldman, and Kesselheim, 2021 and
D¨utting, Ezra, Feldman, and Kesselheim, 2023. In the multi-agent combinatorial contracts model,
a single principal interacts with n agents. Each agent i ∈[n] can take any subset of actions Si from
an available action set Ai. We let A = ⊍i Ai, and use m = ∣A∣to denote the total number of actions.
We refer to the special case where ∣Ai∣= 1 for all i ∈[n], i.e., each agent can either take action or
not, as the binary-actions case. The agents’ choice of actions S ⊆A, with Si = S ∩Ai the set of
actions chosen by agent i ∈[n], determines a reward f(S) through a reward function f ∶2A →R≥0.
We generally assume that the reward function is normalized (so that f(∅) = 0) and monotone (so
that S ⊆T implies f(S) ≤f(T)). Access to f may be given through a value oracle or a demand
oracle (see Section 2). The agents each have a cost cj for each action j ∈A, and the cost for a
set of actions Si ⊆Ai is c(Si) = ∑j∈Si cj. To incentivize the agents, the principal designs a linear
contract ⃗α = (α1,...,αn) ∈[0,1]n. The interpretation is that the principal pays each agent i an
αi fraction of the reward f(S) that results from the agents’ actions S. The principal’s utility is
(1 −∑i αi)f(S). The agents, in turn, have a utility of αif(S) −c(Si). Since the agents’ utilities
depend on each other, we are interested in equilibria among agents.
While prior work has focused on pure Nash equilibria (PNE), here we are interested in exploring
the more general equilibrium concepts of mixed Nash equilibria (MNE), correlated equilibria (CE),
and coarse-correlated equilibria (CCE). In these more general equilibrium notions the principal
2

uP
⃗α⋆
CCE
PNE
CCE
PNE
⃗α⋆
O(1)
Lifting (Thm. 3.1)
submodular and XOS
uP
⃗α⋆
CCE
PNE
⃗α⋆
CCE
PNE
O(1)
Robustness (Thm. 3.4)
submodular
uP
⃗α⋆
O(1)
Approximation (Cor. 3.5)
submodular
Figure 1: Visualization of our results for submodular and XOS rewards. Lifting (left panel): We
are given as input a contract ⃗α⋆and a CCE (triangle) and we construct a contract ⃗α and a
PNE (circle). Robustness (middle panel): We are given a contract ⃗α⋆and a PNE (circle) and we
construct a contract ⃗α with a guarantee for any CCE under that contract. In both panels, the
ranges of principal utilities under PNE and CCE are drawn as continuous intervals for illustration.
Approximation (right panel): The lower curve shows the worst-performing CCE for each contract;
the upper curve shows the corresponding best-performing CCE. We show that it is possible to
compute a contract ⃗α such that the worst CCE under that contract is within a constant-factor of
the best CCE under any contract (black triangle).
induces the agents to play a distribution over actions, while ensuring that no agent has an incentive
to deviate. The randomization can be either independent (as in MNE), or correlated (as in CE
and CCE), where CE and CCE differ in how they capture the property that no agent wants to
deviate (for formal definitions see Section 2). It is well known that these equilibrium concepts are
successive generalizations, i.e.,
PNE ⊆MNE ⊆CE ⊆CCE.
Our goal in this work is to bound the gap in the principal’s utility between different equilib-
ria under different equilibrium notions, potentially achieved by different contracts, and provide
algorithms for computing contracts with strong robustness guarantees. We consider both rewards
from the hierarchy of complement-free set functions (submodular ⊆XOS ⊆subadditive) as well as
supermodular and general monotone rewards.
1.2
Our Contribution
We discuss our main results, for submodular and XOS reward functions, in Section 1.2.1.
In
Section 1.2.2, we cover additional results that map the broader landscape of gaps between different
equilibrium concepts under prominent classes of reward functions. We provide an illustration and
an overview of our results in Figure 1 and Table 1.
1.2.1
Main Results: Submodular and XOS Rewards
For submodular rewards, Babaioff, Feldman, and Nisan, 2010 demonstrated that the principal’s
utility under the best mixed Nash equilibrium can be strictly greater than under the best pure
3

Nash equilibrium.
They conjectured that, for submodular rewards, this (multiplicative) gap is
bounded by a constant. Despite substantial progress on combinatorial contract design since then,
this conjecture has remained unresolved.
Our main result not only settles this conjecture but in fact establishes a much stronger result.
We show that, in a model with arbitrary (non-binary) actions and for XOS rewards (a strict
generalization of submodular rewards), for each contract ⃗α⋆and any coarse-correlated equilibrium
(CCE) of that contract, there is a (typically different) contract ⃗α and a pure Nash equilibrium
(PNE) under ⃗α that achieves a constant fraction of the principal’s utility under the CCE. See
Figure 1 (left) for an illustration. Thus, the conjectured constant gap is strengthened along three
dimensions: extending from binary to arbitrary actions, from MNE to CCE, and from submodular
to XOS rewards.
Black-Box Lifting Theorem (Theorem 3.1). For the multi-agent combinatorial contracts model
with submodular or XOS rewards, given any contract ⃗α⋆and any CCE of ⃗α⋆, there exists a contract
⃗α and a PNE S of ⃗α such that the principal’s utility under S is a constant fraction of the principal’s
utility under the CCE of ⃗α⋆. Moreover, given ⃗α⋆and the CCE, one can find ⃗α and S in polynomial
time (in n, m and the support size of the CCE) with value and demand oracle access to f.
This result provides a black-box lifting: any guarantee established with respect to the best-
PNE benchmark automatically holds also against the stronger benchmark of the best CCE, with
only a constant factor loss, thereby strengthening existing bounds for multi-agent contracts and
simplifying the path to new ones. Indeed, to obtain guarantees against the best CCE, one no longer
needs to grapple with the intricate notion of CCE (with its randomization and correlation), but can
instead reason about the simpler and more transparent concept of pure Nash equilibrium. Readers
familiar with the smoothness framework for bounding the price of anarchy (Roughgarden, 2015)
may find this connection conceptually reminiscent; see Section 1.4 for further discussion.
As an immediate corollary, all approximation results established in D¨utting, Ezra, Feldman,
and Kesselheim, 2023, 2025, for instance, hold against the stronger benchmark of the best CCE
under any contract. One such result is that, for submodular rewards, there is a poly-time algorithm
that finds a contract under which any PNE attains a constant-factor approximation to the best
PNE under any contract (D¨utting, Ezra, Feldman, and Kesselheim, 2025). Our lifting theorem
immediately extends this guarantee against the best CCE under any contract.
We further strengthen this result by establishing the following (black-box) robustness result
for submodular rewards, which shows how to transform any contract and pure Nash equilibrium of
that contract into a different contract that comes with a guarantee for any CCE under the modified
contract. See Figure 1 (middle) for an illustration.
Black-Box Robustness Theorem (Theorem 3.4). For the multi-agent combinatorial contracts
model with submodular rewards, given any contract ⃗α⋆and pure Nash equilibrium of ⃗α⋆, there is
an algorithm that runs in polynomial time (in n and m) using value queries to f, that computes a
contract ⃗α such that any CCE under ⃗α achieves an O(1)-approximation to the principal’s utility
under the PNE of ⃗α⋆.
Combining this with the results in (D¨utting, Ezra, Feldman, and Kesselheim, 2023, 2025) and
the Black-Box Lifting Theorem, shows that for the multi-agent combinatorial contracts model with
submodular rewards there is a poly-time algorithm (with value and demand oracles) that computes
a contract such that any CCE under that contract provides a O(1)-approximation to the best CCE
under any contract (see Corollary 3.5). In the special case of binary actions, such a contract can
4

Reward function
Gap between ... and PNE
MNE
CE
CCE
Submodular/XOS
Binary/arbitrary
Θ(1)
actions
Lower: Ex. A.1, Upper: Thm. 3.1
Subadditive
Binary/arbitrary
Θ(poly(n))
actions
Lower: Prop. 4.1, Upper: Prop. 4.5
Supermodular
Binary
No gap
actions
Thm. 5.1
Arbitrary
No gap
Unbounded
actions
Thm. 5.2
Prop. 5.4
General
Binary/arbitrary
Unbounded
actions
Prop. 6.1
Table 1: Gaps between MNE/CE/CCE and PNE, for different reward functions and binary actions
vs. arbitrary actions. In merged cells, lower bounds are proved for simpler action and equilibrium
notions and extend to more general ones; upper bounds are proved for more general cases and
apply to the simpler ones. (E.g., for submodular/XOS rewards, the lower bound is proved for
binary actions and MNE, while the upper bound is proved for arbitrary actions and CCE.)
be computed with value queries only. We provide an illustration of the guarantees achieved by the
corresponding algorithms in Figure 1 (right).
Similar to the Black-Box Lifting Theorem, the Black-Box Robustness Theorem is conceptually
related to the price of anarchy framework. It shows that, for submodular rewards, one only needs
to show the existence of a good contract and pure Nash equilibrium, and can then rely on the
extension result to transform the original contract into a contract under which all CCE (and hence
learning outcomes) are near-optimal. Notably, for XOS rewards, such a worst-case approximation
guarantee is unattainable, even for the weaker target of ensuring that any PNE under the given
contract is within a constant factor of the best PNE under any contract (as already observed in
D¨utting, Ezra, Feldman, and Kesselheim, 2025).
1.2.2
Beyond XOS Rewards: Mapping the Landscape
We next examine the gap between different equilibrium concepts beyond XOS rewards. We start
with subadditive rewards, then we move to supermodular rewards, and finally we consider general
(monotone) rewards.
Subadditive Rewards.
For subadditive rewards, we construct a carefully designed instance that
exhibits a polynomial lower bound of order Ω(√n) on the gap between the principal’s utility under
the best mixed Nash equilibrium (MNE) and the best pure Nash equilibrium (PNE), where n
denotes the number of agents. Remarkably, this gap already arises in the binary-actions case (so
n is also the number of actions here). We also show that this gap is at most O(n), even between
5

CCE and PNE and the case of general actions.1
Proposition (Subadditive Rewards) (Proposition 4.1 and Proposition 4.5).
For the multi-
agent combinatorial contracts model with subadditive rewards, the gap between the principal’s
utility from the best MNE and the best PNE is Ω(poly(n)), even in the binary-actions case. On
the other hand, the gap between the principal’s utility under the best CCE and the best PNE is
at most O(n), even for an arbitrary number of actions.
Supermodular Rewards.
For supermodular rewards, we show that in the case of binary actions,
there is no gap between the principal’s utility from the best coarse-correlated equilibrium and the
best pure Nash equilibrium. This strengthens a result of Babaioff, Feldman, and Nisan, 2010, who
established this no-gap result only with respect to mixed NE.
Theorem (Supermodular Rewards, Binary Actions) (Theorem 5.1). For the multi-agent
model with binary actions and supermodular rewards, there is no gap between the principal’s
utility from the best CCE and the best PNE.
In contrast, for arbitrary actions there is no gap only when comparing the best correlated
equilibrium (CE) to the best PNE; for the more general notion of coarse-correlated equilibria
(CCE), the gap to PNE may be unbounded.
Theorem (Supermodular Rewards, General Actions) (Theorem 5.2 and Proposition 5.4).
For the multi-agent model with arbitrary actions and supermodular rewards, there is no gap between
the principal’s utility under the best CE and the best PNE; while the gap between CCE and PNE
is unbounded.
General Rewards.
Finally, we turn to general monotone rewards, in particular rewards that are
neither subadditive nor supermodular. We show that in this regime, even the gap between the best
MNE and the best PNE can be unbounded. Moreover, such unbounded gaps arise already with a
constant number of agents and binary actions.
Proposition (General Rewards) (Proposition 6.1). In the multi-agent combinatorial contract
model with general rewards (neither subadditive, nor supermodular), the gap between the princi-
pal’s utility under the best MNE and the best PNE is unbounded, even with only four agents and
binary actions.
1.3
Challenges and Techniques
Black-Box Lifting and the Scaling-for-Existence Lemma.
Our key tool for establishing
an upper bound on the gap between coarse-correlated equilibria and pure Nash equilibria, for
submodular and XOS rewards, is a simple yet powerful Scaling-for-Existence Lemma (Lemma 3.3).
This lemma starts from a contract ⃗α⋆and a distribution over action sets that satisfies a mild
dropout-stability condition (Definition 2.6).
Dropout-stability requires that each agent weakly
prefers to follow the actions in the given distribution over unilaterally deviating to taking no
action. This condition is naturally satisfied by all equilibrium concepts we study.
1A weaker upper bound of m follows from a recent result by D¨utting, Ezra, Feldman, and Kesselheim, 2025,
showing that the gap between social welfare and the best PNE is at most m.
6

The Scaling-for-Existence Lemma shows that, after appropriately scaling the contract to ⃗α, there
exists a PNE that guarantees high reward relative to the original distribution. In particular, if there
is a subset of agents that achieves high expected reward under the original distribution and whose
total share ∑i α⋆
i is bounded away from 1, then the lemma can be used to show that the induced
pure Nash equilibrium recovers a constant fraction of the principal’s utility under the original
distribution. To obtain the constant-factor gap, we show that in any dropout-stable distribution,
either (i) there is a “significant” agent and a good pure Nash equilibrium that incentivizes only
this agent, or (ii) there exists a subset of agents to which we can apply the Scaling-for-Existence
Lemma to obtain a good pure Nash equilibrium.
Our proof of the Scaling-for-Existence Lemma leverages that, for each contract, the induced
game among the agents is a potential game (e.g., Deo-Campo Vuong, Dughmi, Patel, and Prasad,
2024; D¨utting, Ezra, Feldman, and Kesselheim, 2025). We show that for the original contract
⃗α⋆and any dropout-stable distribution under this contract, the XOS structure implies that the
expected potential of any set S in the support of the dropout-stable distribution is non-negative.
We then scale the contract to ⃗α and select S as a global maximizer of the potential function for ⃗α.
This ensures that (S, ⃗α) forms a pure Nash equilibrium. Finally, the fact that ⃗α is obtained from
⃗α⋆through scaling, together with the non-negativity of the expected potential under ⃗α⋆, implies
that this pure Nash equilibrium achieves high reward relative to the original distribution.
Notably, for subadditive rewards, our proof for the Scaling-for-Existence Lemma breaks: it is
no longer guaranteed that the expected potential of any set S in the support of a dropout stable
distribution for contract ⃗α⋆is non-negative. This failure not only undermines the proof technique,
but points to a deeper structural issue. Namely, such a result is provably impossible for subadditive
rewards: the gap between PNE and MNE (and thus PNE and CCE) is superconstant.
Black-Box Robustness and the Scaling-for-Robustness Lemma.
The Scaling-for-Existence
Lemma derives a good PNE from a dropout-stable distribution over actions (such as CE or
CCE). Our Black-Box Robustness Theorem builds on a lemma, the Scaling-for-Robustness Lemma
(Lemma 3.6), that achieves an orthogonal goal, namely showing that every CCE is good relative
to a reference equilibrium (or rather relaxation thereof).
Our lemma generalizes the Doubling Lemma of D¨utting, Ezra, Feldman, and Kesselheim, 2025.
The Doubling Lemma showed that, for submodular rewards, for every contract ⃗α⋆and PNE of ⃗α⋆,
there exists a scaled contract ⃗α such that any PNE of ⃗α provides a constant-approximation to the
original PNE. We present a new argument that achieves a parallel result for any CCE (rather than
PNE) under the scaled contract, losing only another constant factor. This enables a comparison of
any CCE under a given contract to the best PNE under any contract.
There are two main differences between the two scaling lemmas: First, they give different
types of guarantees: the Scaling-for-Existence Lemma ensures that there exists a good equilibrium,
whereas the Scaling-for-Robustness Lemma ensures that every equilibrium is good. Second, their
domains differ: the existence lemma holds for XOS rewards, while the robustness lemma holds
only for submodular rewards. A lemma unifying both results provably can’t hold. Indeed, for XOS
rewards, there are instances for which the gap between the best and the worst equilibrium is large
(D¨utting, Ezra, Feldman, and Kesselheim, 2025).
Transitions for Supermodular Rewards.
Our results for supermodular rewards exhibit two
perhaps surprising transitions, namely (i) between binary and general actions and (ii) between
7

CE and CCE. Compared to the binary-actions case, arbitrary actions introduce two additional
challenges. First, agents may take actions not present in the original distribution. We address
this by showing that there exists a PNE whose action profile contains the union of the sets in
the support of the correlated equilibrium, rather than matching it exactly, as in the binary case.
Second, a distribution that is only a CCE (and not a CE) may place positive probability on actions
that reduce an agent’s utility under the contract; such actions are not best responses and therefore
cannot appear in any PNE of that contract. Consequently, our proof extends to correlated equilibria
but not to coarse-correlated equilibria. Indeed, our lower-bound construction for CCE shows that
the gap can be unbounded.
1.4
Further Related Work
Inefficiency of Equilibria and Price of Anarchy.
Bounding the inefficiency of equilibria is one
of the staples of algorithmic game theory e.g., Koutsoupias and Papadimitriou, 1999; Roughgarden
and Tardos, 2002; Syrgkanis and Tardos, 2013, and among the main conceptual contributions of
theoretical computer science to economics.
In this regard, our work bears some conceptual resemblance to the smoothness framework for
bounding the price of anarchy (Roughgarden, 2015), in that to bound a ratio under a general
equilibrium concept (CCE), it suffices to bound it under a simpler one (PNE), thereby simplifying
the analysis. Similarly, as in the smoothness framework, it suffices to consider “simple” deviations:
deviation to one’s strategy in an optimal profile in the smoothness framework, and deviation to
taking no action in our case (as captured by the dropout-stability notion).
Two important differences to the Price of Anarchy literature are that the Price of Anarchy
literature is typically interested in the social welfare (or social cost) achieved by equilibria, and
focuses on worst-case equilibria for a fixed game. In contrast, here we are interested in the principal’s
utility and we compare equilibria across different induced games.
Related Studies on Combinatorial Contracts.
Our work builds on the growing body of
research on combinatorial contracts (Feldman, 2025), and in particular contributes to the rapidly
expanding literature on multi-agent contracts. The work that is most related to our work is Babaioff,
Feldman, and Nisan, 2010, who—working in the combinatorial agency model of Babaioff, Feldman,
and Nisan, 2006; Babaioff, Feldman, Nisan, and Winter, 2012—quantify the ratio between the
principal’s utility under mixed and pure strategies, for reward functions exhibiting increasing and
decreasing marginals (corresponding to supermodular and submodular functions, respectively).
We significantly extend this work from binary actions to arbitrary actions, and from mixed Nash
equilibria to more general equilibrium concepts such as correlated and coarse-correlated equilibria—
and on the way we resolve the main open question from this prior work, concerning the gap between
PNE and MNE for submodular rewards
The very recent work of D¨utting, Ezra, Feldman, and Kesselheim, 2025 is another important
reference.
Although their work focuses on pure Nash equilibria, just like most of the existing
literature on multi-agent contracts, they do show a related result: namely, that for the multi-
agent combinatorial actions model that we study in this work, and for submodular rewards, there
exists a contract ⃗α such that the worst-equilibrium under that contract, yields a constant-factor
approximation to the best equilibrium under the best contract. We strengthen this result in two
ways: First, we show that in fact any CCE of the contract returned by the algorithm obtains a
8

constant fraction to the best PNE under any contract. Second, by our lifting result, we extend this
guarantee to the best-CCE benchmark.
Alon, Castiglioni, Chen, Ezra, Li, and Talgam-Cohen, 2025 extend the multi-agent (binary
action) contract design framework to settings with many projects, where the principal needs to
partition the agents among the projects, and within each project, the principal incentivizes the
agents through a contract.
Cacciamani, Bernasconi, Castiglioni, and Gatti, 2024 explore a related multi-agent and (non-
combinatorial) multi-action model, and highlight the value of randomized contracts. In their model,
the principal also uses a randomized contract, which is different from our approach which assumes
that the principal posts a single deterministic contract. They then propose and study an equilibrium
notion, which can be interpreted as a correlated equilibrium when both the principal and the agents
randomize. They show that this type of randomized correlated equilibria are more powerful than
pure Nash equilibria, demonstrating for instance that the principal’s utility can be unboundedly
higher when the setting has a supermodular reward structure. An important difference between
our work and their work is that we consider deterministic contracts.
Finally, slightly more removed from our question and work, Dasaratha, Golub, and Shah, 2025
study a multi-agent multi-action model in which the agents choose from a continuum of effort levels,
and the agent’s choices determine both their costs and the principal’s reward, through cost and
reward functions. The conceptual similarity lies in their treatment of “fractional” actions, akin to
our model where an agent selects different action sets with varying probabilities. However, unlike
our work, they do not consider mixed or correlated equilibria.
2
Preliminaries
Multi-Agent Combinatorial Contracts.
Every agent i ∈[n] has a (finite) set of actions Ai.
The set of actions Ai and Ai′ of any two agents i ≠i′ are disjoint. We denote the set of all actions
by A = ⋃i∈[n] Ai = [m]. An important special case is when for all i ∈[n], it holds that ∣Ai∣= 1. In
this case, each agent can either take action or not. We refer to this as the binary-actions case.
Every agent i can take any subset of actions Si ⊆Ai. We use S = ⋃i∈[n] Si to denote the set
of actions chosen by the agents, and for each agent i ∈[n] we let S−i = ⋃i′≠i Si. (Similarly, for any
S ⊆A we let Si = S ∩Ai.) There is a reward function f ∶2A →R≥0. We generally assume that the
reward function is monotone (non-decreasing) and normalized so that f(∅) = 0. In addition, each
agent has a cost cj for each action j ∈Ai. The cost of a set of actions Si ⊆Ai is c(Si) = ∑j∈Si cj.
For singletons {j} ⊆A, we sometimes use the shorthands f(j) = f({j}) and c(j) = c({j}).
A (linear) contract ⃗α = (α1,...,αn) defines a share αi ∈[0,1] of the reward f(S) that is to
be paid to agent i. The utility of agent i under contract ⃗α when the set of actions chosen by the
agents is S is
ui(S, ⃗α) = αif(S) −c(Si).
The utility of the principal in that case is
uP (S, ⃗α) = ⎛
⎝1 −∑
i∈[n]
αi
⎞
⎠⋅f(S).
Note that, for any set S, the utilities of the agents and the utility of the principal sum up to
f(S) −c(S). We refer to this quantity as the welfare of the set of actions S.
9

We assume that both the principal and the agents are expected utility maximizers; their ex-
pected utilities for a distribution D over sets S ⊆A is ui(D, ⃗α) = ES∼D[ui(S, ⃗α)] and uP (D, ⃗α) =
ES∼D[uP (S, ⃗α)]. We adopt the perspective of the principal and seek a contract that maximizes the
principal’s expected utility.
Equilibrium Concepts.
In multi-agent combinatorial contracts, the principal defines a contract
⃗α and the agents choose their actions in reply to this contract. We are thus looking at a single-leader
multiple-followers Stackelberg game. Specifically, for any fixed contract ⃗α we study a simultaneous
move game among the agents. We consider different equilibrium concepts.
A pure Nash equilibrium is a set of actions S such that no agent wants to deviate from their
choice of action Si to some other action Ti.
Definition 2.1 (Pure Nash Equilibrium). Given reward function f, a pure Nash equilibrium (PNE)
of contract ⃗α is a set of actions S ⊆A such that for every agent i and every Ti ⊆Ai it holds that
αi ⋅f(S−i ∪Si) −c(Si) ≥αi ⋅f(S−i ∪Ti) −c(Ti).
A mixed Nash equilibrium, in turn, is a product distribution D = D1 × ... × Dn over sets of
actions where Di is a distribution over sets of action among Ai, where no agent i strictly wants to
deviate from their distribution Di to a pure strategy Ti ⊆Ai.
Definition 2.2 (Mixed Nash Equilibrium). Given reward function f, a mixed Nash equilibrium
(MNE) of contract ⃗α is a product distribution D = ∏i∈[n] Di over sets S ⊆A such that for every
agent i and every Ti ⊆Ai it holds that
ES∼D[αi ⋅f(S−i ∪Si) −c(Si)] ≥ES∼D[αi ⋅f(S−i ∪Ti) −c(Ti)].
Correlated equilibria are defined as a joint (possibly) correlated distribution over sets of actions.
We can interpret Si as the action recommended to agent i. Then the equilibrium requirement is
that each agent i should prefer to follow their recommended action Si, rather then switching to
some other action πi(Si) whenever they are told Si.
Definition 2.3 (Correlated Equilibrium). Given reward function f, a correlated equilibrium (CE)
of contract ⃗α is a distribution D over sets S ⊆A such that for every agent i and every mapping
πi ∶2Ai →2Ai it holds that
ES∼D[αi ⋅f(S−i ∪Si) −c(Si)] ≥ES∼D[αi ⋅f(S−i ∪πi(Si)) −c(πi(Si))].
The notion of a coarse-correlated equilibrium weakens the equilibrium requirement of a cor-
related equilibrium. Rather than being able to map each recommended action Si to some other
action πi(Si), agent i only considers a single alternative action Ti.
Definition 2.4 (Coarse-Correlated Equilibrium). Given reward function f, a coarse-correlated
equilibrium (CCE) of contract ⃗α is a distribution D over sets S ⊆A such that for every agent i and
every Ti ⊆Ai it holds that
ES∼D[αi ⋅f(S−i ∪Si) −c(Si)] ≥ES∼D[αi ⋅f(S−i ∪Ti) −c(Ti)].
10

Note that the inequality in the definition of CCE is identical to that in the definition of MNE.
The difference is that in an MNE, the distribution D must be a product distribution.
It is not difficult to see that the equilibrium notions are successive relaxations, i.e.,
PNE ⊆MNE ⊆CE ⊆CCE.
While in general games, a pure Nash equilibrium may not exist, games induced by multi-agent
combinatorial action contracts admit a weighted potential function (Deo-Campo Vuong, Dughmi,
Patel, and Prasad, 2024; D¨utting, Ezra, Feldman, and Kesselheim, 2025). Recall that any (finite)
game that admits such a potential function has the finite-improvement property, and hence at least
one pure Nash equilibrium. Another useful property of such games is that any local maximum
of the potential function corresponds to a pure Nash equilibrium of the underlying game. (For a
detailed discussion of potential games see Monderer and Shapley, 1996.)
Recall that a weighted potential function is a function ϕ ∶2A →{−∞}∪R such that ui(Si,S−i, ⃗α) >
ui(S′
i,S−i, ⃗α) implies ϕ(Si,S−i) > ϕ(S′
i,S−i). For any set S and contract ⃗α, let
Φ(S, ⃗α) = f(S) −∑
i∈[n]
c(Si)
αi
,
(1)
where, if αi = 0 we define c(Si)/αi = ∞when c(Si) > 0, and we let c(Si)/αi = 0 when c(Si) = 0.
Proposition 2.5 (Deo-Campo Vuong, Dughmi, Patel, and Prasad, 2024; D¨utting, Ezra, Feldman,
and Kesselheim, 2025). For every contract ⃗α, the function Φ(⋅, ⃗α) is a weighted potential function
in the game induced by the contract ⃗α.
Dropout Stability.
A crucial ingredient in our analysis is the following property, which captures
stability with respect to a unilateral deviation to taking no action.
Definition 2.6 (Dropout Stability). Given reward function f, a distribution D over sets of actions
S is dropout-stable with respect to ⃗α if for every agent i it holds that
ES∼D[αi ⋅f(S) −c(Si)] ≥ES∼D[αi ⋅f(S−i)].
The following observation is immediate.
Observation 2.7. Any coarse-correlated equilibrium of ⃗α is also dropout-stable with respect to ⃗α.
In what follows, it will be useful to have the notion of marginal contribution of an individual
action or set of actions to a given set of actions S.
For an action j ∈A, we write f(j ∣S) =
f(S ∪j) −f(S) for the marginal contribution of action j to S. Similarly, for a set of actions T ⊆A,
we write f(T ∣S) = f(S ∪T) −f(S) for the marginal contribution of the set of actions T to S.
Classes of Reward Functions.
Our main interest will be in the following classes of (non-
negative) reward functions f ∶2A →R≥0. A set function is:
• additive if there exist values f1,...,fm ∈R≥0 such that f(S) = ∑j∈S fj.
• gross-substitutes if for any two vectors p ≤q ∈Rm
+ and any S ⊆A such that S ∈arg maxS′⊆A(f(S′)−
∑j∈S′ pj) there is a T ⊆A with {j ∈S ∣qj ≤pj} ⊆T such that T ∈arg maxT ′⊆A(f(T ′) −∑j∈T ′ qj).
11

• submodular if for every S,S′ ⊆A with S ⊆S′ and any j ∈A it holds that f(j ∣S) ≥f(j ∣S′).
• XOS if there exists a collection of additive functions {aℓ∶2A →R≥0}ℓ=1,...,k such that for each
S ⊆A it holds that f(S) = maxℓ=1,...,k aℓ(S).
• subadditive if for every S,S′ ⊆A, it holds that f(S) + f(S′) ≥f(S ∪S′).
• supermodular if for every S,S′ ⊆A with S ⊆S′ and any j ∈A it holds that f(j ∣S) ≤f(j ∣S′).
All functions in this list except for supermodular belong to the hierarchy of complement-free set
functions. It is well known that additive ⊆gross substitutes ⊆submodular ⊆XOS ⊆subadditive,
and that all containment relations are strict (B. Lehmann, D. Lehmann, and Nisan, 2006).
We consider two standard primitives for accessing combinatorial set functions. A value oracle is
given a set S and returns f(S). A demand oracle is given a set of non-negative prices p1,...,pm ∈
R≥0 and returns a set S that maximizes f(S) −∑j∈S pj.
3
Submodular and XOS Rewards
In this section, we show that, when the rewards are submodular or more generally XOS, there is
a constant gap between the principal’s utility under the best coarse-correlated equilibrium and the
best pure Nash equilibrium. This result is tight in several ways. First, as we demonstrate in Exam-
ple A.1, there is at least a constant gap between mixed Nash equilibria and pure Nash equilibria,
even with gross-substitutes rewards and binary actions. Moreover, as we show in Proposition 4.1,
for subadditive rewards there is at least a polynomial gap, even between mixed and pure Nash
equilibria and the special case of binary actions.
Theorem 3.1 (Black-Box Lifting Theorem). Suppose f is XOS. Let ⃗α⋆be any contract and let
D⋆be any coarse-correlated equilibrium of ⃗α⋆. Then there exists a contract ⃗α and a pure Nash
equilibrium S of ⃗α such that (1 −∑i αi) ⋅f(S) ≥Ω(1) ⋅(1 −∑i α⋆
i ) ⋅ES⋆∼D⋆[f(S⋆)]. Moreover, given
⃗α⋆and D⋆, one can find such ⃗α and S in polynomial time (in n, m and in the support size of D⋆)
using value and demand oracles to f.
To prove Theorem 3.1 we proceed in two steps. In Section 3.1, we present our key new lemma
driving this result, the Scaling-for-Existence Lemma. Afterwards, in Section 3.2, we show how
to use this lemma to establish the theorem. Finally, in Section 3.3 we show how to leverage the
theorem to obtain a poly-time algorithm for submodular rewards, that computes a contract such
that any CCE under that contract provides a constant approximation to the best CCE under the
best contract.
Remark 3.2. We note that the proof of Theorem 3.1 does not use the additivity of the cost
functions, and thus Theorem 3.1 holds even when each agent has an arbitrary normalized (not
necessarily monotone) non-negative combinatorial cost function ci ∶2Ai →R≥0.
3.1
The Scaling-for-Existence Lemma
Our key tool for establishing Theorem 3.1 is the following Scaling-for-Existence Lemma.
The
starting point of this lemma is a coarse-correlated equilibrium D for some contract ⃗α — or, more
precisely, any distribution D over sets that satisfies the weaker dropout-stability condition for
contract ⃗α. The lemma then establishes the existence of a pure Nash equilibrium at an appropriately
scaled contract ⃗α′, that achieves high reward relative to the original distribution D. Our proof relies
12

Algorithm 1 Scaling-for-Existence for XOS Rewards
Input: Costs c1,...,cm ∈R≥0, demand oracle access to a XOS function f ∶2A →R≥0, a subset
of agents N′ ⊆N, a parameter γ > 1, a contract ⃗α and a corresponding CCE D.
Output: A contract ⃗α′ and a PNE S′ of ⃗α′ with f(S′) ≥(1 −1
γ ) ⋅ES∼D[f(⋃i∈N′ Si)].
1: Let α′
i = γ ⋅αi ⋅1[i ∈N′]
2: Let ⃗p be the price vector where p(j) = cj
α′
i for each j ∈Ai
▷Here, 0
0 = 0 and c
0 = ∞for c > 0
3: Let S′ ∈arg maxS⊆A(f(S) −∑j∈S p(j))
4: return ⃗α′,S′
on the property that the expected potential value of any dropout-stable distribution must be non-
negative for XOS reward functions (even when restricted to a subset of agents). This implies that if
a contract is scaled, then there is a PNE with high potential, which bounds from below the reward.
Lemma 3.3 (Scaling-for-Existence Lemma). Suppose f is XOS. Let D be a dropout-stable distri-
bution with respect to ⃗α. For any set of agents N′ ⊆N and γ > 1, let ⃗α′ be defined by α′
i = γ ⋅αi
for i ∈N′ and α′
i = 0 otherwise. Then, there exists a pure Nash equilibrium S′ with respect to ⃗α′,
satisfying
f(S′) ≥(1 −1
γ ) ⋅ES∼D[f( ⋃
i∈N′ Si)].
Moreover, ⃗α′ and S′ can be found in polynomial time (in n, m and in the support size of D⋆) with
demand oracle access to f (see Algorithm 1).
Proof. Consider any N′. We use notation SN′ = ⋃i∈N′ Si. Fix a set S in the support of D. Because
f is XOS, there is an additive function a such that f(S) = a(S) and f(S′′) ≥a(S′′) for all S′′.
Therefore, we have
∑
i∈N′ f(Si ∣S−i) = ∑
i∈N′ (f(S) −f(S−i)) ≤∑
i∈N′ (a(S) −a(S−i)) = ∑
i∈N′ a(Si) = ∑
i∈N′ a(SN′) ≤f(SN′). (2)
Now for any set S define Φ(S, ⃗α) = f(S)−∑i
c(Si)
αi
where 0
0 is interpreted as 0, and c
0 for a positive
c is interpreted as ∞. We observe that for any agent i ∈N with αi = 0, by dropout-stability it holds
that ES∼D[c(Si)] = 0 and therefore Φ(S, ⃗α) is always finite for S in the support of a distribution D
that is dropout-stable with respect to ⃗α.
Then we have
Φ(SN′, ⃗α) = f(SN′) −∑
i∈N′
c(Si)
αi
≥∑
i∈N′ f(Si ∣S−i) −∑
i∈N′
c(Si)
αi
= ∑
i∈N′ (f(Si ∣S−i) −c(Si)
αi
),
where the inequality follows by Inequality (2).
Observe that dropout-stability is equivalent to ES∼D[αi ⋅f(Si ∣S−i) −c(Si)] ≥0 for all i. Then,
by linearity of expectation and dropout-stability, it follows that
ES∼D[Φ(SN′, ⃗α)] ≥0.
(3)
Let S′ be a set of actions maximizing Φ(S′, ⃗α′) (when fixing ⃗α′ as defined in the statement of
the lemma). Then we have
Φ(S′, ⃗α′) ≥ES∼D[Φ(SN′,γ ⃗α)] = ES∼D [f(SN′) −∑
i∈N′
c(Si)
γ ⃗αi
]
13

= (1 −1
γ )ES∼D[f(SN′)] + 1
γ ES∼D[Φ(SN′, ⃗α)] ≥(1 −1
γ )ES∼D[f(SN′)],
where the first inequality follows by the maximality of S′, and the last inequality follows by Eq. (3).
As S′ is a global maximum of Φ(⋅, ⃗α′), it is also a local maximum. Since Φ(⋅, ⃗α′) is a potential
function for the game induced by the contract ⃗α′ (see Proposition 2.5), this means that S′ is a pure
Nash equilibrium with respect to contract ⃗α′. Finally, observe that one can find S′ using a single
demand query with prices cj
α′
i for each action j ∈Ai (where 0
0 is interpreted as 0, and c
0 for c > 0 is
interpreted as ∞). The “moreover” part of the lemma thus follows by noting that Algorithm 1 sets
⃗α′ as stated in the lemma, and chooses S′ as a demand set at these prices.
3.2
Proof of Theorem 3.1
We are now ready to prove Theorem 3.1. The high-level idea is to distinguish cases based on the
correlated equilibrium D⋆at contract α⋆, and whether there is a “significant” agent, namely, an
agent such that α∗
i > 3/4 and (1 −α⋆
i ) ⋅E[f(S⋆
i )] ≥4 ⋅E[f(S⋆
−i)], or not. If there is a significant
agent, we show that we can get a good pure Nash equilibrium by incentivizing that agent alone.
If there is no significant agent, then either (i) there is an agent with α∗
i > 3/4 but (1 −α⋆
i ) ⋅
E[f(S⋆
i )] ≤4 ⋅E[f(S⋆
−i)], or (ii) α∗
i < 3/4 for all agents i. In case (i), we show that dropping agent
i and applying the Scaling-for-Existence Lemma to the remaining agents yields a good pure Nash
equilibrium. (Note that there can be at most one agent with α⋆
i > 3/4 and that ∑i′≠i α⋆
i′ ≤1/4.) In
case (ii), we argue that the agents can be partitioned into two groups B1,B2 such that ∑i′∈Bℓα⋆
i′ ≤
3/4 for ℓ∈{1,2}, and applying the Scaling-for-Existence Lemma to the better of the groups gives
a good pure Nash equilibrium.
Proof of Theorem 3.1. Consider any contract ⃗α⋆and any coarse-correlated equilibrium D⋆with
respect to ⃗α⋆, given as input to Algorithm 2. We analyze the guarantee provided by the contract
computed by this algorithm. In the remainder of the proof, all expectations are over S⋆that is
distributed according to D⋆. We consider three cases:
Case A: There exists an agent i with α⋆
i > 3/4 and (1 −α⋆
i ) ⋅E[f(S⋆
i )] ≥4 ⋅E[f(S⋆
−i)]. In this
case, since α⋆
i > 3/4, we have E[f(S⋆
i )] ≥16 ⋅E[f(S⋆
−i)]. By subadditivity of f, this implies that
E[f(S⋆
i )] ≥16 ⋅E[(f(S⋆) −f(S⋆
i ))], or equivalently, E[f(S⋆
i )] ≥16
17 ⋅E[f(S⋆)].
Consider contract ⃗α with αi = 1+α⋆
i
2
and αj = 0 for j ≠i.
Note that αi > α⋆
i .
Also note
that for agents j ≠i doing nothing is a best response no matter what the other agents do. Let
S = (Si,∅) be any pure Nash equilibrium of ⃗α (such that S′
j = ∅for all j ≠i). We next show that
f(Si) ≥1
2 ⋅E[f(S⋆
i )].
First observe that since S = (Si,∅) is a pure Nash equilibrium of ⃗α, we have
αif(Si) −c(Si) ≥E[αif(S⋆
i ) −c(S⋆
i )].
(4)
On the other hand, since D is a coarse-correlated equilibrium of ⃗α⋆, it must hold that
E[α⋆
i f(S⋆
i ∣S⋆
−i) −c(S⋆
i )] ≥E[α⋆
i f(Si ∣S⋆
−i) −c(Si)].
By subadditivity of f, we have f(S⋆
i ∣S⋆
−i) = f(S⋆
i ∪S⋆
−i) −f(S⋆
−i) ≤f(S⋆
i ). By monotonicity of f,
we have f(Si ∣S⋆
−i) = f(Si ∪S⋆
−i) −f(S⋆
−i) ≥f(Si) −f(S⋆
−i). We thus obtain
E[α⋆
i f(S⋆
i ) −c(S⋆
i )] ≥E[α⋆
i f(Si) −α⋆
i f(S⋆
−i) −c(Si)].
(5)
14

Algorithm 2 Black-Box Lifting for XOS Rewards
Input: Costs c1,...,cm ∈R≥0, value and demand oracle access to a XOS function f ∶2A →R≥0,
a contract ⃗α⋆, and a corresponding CCE D⋆.
Output: A contract ⃗α, and a PNE S with (1 −∑i αi)f(S) ≥Ω(1)(1 −∑i α⋆
i )ES⋆∼D⋆[f(S⋆)].
1: if maxj α⋆
j > 3/4 then
2:
Let i = arg maxj α⋆
j
▷There must be a unique maximum
3:
if (1 −α⋆
i ) ⋅ES⋆∼D⋆[f(S⋆
i )] ≥4 ⋅ES⋆∼D⋆[f(S⋆
−i)] then
4:
Set ⃗α such that αi = 1+α⋆
i
2
and αj = 0 for j ≠i
5:
Let S ∈arg maxS′⊆Ai(f(S′) −c(S′)
αi )
6:
return ⃗α,S
7:
else
8:
Apply Algorithm 1 with D⋆, ⃗α⋆, N′ = [n] ∖{i} and γ = 2 to obtain ⃗α and S
9:
return ⃗α,S
10:
end if
11: else
12:
Partition N into two bundles B1,B2, where for each ℓ∈{1,2}, ∑i∈Bℓα⋆
i ≤3/4
13:
Let ℓ∈arg maxℓ′∈{1,2} ES⋆∼D⋆[f(⋃i∈Bℓ′ S⋆
i )]
14:
Apply Algorithm 1 with D⋆, ⃗α⋆, N′ = Bℓand γ = 7
6 to obtain ⃗α and S
15:
return ⃗α,S
16: end if
By summing up (4) and (5), using linearity of expectation, we get
(αi −α⋆
i )f(Si) ≥(αi −α⋆
i ) ⋅E[f(S⋆
i )] −α⋆
i ⋅E[f(S⋆
−i)].
(6)
Thus, using that αi > α⋆
i ,
f(Si)
≥
E[f(S⋆
i )] −
α⋆
i
αi −α⋆
i
E[f(S⋆
−i)] = E[f(S⋆
i )] −
2α⋆
i
1 −α⋆
i
E[f(S⋆
−i)]
≥
E[f(S⋆
i )] −
2α⋆
i
1 −α⋆
i
⋅1 −α∗
i
4
⋅E[f(S⋆
i )] ≥1
2E[f(S⋆
i )],
(7)
where the first inequality is by rearranging Inequality (6), the equality is by the definition of αi,
the second inequality is by the assumption of the case, and the last inequality is since α⋆
i ≤1.
Overall, the principal’s utility under contract ⃗α and equilibrium S is
(1 −∑
j
αj) ⋅f(S) = (1 −αi) ⋅f(Si) = 1
2(1 −α⋆
i ) ⋅f(Si) ≥1
4(1 −α⋆
i ) ⋅E[f(S⋆
i )]
≥1
4(1 −∑
j
α⋆
j ) ⋅E[f(S⋆
i )] ≥4
17(1 −∑
j
α⋆
j ) ⋅E[f(S⋆)],
where the second equality follows by the definition of αi. This concludes the argument for this
case.
Case B: There exists an agent i with α⋆
i > 3/4 and (1 −α⋆
i ) ⋅E[f(S⋆
i )] ≤4 ⋅E[f(S⋆
−i)]. In this
case, let ⃗α be the contract where αi = 0 and αj = 2α⋆
j for j ≠i. By applying Lemma 3.3 on D⋆, ⃗α⋆,
15

N′ = [n]∖{i} and γ = 2 we get that there exists a pure Nash equilibrium S with respect to contract
⃗α such that
f(S) ≥1
2E
⎡⎢⎢⎢⎣
f( ⋃
j∈N′ S⋆
j )
⎤⎥⎥⎥⎦
.
(8)
We can bound the principal’s utility under ⃗α⋆and D⋆by
⎛
⎝1 −∑
j
α⋆
j
⎞
⎠E [f(S⋆)]
≤
⎛
⎝1 −∑
j
α⋆
j
⎞
⎠E [f(S⋆
i )] + ⎛
⎝1 −∑
j
α⋆
j
⎞
⎠E [f(S⋆
−i)]
≤
(1 −α⋆
i )E [f(S⋆
i )] + E [f(S⋆
−i)] ≤5 ⋅E [f(S⋆
−i)],
(9)
where the first inequality is by subadditivity, and the last inequality is by the assumption of the
case.
One the other hand, under contract ⃗α (for which ∑j αj = ∑j≠i 2α⋆
j ≤2(1 −α⋆
i ) ≤
1
2), and
equilibrium S, the principal’s utility is
(1 −∑
j
αj)f(S)
(8)
≥(1 −∑
j≠i
2α⋆
j ) ⋅1
2E
⎡⎢⎢⎢⎣
f( ⋃
j∈N′ S⋆
j )
⎤⎥⎥⎥⎦
≥1
4E [f(S⋆
−i)]
(9)
≥
1
20
⎛
⎝1 −∑
j
α⋆
j
⎞
⎠E [f(S⋆)],
which concludes the proof of the case.
Case C: α⋆
i ≤3/4 for every i. We claim that the agents can be partitioned into two bundles B1,B2,
where for each ℓ∈{1,2}, ∑i∈Bℓα⋆
i ≤3/4. To see this, consider the following process. We start by
creating a separate bundle for each agent. Note that this way, by the assumption of the case, each
bundle has sum of α⋆
i at most 3/4. Then, as long as there are two bundles with sum of α⋆
i less
than 3/4 we merge them. This process is well-defined and terminates with two bundles with the
desired property since as long as there are more than two bundles, since ∑i α⋆
i ≤1, there must be
two bundles with sum of α⋆
i at most 2/3, so we can merge two of them.
Now, assume without loss of generality that
E[f( ⋃
i∈B1
S⋆
i )] ≥E[f( ⋃
i∈B2
S⋆
i )].
(10)
Let ⃗α be the contract where αi = 0 for i ∈B2 and αi = 7
6α⋆
i for i ∈B1. By applying Lemma 3.3 on
D⋆, ⃗α⋆, N′ = B1 and γ = 7/6 we get that there exists an equilibrium S with respect to contract ⃗α
such that
f(S) ≥1
7E [f( ⋃
i∈B1
S⋆
i )].
(11)
The principal’s utility from ⃗α and S is
(1 −∑
i
αi)f(S)
≥
(1 −7
6 ∑
i∈B1
α⋆
i ) ⋅1
7 ⋅E [f( ⋃
i∈B1
S⋆
i )] ≥(1 −7
6 ⋅3
4) ⋅1
7 ⋅E [f( ⋃
i∈B1
S⋆
i )]
≥
1
56
E [f(⋃i∈B1 S⋆
i )] + E [f(⋃i∈B2 S⋆
i )]
2
≥E[f(S⋆)]
112
,
where the first inequality is by the definition of ⃗α and by Inequality (11), the second inequality is
since ∑i∈B1 α⋆
j ≤3/4, the third inequality is since by Inequality (10), and the last inequality is by
subadditivity. This concludes the proof of the theorem.
16

3.3
Robustness and Tractability
We next derive our robust approximation results. To this end, we show that for submodular rewards
it is possible to turn any contract ⃗α⋆and pure Nash equilibrium S⋆of that contract into a contract
⃗α such that any CCE under ⃗α achieves a constant approximation to the principal’s utility under
S⋆.
Theorem 3.4 (Black-Box Robustness Theorem). Let f be a submodular reward function. There
exists an algorithm (Algorithm 3 in Appendix B) that runs in polynomial time (in n and m) using
only value queries to f, that, given a contract ⃗α⋆and a corresponding PNE S⋆, outputs a contract
⃗α such that for every CCE D of ⃗α,
(1 −∑
i
αi) ⋅ES∼D[f(S)] ≥Ω(1) ⋅(1 −∑
i
α⋆
i ) ⋅f(S⋆).
Using (D¨utting, Ezra, Feldman, and Kesselheim, 2023) and (D¨utting, Ezra, Feldman, and
Kesselheim, 2025) and combining with Theorem 3.1 we obtain the following corollary:
Corollary 3.5 (Efficient Robust Approximation Algorithms). For submodular rewards there is an
algorithm that runs in polynomial time using value and demand queries and finds a contract ⃗α such
that any CCE of ⃗α obtains an O(1)-approximation to the principal’s optimal utility under the best
CCE under any contract. For binary actions the same guarantee can be achieved with value queries
only.
The key tool for proving Theorem 3.4 is a Scaling-for-Robustness Lemma—a strengthened
version of the Doubling Lemma from D¨utting, Ezra, Feldman, and Kesselheim, 2025.2 This lemma
plays a role orthogonal to the Scaling-for-Existence Lemma: rather than showing the existence of a
contract and a PNE which is good relative to a reference CCE, it is used to derive a contract under
which every CCE is good with respect to a reference PNE. Similar to the Scaling-for-Existence
Lemma, rather than working directly with the reference equilibrium, it starts from a dropout
stable distribution over sets of actions.
Lemma 3.6 (Scaling-for-Robustness Lemma). Suppose f is submodular. Let ϵ > 0 and let ⃗ϵ =
(ϵ,...,ϵ) ∈Rn
+. Let γ > 1. Let D be a dropout-stable distribution with respect to ⃗α. Then any
coarse correlated equilibrium (CCE) D† with respect to γ ⃗α + ⃗ϵ satisfies ES†∼D†[f(S†)] ≥1
2(1 −
1
γ )ES∼D[f(S)].
Proof. Let D be a dropout-stable distribution with respect to ⃗α, and let D† be a CCE with respect
to γ ⃗α+⃗ϵ. As D† is a CCE with respect to γ ⃗α+⃗ϵ, agent i weakly prefers taking action set S†i drawn
from D† over Si drawn independently from D. That is,
ES†∼D†[(γαi + ϵ)f(S†) −c(S†i)] ≥(γαi + ϵ)ES†∼D†,S∼D[f(S†−i ∪Si)] −c(Si).
Rearranging the terms and taking the sum over all agents i, we obtain
ES†∼D†,S∼D [
n
∑
i=1
f(S†i ∣S†−i) −
n
∑
i=1
f(Si ∣S†−i) +
n
∑
i=1
c(Si) −c(S†i)
γαi + ϵ
] ≥0.
(12)
2While the Doubling Lemma by D¨utting, Ezra, Feldman, and Kesselheim, 2025 applies to any PNE of the scaled
contract, our Scaling-for-Robustness Lemma applies even with respect to any CCE of the scaled contract.
17

By submodularity of f, for any S† it holds that
n
∑
i=1
f(S†i ∣S†−i) ≤f(S†),
(13)
while for any S,S† it holds that
n
∑
i=1
f(Si ∣S†−i) ≥f(S ∖S† ∣S†)
(14)
Also, as D is dropout-stable, we furthermore have for every agent i that ES∼D[αif(S)−c(Si)] ≥
ES∼D[αif(S−i)], implying that
ES∼D[c(Si)]
αi
≤ES∼D[f(Si ∣S−i)].
(15)
Therefore, it holds that
ES†∼D†,S∼D [
n
∑
i=1
c(Si) −c(S†i)
γαi + ϵ
] ≤
n
∑
i=1
ES∼D[c(Si)]
γαi + ϵ
≤1
γ
n
∑
i=1
ES∼D[c(Si)]
αi
≤1
γ
n
∑
i=1
ES∼D[f(Si ∣S−i)] ≤ES∼D[f(S)]
γ
, (16)
where the next-to-last inequality follows by Equation (15), and the final one holds by submodularity
of f.
Combining Inequalities (13), (14), we get that for any S,S†,
n
∑
i=1
f(S†i ∣S†−i) −
n
∑
i=1
f(Si ∣S†−i) ≤f(S†) −f(S ∖S† ∣S†) = 2f(S†) −f(S ∪S†) ≤2f(S†) −f(S).
Taking expectation over the last inequality and combining it with Equation (12) and (16) gives
0 ≤ES†∼D†,S∼D [
n
∑
i=1
f(S†i ∣S†−i) −
n
∑
i=1
f(Si ∣S†−i) +
n
∑
i=1
c(Si) −c(S†i)
γαi + ϵ
]
≤ES†∼D†,S∼D [2f(S†) −(1 −1
γ )f(S)],
yielding ES†∼D†,S∼D [2f(S†) −(1 −1
γ )f(S)] ≥0, and thus ES†∼D†[f(S†)] ≥1
2(1 −1
γ )ES∼D†[f(S)],
as desired.
The proof of Theorem 3.4 concludes by applying Lemma 3.6 to analyze the contract returned
by Algorithm 3 (see Appendix B for details).
4
Subadditive Rewards
In this section, we show that for subadditive rewards, there is a Θ(poly(n)) gap between the
principal’s utility under the best coarse-correlated equilibrium and the best pure Nash equilibrium.
We first show that this gap arises already between mixed and pure Nash equilibria, and even with
binary actions.
18

Proposition 4.1 (Subadditive Rewards). There exists a binary-action instance with a subadditive
reward function in which the gap between the principal’s utility under the best MNE and under the
best PNE is Ω(√n).
Proof. Consider a setting with 2n + 2 agents denoted by A = {x,y} ∪[2n]. We define the reward
function f ∶2A →R≥0 in Table 2. The costs of agents x and y are 0, and the costs of all remaining
agents are ci =
2
3n.
∣S ∩{x,y}∣
∣S ∩[2n]∣
0
0 < i < 2n −1
2n −1
2n
[n] ⊆S
[n] /⊆S
0
0
2 +
i
√n
2 + 2n−1
√n
3 + 2n−1
√n
4 + 2n−1
√n
1
4
4 +
i
√n
5 + 2n−1
√n
4 + 2n−1
√n
6 + 2n−1
√n
2
5
5 +
i
√n
5 + 2n−1
√n
6 + 2n−1
√n
7 + 2n−1
√n
Table 2: Definition of the monotone subadditive function f ∶2[2n]∪{x,y} →R≥0. The value of a set
S is determined by ∣S ∩{x,y}∣and ∣S ∩[2n]∣, and in the case ∣S ∩[2n]∣= 2n −1, by whether the
missing element belongs to [n].
Claim 4.2. The function f is monotone and subadditive.
Proof. We first prove that the function f is monotone. Afterwards, we show that it is subadditive.
Monotonicity.
To see that f is monotone, we can observe that all of the marginals (presented
in Tables 3 and 4) are non-negative.
∣S ∩{x,y}∣
∣S ∩[2n]∣
0
0 < i < 2n −1
2n −1
2n
[n] ⊆S
[n] /⊆S
0
4
2
3
1
2
1
1
1
0
2
1
Table 3: The marginal f(j ∣S) for j ∈{x,y}.
Subadditivity.
To see that f is subadditive, observe that for every T ≠∅, it holds that
f(T) ≥2 + 2 ⋅1[∣{x,y} ∩T∣≥1] + 1[∣{x,y} ∩T∣≥2] + ∣T ∖{x,y}∣
√n
,
(17)
on the other hand
f(T) ≤4 + 2 ⋅1[∣{x,y} ∩T∣≥1] + 1[∣{x,y} ∩T∣≥2] + ∣T ∖{x,y}∣
√n
.
(18)
19

∣S ∩{x,y}∣
∣S ∩[2n]∣
0
0 < i < 2n −2
2n −2
2n −1
[n] ∖{j} ⊆S
[n] ∖{j} /⊆S
j ∈[n]
j ∉[n]
0
2 +
1
√n
1
√n
1
√n
1 +
1
√n
1
2
1
1
√n
1
√n
1 +
1
√n
1
√n
2
1
2
1
√n
1
√n
1
√n
1 +
1
√n
1
2
Table 4: The marginal f(j ∣S) for j ∈[2n].
Thus,
f(S) + f(T)
≥
2 + 2 + 2 ⋅1[∣{x,y} ∩S∣≥1] + 2 ⋅1[∣{x,y} ∩T∣≥1]
+
1[∣{x,y} ∩S∣≥2] + 1[∣{x,y} ∩T∣≥2] + ∣S ∖{x,y}∣
√n
+ ∣T ∖{x,y}∣
√n
≥
4 + 2 ⋅1[∣{x,y} ∩(S ∪T)∣≥1] + 1[∣{x,y} ∩(S ∪T)∣≥2] + ∣S ∪T ∖{x,y}∣
√n
≥
f(S ∪T),
where the first inequality is by Inequality (17), the second inequality is by subadditivity of the indi-
cator function, and since ∣S∩[2n]∣
√n
is an additive function, and the last inequality is by Inequality (18)
This concludes the proof of the claim.
Claim 4.3. No PNE achieves a principal utility of more than 6.5.
Proof. Let S be some PNE. If ∣S ∩[2n]∣≤1 then the utility of the principal is bounded by the
reward which is bounded by 5 +
1
√n. If 1 < ∣S ∩[2n]∣< 2n −1 then the marginal of all agents in
S ∩[2n] are
1
√n, which means that the principal’s utility is bounded by f(S)(1 −∣S ∩[2n]∣⋅ci
√n),
which is negative for ∣S ∩[2n]∣> 3√n
2 , thus, the utility of principal is bounded by 5 +
3√n/2
√n = 6.5.
For S with ∣S ∩[2n]∣= 2n −1, the marginals of all the 2n −1 agents in ∣S ∩[2n] is bounded by
1 +
1
√n, thus the fraction that remains with the principal is 1 −(2n −1)
2/3n
1+ 1
√n
< 0, which means that
the principal obtains a negative utility from incentivizing this set. If ∣S ∩[2n]∣= 2n, then half of
the agents (in [2n] have a marginal of 1, and the remaining half have marginals of 2. Thus, the
fraction of the reward that remains with the principal is 1 −n
2/3n
1 −n
2/3n
2
= 0, which means that the
principal cannot obtain positive utility from incentivizing this set.
Claim 4.4. There exists a MNE that achieves a principal utility of Ω(√n).
Proof. Consider the MNE where all agents in [2n] take action with a probability of 1, and agents
x,y take action (each) with a probability of 1
2.
Since the costs of x,y are zero, we could use
αx = αy = 0. For the remaining agents, the expected marginal contribution of them to the reward is
1.5 since with probability 1
2 their marginal contribution is 1, and with probability half their marginal
contribution is 2. Thus, it is sufficient to use contract
ci
1.5 =
4
9n to incentivize them. Overall, the
20

utility of the principal from this MNE is E[f(S)](1−2n⋅4
9n) = ( 1
4 ⋅4+ 1
2 ⋅6+ 1
4 ⋅7+ 2n−1
√n )⋅1
9 = Ω(√n),
which concludes the proof.
The proof of the proposition follows from Claims 4.2, 4.3, and 4.4.
We next show that the gap between the principal’s utility under the best CCE and the best
PNE is at most polynomial in the number of agents.
Proposition 4.5. The gap between the principal’s utility under the best CCE and under the best
PNE is at most O(n).
The proof of Proposition 4.5 is deferred to Appendix C.
Remark 4.6. We note that D¨utting, Ezra, Feldman, and Kesselheim (2025) show that the prin-
cipal’s utility under the best PNE is at least a
1
m-fraction of the optimal welfare (which trivially
bounds the principal’s utility under the best CCE). This implies an upper bound of m on the
gap between the utility under the best CCE and the best PNE for subadditive reward functions.
Proposition 4.5 establishes a stronger upper bound that does not depend on the number of actions,
but only on the number of agents.
5
Supermodular Rewards
In this section, we establish our results for supermodular rewards. We first show that with binary
actions, there is no gap between the principal’s utility in the best coarse-correlated equilibrium and
the best pure Nash equilibrium.
Theorem 5.1 (Supermodular Rewards, Binary Actions). There exists no gap between the princi-
pal’s utility under the best CCE and the best PNE in binary-action settings.
Proof. Consider a contract ⃗α, and a CCE D. Let S′ be the union of the sets of agents that are in
the support of D. Let ⃗α′ be the contract for which α′
i = 0 for i /∈S′, and α′
i = αi for i ∈S′. We prove
that S′ is a pure Nash equilibrium with respect to ⃗α′.
In the remainder of the proof, all expectations (and probabilities) are over S, which is distributed
according to D. As D is a coarse-correlated equilibrium, no agent can improve their utility by
unilaterally not working anymore. That is, for all i ∈S′, we have
E[αi ⋅f(S) −ci1[i ∈S]] ≥E[αi ⋅f(S ∖{i})],
or equivalently
E[αi ⋅(f(S) −f(S ∖{i})) −ci1[i ∈S]] ≥0.
For every set S in the support of D and every agent i ∈A we have
f(i ∣S ∖{i}) = (f(S) −f(S ∖{i})) ⋅1[i ∈S] ≤f(i ∣S′ ∖{i}) ⋅1[i ∈S],
where the last inequality is since f is supermodular, and S ⊆S′. In combination, this means that
Pr [i ∈S](αi ⋅f(i ∣S′ ∖{i}) −ci) = E[αi ⋅f(i ∣S′ ∖{i}) ⋅1[i ∈S] −ci ⋅1[i ∈S]] ≥0.
So, if i ∈S′, then αi ⋅f(i ∣S′ ∖{i}) −ci ≥0, meaning that αif(S′) −ci ≥αif(S′ ∖{i}), and therefore
α′
if(S′)−ci ≥α′
if(S′ ∖{i}), which means that agent i does not want to deviate. For i /∈S′, it holds
that α′
i ⋅f(i ∣S′) = 0 ≤ci, which means that agent i does not want to deviate. Overall, we deduce
that S′ is a pure Nash equilibrium with respect to contract ⃗α′.
21

We next consider the general (non-binary) setting for which we show that there is no gap
between CE and PNE.
Theorem 5.2 (Supermodular Rewards, General Actions). There exists no gap between the utility
of the principal under the best CE and the best PNE.
Proof. Consider a contract ⃗α and a correlated equilibrium D with respect to this contract. Let
T = ∪S∈sup(D)S. Before proving the theorem we are first going to prove the following key lemma.
Lemma 5.3. For every agent i, assuming that every agent j ≠i selects a set of actions Sj such
that Tj ⊆Sj (where we denote by S−i = ∪j≠iSj), then there exists a set Si for which Ti ⊆Si that is
agent i’s best response. I.e.,
Si ∈arg max
Xi⊆Ai αif(Xi ∪S−i) −c(Xi).
Proof. Let S1
i ,...,Sk
i be the support of the sets taken by agent i according to D (ordered arbi-
trarily). Consider an arbitrary set Ri in arg maxXi⊆Ai αif(Xi ∪S−i) −c(Xi). For j = 0,...,k, let
Rj
i = Ri ∪⋃j
ℓ=1 Sℓ
i (where R0
i = Ri). We denote by D−i(Sj
i ) the distribution of the set of actions
suggested to agents N ∖{i}, conditioned on agent i suggested the action set Sj
i . By that D is a
correlated equilibrium, we have that
αi ⋅EX−i∼D−i(Sj
i )[f(Sj
i ∪X−i)] −c(Sj
i ) ≥αi ⋅EX−i∼D−i(Sj
i )[f((Sj
i ∩Rj−1
i
) ∪X−i)] −c(Sj
i ∩Rj−1
i
),
or by rearranging, and since Sj
i ∖Rj−1
i
= Rj
i ∖Rj−1
i
we get that
αi ⋅EX−i∼D−i(Sj
i )[f(Rj
i ∖Rj−1
i
∣(Sj
i ∩Rj−1
i
) ∪X−i)] ≥c(Rj
i ∖Rj−1
i
).
Now, since (1) X−i ⊆S−i for each realization in the support of D−i(Sj
i ), (2) Sj
i ∩Rj−1
i
⊆Rj−1
i
, (3)
Rj
i ∖Rj−1
i
is disjoint from Rj−1
i
∪S−i, and (4) f is supermodular, we deduce that
αi ⋅EX−i∼D−i(Sj
i )[f(Rj
i ∖Rj−1
i
∣Rj−1
i
∪S−i)] ≥c(Rj
i ∖Rj−1
i
).
Since the last expression is deterministic (as it does not depend on the realization of X−i), we
conclude that
αi ⋅f(Rj
i ∖Rj−1
i
∣Rj−1
i
∪S−i) ≥c(Rj
i ∖Rj−1
i
).
By summing over j ∈[k] we obtain that
αi ⋅(f(Rk
i ∪S−i) −f(R0
i ∪S−i)) ≥c(Rk
i ∖R0
i ),
which by rearrangement we conclude that
αi ⋅f(Rk
i ∪S−i) −c(Rk
i ) ≥αi ⋅f(R0
i ∪S−i) −c(R0
i ).
Since R0
i = Ri, and Ri ∈arg maxXi⊆Ai αif(Xi ∪S−i) −c(Xi) this implies that
Rk
i ∈arg max
Xi⊆Ai αif(Xi ∪S−i) −c(Xi).
This concludes the proof of the lemma since Ti = ∪jSj
i ⊆Rk
i .
22

We are now ready to prove the theorem. For this, we observe that if we start with T, and as
long as some agent i can strictly improve her utility, she improves her utility to a set containing Ti
(which is without loss because of Lemma 5.3), this process maintains the property that the action
profile always contains T. Moreover, the process must terminate after a finite number of steps, as
at each step, the value of the potential function (see Equation (1)) strictly increases, and this is a
finite function.
We next prove that Theorem 5.2 is tight by presenting an instance with a supermodular reward
function, for which there is an unbounded gap in the principal’s utility that can be obtained from
a CCE compared to a PNE.
Proposition 5.4 (Supermodular Rewards, General Actions). There exists an instance in which
the gap between the principal’s utilities under the best CCE and under the best PNE is unbounded.
Proof. Consider an instance with two agents where A1 = {1,2}, and A2 = {3}. Let f ∶2A →R≥0 be
as defined as in Table 5. The function f is monotone and supermodular. The costs of the actions
are c(1) = 0.75, c(2) = 8.5 and c(3) = 0.25.
S
∅
{1}
{2}
{3}
{1,2}
{1,3}
{2,3}
{1,2,3}
f(S)
0
0
1
0
5.5
1
1
10
Table 5: A supermodular reward function f with unbounded gap between the best CCE and the
best PNE.
Note that the only set of actions with a positive welfare is {1,2,3}. Thus, this is the only
candidate for a PNE with a positive utility for the principal. To incentivize {1,2,3}, the principal
must use a contract ⃗α such that α1 ⋅f({1,2} ∣{3}) −c({1,2}) ≥α1 ⋅f(1 ∣{3}) −c(1) and α2f(3 ∣
{1,2}) ≥c(3), thus α1 ≥8.5/9 = 17/18, and α2 ≥0.25/4.5 = 1/18, thus the principal cannot obtain a
positive utility.
Consider the contract ⃗α3 = (0.925,1/18). It holds that the distribution D where {1,2,3} is
suggested with probability 0.8, and ∅is suggested with probability 0.2 is a CCE. Indeed this is a
CCE since the utility of agent 2 when following the suggestion is 0.8⋅(α2⋅f({1,2,3})−c(3)) = 11/45,
while if agent 2 does nothing, his utility is 0.8(α2 ⋅f({1,2})) = 11/45, and if he always takes action
3, his utility is 0.8α2f({1,2,3}) + 0.2α2f(3) −c(3) = 7/36 < 11/45.
For agent 1, following the
suggestion of the principal leads to a utility of 0.8 ⋅(0.925 ⋅10 −9.25) = 0. Now deviating to ∅
leads to a utility of 0, deviating to {1} leads to a utility of 0.8 ⋅0.925 ⋅1 −0.75 = −0.01, deviating
to {2} leads to a utility of α1 ⋅1 −c(2) = −7.575, and deviating to {1,2} leads to a utility of
0.8 ⋅0.925 ⋅10 + 0.2 ⋅0.925 ⋅5.5 −9.25 = −0.8325. Thus, it is a CCE.
The utility of the principal under this CCE is (1 −0.925 −1/18) ⋅0.8 ⋅10 = 7/45 > 0, which
concludes the proof.
6
General Rewards
In this section, we show a lower bound on the gap between the principal’s utility from the best MNE
and the best PNE for general reward functions (that are neither subadditive, nor supermodular).
We show that this gap is unbounded, even for a constant number of agents and binary actions.
23

Proposition 6.1 (General Rewards). There exists a binary-action instance in which the gap be-
tween the principal’s utility under the best MNE and under the best PNE is unbounded.
Proof. Consider a binary-action instance with four agents, i.e., A = {1,2,3,4}. The reward function
is defined by the monotone closure of the following values (i.e., the maximum over all defined
subsets). Let
f({1,2}) = 2,f({1,3}) = f({2,4}) = 1,f({1,2,3}) = f({1,2,4}) = ϕ + 1,
where ϕ = 1+
√
5
2
≈1.618 (i.e., ϕ is the golden ratio). Note that f is not subadditive (as f(1)+f(2) <
f({1,2}), nor supermodular (as f({1,2,3} + f({1,2,4}) ≥f({1,2} + f({1,2,3,4})).
The costs are
c(1) = c(2) = 1, and c(3) = c(4) = 0.
We next calculate the utility of the principal under a PNE corresponding to all non-redundant sets
of agents (sets that do not contain an agent with a 0 marginal, and non-zero cost). For this, we
utilize the characterization of Babaioff, Feldman, and Nisan, 2006 for the principal’s utility function
as a function of the PNE for binary instances:
g(S) = f(S)(1 −∑
i∈S
c(i)
f(i ∣S ∖{i})).
It holds that:
g({1,2}) = f({1,2})(1 −
c(1)
f(1 ∣{2}) −
c(2)
f(2 ∣{1})) = 0
g({1,3}) = f({1,3})(1 −
c(1)
f(1 ∣{3})) = 0
g({1,3,4}) = f({1,3,4})(1 −
c(1)
f(1 ∣{3,4})) = 0
g({2,4}) = f({2,4})(1 −
c(2)
f(2 ∣{4})) = 0
g({2,3,4}) = f({2,3,4})(1 −
c(2)
f(2 ∣{3,4})) = 0
g({1,2,3}) = f({1,2,3})(1 −
c(1)
f(1 ∣{2,3}) −
c(2)
f(2 ∣{1,3})) = f({1,2,3})(1 −
1
ϕ + 1 −1
ϕ) = 0
g({1,2,4}) = f({1,2,4})(1 −
c(1)
f(1 ∣{2,4}) −
c(2)
f(2 ∣{1,4})) = f({1,2,4})(1 −1
ϕ −
1
ϕ + 1) = 0
g({1,2,3,4}) = f({1,2,3,4})(1 −
c(1)
f(1 ∣{2,3,4}) −
c(2)
f(2 ∣{1,3,4})) = f({1,2,3,4})(1 −1
ϕ −1
ϕ) < 0
Thus, no PNE obtains a positive utility for the principal.
Consider the contract ⃗α = ( 4
5ϕ, 4
5ϕ,0,0), and the distribution D over agents where agents 1,2
always take an action with probability 1, and agents 3 and 4 take an action with probability 1 −ϕ
2
24

each (independently). The expected marginal of agent 1 (similarly, of agent 2) is: (1 −ϕ
2)2 ⋅ϕ +
( ϕ
2)(1 −ϕ
2) ⋅ϕ + (1 −ϕ
2)( ϕ
2)(ϕ + 1) + ( ϕ
2)2 ⋅2 = 5ϕ
4 . Distribution D is a MNE since agent 1 (similarly,
agent 2) is paid
c(1)
ES∼D[f(1∣S∖{1})] =
4
5ϕ. The principal’s utility under this MNE is
(1 −2 ⋅4
5ϕ)(ϕ + 1
4
⋅2 + (1 −ϕ + 1
4
) ⋅(ϕ + 1)) > 0,
which concludes the proof.
References
Alon, Tal, Matteo Castiglioni, Junjie Chen, Tomer Ezra, Yingkai Li, and Inbal Talgam-Cohen
(2025). “Multi-Project Contracts”. In: Proceedings of the 26th ACM Conference on Economics
and Computation, pp. 580–598.
Babaioff, Moshe, Michal Feldman, and Noam Nisan (2006). “Combinatorial agency”. In: Proc. of
EC 2006, pp. 18–28.
— (2010). “Mixed Strategies in Combinatorial Agency”. In: J. Artif. Intell. Res. 38, pp. 339–369.
Babaioff, Moshe, Michal Feldman, Noam Nisan, and Eyal Winter (2012). “Combinatorial agency”.
In: J. Econ. Theory 3.147, pp. 999–1034.
Cacciamani, Federico, Martino Bernasconi, Matteo Castiglioni, and Nicola Gatti (2024). “Multi-
agent contract design beyond binary actions”. In: Proc. of EC 2024.
Castiglioni, Matteo, Alberto Marchesi, and Nicola Gatti (2023). “Multi-agent contract design: How
to commission multiple agents with individual outcomes”. In: Proc. of EC 2023, pp. 412–448.
Dasaratha, Krishna, Benjamin Golub, and Anant Shah (2025). “Incentive Design with Spillovers”.
In: Proc. of EC 2025.
Deo-Campo Vuong, Ramiro, Shaddin Dughmi, Neel Patel, and Aditya Prasad (2024). “On Super-
modular Contracts and Dense Subgraphs”. In: Proc. of SODA 2024, pp. 109–132.
D¨utting, Paul, Tomer Ezra, Michal Feldman, and Thomas Kesselheim (2021). “Combinatorial Con-
tracts”. In: Proc. of FOCS 2021, pp. 815–826.
— (2023). “Multi-agent Contracts”. In: Proc. of STOC 2023, pp. 1311–1324.
— (2025). “Multi-Agent Combinatorial Contracts”. In: Proc. of SODA 2025, pp. 1857–1891.
D¨utting, Paul, Michal Feldman, and Yoav Gal-Tzur (2024). “Combinatorial Contracts Beyond
Gross Substitutes”. In: Proc. of SODA 2024, pp. 92–108.
D¨utting, Paul, Michal Feldman, Yoav Gal-Tzur, and Aviad Rubinstein (2026). “When Contracts
Get Complex: Information-Theoretic Barriers”. In: Proc. of SODA 2026. Forthcoming.
D¨utting, Paul, Michal Feldman, and Inbal Talgam-Cohen (2024). “Algorithmic Contract Theory:
A Survey”. In: Found. Trends Theor. Comput. Sci. 16.3-4, pp. 211–412.
Ezra, Tomer, Michal Feldman, and Maya Schlesinger (2024). “On the (In)approximability of Com-
binatorial Contracts”. In: Proc. of ITCS 2024. Vol. 287, 44:1–44:22.
Feldman, Michal (2025). “Combinatorial Contract Design: Recent Progress and Emerging Fron-
tiers”. In: arXiv preprint arXiv:2510.15065.
Hann-Caruthers, Wade and Sumit Goel (2024). “Optimality of Weighted Contracts for Multi-agent
Contract Design with a Budget”. In: Proc. of EC 2024, pp. 1295–1295.
Koutsoupias, Elias and Christos Papadimitriou (1999). “Worst-case equilibria”. In: Proc. of STACS
1999, pp. 404–413.
25

Lehmann, Benny, Daniel Lehmann, and Noam Nisan (2006). “Combinatorial auctions with de-
creasing marginal utilities”. In: Games Econ. Behav. 55.2, pp. 270–296.
Monderer, Dov and Lloyd S. Shapley (1996). “Potential Games”. In: Games Econ. Behav. 14,
pp. 124–143.
Roughgarden, Tim (2015). “Intrinsic Robustness of the Price of Anarchy”. In: J. ACM 62.5, 32:1–
32:42.
Roughgarden, Tim and ´Eva Tardos (2002). “How bad is selfish routing?” In: J. ACM 49.2, pp. 236–
259.
Syrgkanis, Vasilis and ´Eva Tardos (2013). “Composable and efficient mechanisms”. In: Proc. of
STOC 2013, pp. 211–220.
A
Separation Example
The following example (adopted from Babaioff, Feldman, and Nisan, 2010, Example 3.1) with two
identical agents each having a single action, shows that with submodular rewards the principal can
strictly benefit from inducing a mixed Nash equilibrium rather than a pure Nash equilibrium. We
remark that the reward function in this example is also gross-substitutes and not just submodular
as every submodular function over two elements is also gross-substitutes.
Example A.1 (Separation Example). Consider an instance with two identical agents A = {1,2}
with costs c(1) = c(2) = c = 1. The submodular reward function is such that f(∅) = 0, f(1) = f(2) =
180, and f({1,2}) = 200.
Recall the definition of the function g ∶2A →R, introduced in the proof of Proposition 6.1.
Under pure Nash equilibria, the best contracts for the possible action profiles ∅, {1}, {2}, and
{1,2} yield the principal a utility of
g(∅) = 0,
g(1) = f(1) ⋅(1 −
c
f(1)) = 179,
g(2) = f(2) ⋅(1 −
c
f(2)) = 179,
and
g({1,2}) = f({1,2}) ⋅(1 −
c
f(1 ∣{2}) −
c
f(2 ∣{1})) = 180.
Thus, the highest utility the principal can obtain in a pure Nash equilibrium is 180, by inducing
both agents to exert effort.
Consider the contract ⃗α = ( 1
36, 1
36). We show that the product distribution D in which each
agent takes an action with probability 0.9 is a MNE. Assuming that one agent takes an action
with probability 0.9, then the utility of the other action as a function of the probability it takes an
action is denoted by
ua(p) = 1
36 (p ⋅(0.9 ⋅f({1,2}) + 0.1 ⋅f(1)) + (1 −p) ⋅(0.9 ⋅f(1) + 0.1 ⋅f(∅))) −p ⋅c = 4.5,
which means that the utility of the agent is independent of the probability of the agent taking
action, which means that D is indeed an MNE.
26

Algorithm 3 Black-Box Robustness for Submodular Rewards
Input: Costs c1,...,cm ∈R≥0, value oracle access to a submodular function f ∶2A →R≥0, a
contract ⃗α⋆, and a corresponding PNE S⋆.
Output: A contract ⃗α guaranteeing a principal’s utility of at least Ω(1) ⋅(1 −∑i α⋆
i )f(S⋆) for
any CCE of ⃗α.
1: Let A0 = {j ∈A ∣cj = 0} be the zero cost actions
2: if f(A0) ≥2
17(1 −∑i α⋆
i )f(S⋆) then
3:
return ⃗α = ⃗ϵ for ϵ =
1
2n
4: else if maxi α⋆
i > 3/4 then
5:
Let i⋆= arg maxi α⋆
i
▷There must be a unique maximum
6:
if (1 −α⋆
i ) ⋅f(S⋆
i ) ≥4 ⋅f(S⋆
−i) then
7:
return ⃗α where αi⋆=
1+α⋆
i⋆
2
and αi = 0 for i ≠i⋆
8:
else
9:
return ⃗α where αi⋆= 0 and αi = 2α⋆
i for i ≠i⋆
10:
end if
11: else
12:
Partition N into two bundles B1,B2, where for each ℓ∈{1,2}, ∑i∈Bℓα⋆
i ≤3/4
13:
Let ℓ∈arg maxℓ′∈{1,2} f(⋃i∈Bℓ′ S⋆
i )
14:
return ⃗α where αi = 7
6α⋆
i for i ∈Bℓand αi = 0 for i /∈Bℓ
15: end if
The expected principal’s utility under contract ⃗α and distribution D is
ES∼D[up(⃗α,S)] = (1−2
36)( 1
100 ⋅f(∅) +
9
100 ⋅f(1) +
9
100 ⋅f(2) + 81
100 ⋅f({1,2})) = 17
18⋅194.4 = 183.6,
which is strictly higher than the optimal principal utility in a pure Nash equilibrium. This shows
that the principal can strictly gain from inducing a mixed Nash equilibrium, rather than a pure
Nash equilibrium.
B
Proof of Theorem 3.4
The high-level idea is to distinguish cases based on the equilibrium S⋆at contract ⃗α⋆, and whether
it is sufficient to incentivize only zero cost actions, or whether there is a “significant” agent, namely,
an agent such that α∗
i > 3/4 and (1 −α⋆
i ) ⋅f(S⋆
i ) ≥4 ⋅f(S⋆
−i), or not. If there is a significant agent,
we show that we can get a good approximation under any CCE by aiming to incentivize that
agent alone. If there is no significant agent, then either (i) there is an agent with α∗
i > 3/4 but
(1 −α⋆
i ) ⋅f(S⋆
i ) ≤4 ⋅f(S⋆
−i), or (ii) α∗
i < 3/4 for all agents i. In case (i), we show that dropping
agent i and applying the Scaling-for-Robustness Lemma to the remaining agents yields a good
guarantee under any CCE. (Note that there can be at most one agent with α⋆
i > 3/4 and that
∑i′≠i α⋆
i′ ≤1/4.) In case (ii), we argue that the agents can be partitioned into two groups B1,B2
such that ∑i′∈Bℓα⋆
i′ ≤3/4 for ℓ∈{1,2}, and applying the Scaling-for-Robustness Lemma to the
better of the groups guarantees a good principal’s utility under any CCE.
Proof of Theorem 3.4. Consider any input ⃗α⋆and PNE S⋆with respect to ⃗α⋆, given as input to
27

Algorithm 3. We analyze the guarantee provided by the contract computed by this algorithm by
distinguishing the following cases:
Case A: It holds that f(A0) ≥
2
17(1 −∑i α⋆
i )f(S⋆). In this case, since A0 is a PNE with respect
to the zero-contract ⃗0 (a contract that pays nothing to all agents), by applying Lemma 3.6 with
ϵ =
1
2n and γ = 2 we obtain that under contract ⃗α = γ⃗0 + ⃗ϵ = ⃗ϵ any CCE D with respect to ⃗α satisfies
ES∼D[f(S)] ≥1
2(1 −1
γ )f(A0) = 1
4f(A0). Thus, the principal’s utility under this case is at least
(1 −∑
i
αi)ES∼D[f(S)] ≥(1 −1
2)1
4f(A0) ≥1
68(1 −∑
i
α⋆
i )f(S⋆),
which concludes this case.
Case B: There exists an agent i with α⋆
i > 3/4 and (1 −α⋆
i ) ⋅f(S⋆
i ) ≥4 ⋅f(S⋆
−i) (and we are not
in Case A). In this case, since α⋆
i > 3/4, we have f(S⋆
i ) ≥16 ⋅f(S⋆
−i). By subadditivity of f, this
implies that f(S⋆
i ) ≥16 ⋅(f(S⋆) −f(S⋆
i )), or equivalently,
f(S⋆
i ) ≥16
17 ⋅f(S⋆).
(19)
Consider contract ⃗α with αi = 1+α⋆
i
2
and αj = 0 for j ≠i. Note that αi > α⋆
i . Let D be any CCE
of ⃗α. We next show that ES∼D[f(S)] ≥1
4 ⋅f(S⋆
i ).
We have the following:
ES∼D[αif(Si) −c(Si)]
≥
ES∼D[αi(f(Si ∪S−i) −f(S−i)) −c(Si)]
≥
ES∼D[αi(f(S⋆
i ∪S−i) −f(S−i))] −c(S⋆
i )
≥
αif(S⋆
i ) −αiES∼D[f(S−i)] −c(S⋆
i )
≥
αif(S⋆
i ) −αif(A0) −c(S⋆
i ),
(20)
where the first inequality is by subadditivity, the second inequality is since D is a CCE of ⃗α, the
third inequality is by monotonicity of f, and the last inequality is since no agent but i will take
non-zero cost actions in a CCE since αj = 0 for j ≠i. On the other hand, since S⋆is a PNE of ⃗α⋆,
it must hold that
α⋆
i f(S⋆
i ∪S⋆
−i) −c(S⋆
i ) ≥ES∼D[α⋆
i f(Si ∪S⋆
−i) −c(Si)].
By subadditivity of f, we have f(S⋆
i ∪S⋆
−i) −f(S⋆
−i) ≤f(S⋆
i ). Moreover, by monotonicity of f, we
have f(Si ∪S⋆
−i) ≥f(Si). We thus obtain
α⋆
i f(S⋆
i ) −c(S⋆
i ) ≥ES∼D[α⋆
i f(Si) −c(Si)] −α⋆
i f(S⋆
−i).
(21)
By summing up (20) and (21), we obtain
ES∼D[αif(Si) −c(Si)] + α⋆
i f(S⋆
i ) −c(S⋆
i )
≥ES∼D[α⋆
i f(Si) −c(Si)] −α⋆
i f(S⋆
−i) + αif(S⋆
i ) −αif(A0) −c(S⋆
i ).
Using linearity of expectation and that αi ≤1 and α⋆
i ≤1, we get
(αi−α⋆
i )ES∼D[f(Si)] ≥(αi−α⋆
i )⋅f(S⋆
i )−αif(A0)−α⋆
i f(S⋆
−i) ≥(αi−α⋆
i )⋅f(S⋆
i )−f(A0)−f(S⋆
−i). (22)
28

Thus, using that αi > α⋆
i ,
ES∼D[f(Si)]
≥
f(S⋆
i ) −f(S⋆
−i) + f(A0)
αi −α⋆
i
= f(S⋆
i ) −2(f(S⋆
−i) + f(A0))
1 −α⋆
i
≥
f(S⋆
i ) −
2
1 −α⋆
i
⋅⎛
⎝
1 −α∗
i
4
⋅f(S⋆
i ) + 2
17(1 −∑
j
α⋆
j )f(S⋆)⎞
⎠
≥
f(S⋆
i ) −
2
1 −α⋆
i
⋅(1 −α∗
i
4
⋅f(S⋆
i ) + 2
17(1 −α⋆
i )17
16f(S⋆
i )) = 1
4f(S⋆
i ).
(23)
where the first inequality is by rearranging Inequality (22), the first equality is by the definition of αi,
the second inequality is by the assumption of the case, and the last inequality is by Inequality (19).
Overall, the principal’s utility under contract ⃗α and CCE D is
(1 −∑
j
αj) ⋅ES∼D[f(S)] ≥(1 −αi) ⋅ES∼D[f(Si)] = 1
2(1 −α⋆
i ) ⋅ES∼D[f(Si)] ≥1
8(1 −α⋆
i ) ⋅f(S⋆
i )
≥1
8(1 −∑
j
α⋆
j ) ⋅f(S⋆
i ) ≥2
17(1 −∑
j
α⋆
j ) ⋅f(S⋆),
where the first equality is by definition of ⃗α and monotonicity, the equality follows by the definition
of αi, the second inequality holds by Inequality (23), and the final inequality is by Inequality (19)
This concludes the argument for this case.
Case C: There exists an agent i with αi > 3/4 and (1 −α⋆
i ) ⋅f(S⋆
i ) ≤4 ⋅f(S⋆
−i) (and we are not
in Case A). In this case, let ⃗α be the contract where αi = 0 and αj = 2α⋆
j for j ≠i. By applying
Lemma 3.6 on S⋆, ⃗α⋆, N′ = [n] ∖{i} and γ = 2 we get that any CCE D with respect to contract ⃗α
satisfies
ES∼D[f(S)] ≥1
4f( ⋃
j∈N′ S⋆
j ).
(24)
We can bound the principal’s utility under ⃗α⋆, and S⋆by
⎛
⎝1 −∑
j
α⋆
j
⎞
⎠f(S⋆)
≤
⎛
⎝1 −∑
j
α⋆
j
⎞
⎠f(S⋆
i ) + ⎛
⎝1 −∑
j
α⋆
j
⎞
⎠f(S⋆
−i)
≤
(1 −α⋆
i )f(S⋆
i ) + f(S⋆
−i) ≤5 ⋅f(S⋆
−i),
(25)
where the first inequality is by subadditivity, the last inequality is by the assumption of the case.
One the other hand, under contract ⃗α (for which ∑j αj = ∑j≠i 2α⋆
j ≤2(1 −α⋆
i ) ≤1
2), and CCE
D, the principal’s utility is
(1 −∑
j
αj)ES∼D[f(S)]
(24)
≥(1 −∑
j≠i
2α⋆
j ) ⋅1
4f( ⋃
j∈N′ S⋆
j ) ≥1
8f(S⋆
−i)
(25)
≥
1
40
⎛
⎝1 −∑
j
α⋆
j
⎞
⎠f(S⋆),
which concludes the proof of the case.
Case D: α⋆
i ≤3/4 for every i (and we are not in case A). Note that we can partition the agents
into two bundles B1,B2, where for each ℓ∈{1,2}, ∑i∈Bℓα⋆
i ≤3/4 (by the same argument as in the
proof of Theorem 3.1). Now, assume without loss of generality that
f( ⋃
i∈B1
S⋆
i ) ≥f( ⋃
i∈B2
S⋆
i ).
(26)
29

Let ⃗α be the contract where αi = 0 for i ∈B2 and αi = 7
6α⋆
i for i ∈B1. By applying Lemma 3.6 on
S⋆, ⃗α⋆, N′ = B1 and γ = 7/6 we get that there any CCE D with respect to contract ⃗α satisfies
ES∼D[f(S)] ≥1
14f( ⋃
i∈B1
S⋆
j )
(27)
The principal’s utility from ⃗α and D is
(1 −∑
i
αi)ES∼D[f(S)]
≥
(1 −7
6 ∑
i∈B1
α⋆
i ) ⋅1
14 ⋅f( ⋃
i∈B1
S⋆
i ) ≥(1 −7
6 ⋅3
4) ⋅1
14 ⋅f( ⋃
i∈B1
S⋆
i )
≥
1
112
f(⋃i∈B1 S⋆
i ) + f(⋃i∈B2 S⋆
i )
2
≥f(S⋆)
224 ,
where the first inequality is by the definition of ⃗α and by Inequality (27), the second inequality
is since ∑i∈B1 α⋆
i ≤3/4, the third inequality is by Inequality (26), and the last inequality is by
subadditivity. This concludes the proof of the theorem.
C
Proof of Proposition 4.5
We first prove a weaker variant of the Scaling-for-Existence Lemma for subadditive functions.
Lemma C.1 (Scaling-for-Existence Lemma for Subadditive). Suppose f is subadditive. Let D be
a dropout-stable distribution with respect to ⃗α. For any set of i ∈N and γ > 1, let ⃗α′ be defined by
α′
i = γ ⋅αi, and α′
i′ = 0 for i′ ≠i. Then, there exists a pure Nash equilibrium S′ with respect to ⃗α′,
satisfying
f(S′) ≥(1 −1
γ ) ⋅ES∼D[f(Si)].
Proof. Fix a set S in the support of D. Now for any set S′
i ⊆Ai define Φ(S′
i, ⃗α) = f(S′
i) −c(S′
i)
αi
where 0
0 is interpreted as 0, and c
0 for a positive c is interpreted as ∞. Then we have
ES∼D[Φ(Si, ⃗α)] = ES∼D[f(Si) −c(Si)
αi
] ≥ES∼D[f(Si ∣S−i) −c(Si)
αi
] ≥0,
(28)
where the first inequality is by subadditivity, and the last inequality is by dropout-stability.
Let S′
i ⊆Ai be a set of actions maximizing Φ(S′
i, ⃗α′) (when fixing ⃗α′ as defined in the statement
of the lemma). Then we have
Φ(S′
i, ⃗α′) ≥ES∼D[Φ(Si, ⃗α′)] = ES∼D [f(Si) −c(Si)
γαi
]
= (1 −1
γ )ES∼D[f(Si)] + 1
γ ES∼D[Φ(Si, ⃗α)] ≥(1 −1
γ )ES∼D[f(Si)],
where the first inequality follows by the maximality of S′
i, and the last inequality follows by Eq. (28).
As S′
i is a global maximum of Φ(⋅, ⃗α′), it is also a local maximum. Since Φ(⋅, ⃗α′) is a potential
function for the game induced by the contract ⃗α′ (see Proposition 2.5), this means that S′
i is a pure
Nash equilibrium with respect to contract ⃗α′.
30

We are now ready to prove Proposition 4.5. Consider any contract ⃗α⋆and any coarse-correlated
equilibrium D with respect to ⃗α⋆. In the remainder of the proof, all expectations are over S⋆that
is distributed according to D. We consider three cases:
Case A: There exists an agent i with α⋆
i > 3/4 and (1 −α⋆
i ) ⋅E[f(S⋆
i )] ≥4 ⋅E[f(S⋆
−i)]. The proof
of this case is identical to the proof of Case A of the proof of Theorem 3.1.
Case B: There exists an agent i with α⋆
i > 3/4 and (1−α⋆
i )⋅E[f(S⋆
i )] ≤4⋅E[f(S⋆
−i)]. In this case,
let i⋆= arg maxi′≠i E[f(Si′)]. Let ⃗α′ be the contract where α′
i′ = 0 for i′ ≠i⋆, and α′
i⋆= 2αi⋆. By
applying Lemma C.1 on D, ⃗α⋆, i⋆and γ = 2 we get that there exists an equilibrium S′ with respect
to contract ⃗α′ such that
f(S′) ≥1
2E [f(S⋆
i⋆)].
(29)
We can bound the expected principal’s utility under ⃗α⋆, and D by
⎛
⎝1 −∑
j
α⋆
j
⎞
⎠E [f(S⋆)]
≤
⎛
⎝1 −∑
j
α⋆
j
⎞
⎠E [f(S⋆
i )] + ⎛
⎝1 −∑
j
α⋆
j
⎞
⎠E [f(S⋆
−i)]
≤
(1 −α⋆
i )E [f(S⋆
i )] + E [f(S⋆
−i)] ≤5 ⋅E [f(S⋆
−i)],
(30)
where the first inequality is by subadditivity, the last inequality is by the assumption of the case.
One the other hand, under contract ⃗α′ (for which ∑j α′
j = 2α⋆
i⋆≤2(1−α⋆
i ) ≤1
2), and equilibrium
S′, the principal’s utility is
(1 −∑
j
α′
j)f(S′)
(29)
≥(1 −2α⋆
i⋆) ⋅1
2E [f(S⋆
i⋆)] ≥1
4nE [f(S⋆
−i)]
(30)
≥
1
20n
⎛
⎝1 −∑
j
α⋆
j
⎞
⎠E [f(S⋆)],
where the second inequality is by subadditivity and the definition of i⋆. This concludes the proof
of the case.
Case C: α⋆
i ≤3/4 for every i. In this case, let i⋆= arg maxi E[f(Si)]. Let ⃗α′ be the contract where
α′
i = 0 for i ≠i⋆, and α′
i⋆= 7
6αi⋆. By applying Lemma C.1 on D, ⃗α⋆, i⋆and γ = 7
6 we get that there
exists an equilibrium S′ with respect to contract ⃗α′ such that
f(S′) ≥1
7E [f(S⋆
i⋆)].
(31)
Under contract ⃗α′ (for which ∑j α′
j = 7
6α⋆
i⋆≤7
6 ⋅3
4 = 7
8), and equilibrium S′, the principal’s utility
is
(1 −∑
j
α′
j)f(S′)
(31)
≥(1 −7
8) ⋅1
7E [f(S⋆
i⋆)] = 1
56E [f(S⋆
i )] ≥
1
56nE [f(S⋆)],
where the last inequality is by the definition of i⋆and by subadditivity. This concludes the proof
of the proposition.
31
