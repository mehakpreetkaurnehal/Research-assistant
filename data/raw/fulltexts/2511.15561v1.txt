Variance-reduced extreme value index estimators
using control variates in a semi-supervised setting
Louison Bocquet-Nouaille1,2, Jérôme Morio1,2, and Benjamin Bobbia2
1ONERA/DTIS, Université de Toulouse, F-31055 Toulouse
2Fédération ENAC ISAE-SUPAERO ONERA, Université de Toulouse, 31000 Toulouse
The estimation of the Extreme Value Index (EVI) is fundamental in extreme value analysis but suffers from
high variance due to reliance on only a few extreme observations.
We propose a control variates based
transfer learning approach in a semi-supervised framework, where a small set of coupled target and source
observations is combined with abundant unpaired source data.
By expressing the Hill estimator of the
target EVI as a ratio of means, we apply approximate control variates to both numerator and denomi-
nator, with jointly optimized coefficients that guarantee variance reduction without introducing bias. We
show theoretically and through simulations that the asymptotic relative variance reduction of the trans-
ferred Hill estimator is proportional to the tail dependence between the target and source variables and
independent of their EVI values. Thus, substantial variance reduction can be achieved even without sim-
ilarity in tail heaviness of the target and source distributions. The proposed approach can be extended
to other EVI estimators expressed with ratio of means, as demonstrated on the moment estimator. The
practical value of the proposed method is illustrated on multi-fidelity water surge and ice accretion datasets.
1
Introduction
A key parameter in Extreme Value Theory (EVT) is the Extreme Value Index (EVI), which characterizes
the behavior of the distribution’s tail, notably the frequency and magnitude of extreme events. Estimating
the EVI is essential to compute other quantities, such as extreme quantiles.
Classical EVT approaches assume a large dataset of size n, but only use the top k << n observations
representing extremes to study the distribution’s tail. Choosing the number of extremes k involves a crucial
bias–variance trade-off: taking k too large introduces bias by including non-extreme observations, while
taking k too small results in estimates with high variance due to insufficient data. In addition, datasets
are often limited in practice, making both the sample size n and the number of extremes k small. As a
result, each observation influences the estimates more strongly, which increases their variance and leads to
less reliable results.
Many variance reduction methods exist in different frameworks (Asmussen and Glynn, 2007). Yet, in
extreme value analysis, most studies focused on bias correction (Caeiro et al., 2020; Gomes et al., 2016; Cai
et al., 2013). Given the bias–variance trade-off, variance reduction constitutes a natural and complementary
strategy to bias correction for improving the accuracy of EVI estimates.
In this work, a transfer learning approach for variance reduction (Zhu et al., 2025) is considered. The idea
of transfer learning is to leverage information from another dataset, called the source, to enhance estimations
on the target dataset. This approach is similar to how humans learn: someone who knows how to play the
piano will find it easier to learn the violin than someone with no musical experience. In practice, the dataset
considered is composed of a small set of coupled target and source samples (Y T
i , Y S
i )i=1...n, and a larger
set of additional unpaired source samples (Y S
i )i=n+1...n+m. This setting assumes that new samples cannot
be acquired. The transfer success relies on the dependence between target and source, combined with the
1
arXiv:2511.15561v1  [stat.ME]  19 Nov 2025

abundance of source data. This framework is often referred to as the "semi-supervised" framework, for
its similarity with machine learning problems where only a few observations are labeled in larger datasets.
Although only one source is considered in this work, the framework can be extended to multiple sources and
is closely related to data fusion, where multiple datasets are integrated to enhance inference.
The semi-supervised setting appears in a wide range of applications.
The target may correspond to
real-world data, while the source comes from a simulation model. Alternatively, the target could come from
a more accurate, high-fidelity model, while the source comes from a cheaper, lower-fidelity model. This
is known as multi-fidelity modeling, and it is particularly suited for transfer learning (Peherstorfer et al.,
2018). Another relevant setting involves source and target data of similar fidelity, but collected at different
locations. For example, wind measurements from two nearby weather stations, where the source station may
offer higher sampling resolution or a longer observation history. In each case, the richer source data helps
improve estimation on the target.
A few recent studies have employed transfer learning to reduce the variance of extreme value estimations
in a semi-supervised setting. For instance, (Kim et al., 2024) apply a parametric Multi-Fidelity Monte Carlo
(MFMC) method to estimate parameters of the Gumbel distribution and exceedance probabilities. This
method, also known as approximate control variates (ACV) (Gorodetsky et al., 2020), is the one adopted in
the present work and further detailed in Section 3. Similarly, (Ahmed et al., 2025) introduce variance-reduced
estimators for the EVI, based on the maximum likelihood estimator (MLE), and for extreme quantiles. The
authors propose the following approach: the source variable is transformed to have a known EVI g, which is
estimated with the MLE as bg, to refine the target EVI estimation with the difference bg −g. In earlier work,
(Ahmed and Einmahl, 2019) presented a variance-reduced Hill estimator, based on the difference between
two Hill estimates of the source EVI: one computed on the n coupled samples, and the other on the full
set of n + m available samples. Another related work is (Einmahl and Peng, 2024), where variance-reduced
estimators are presented for the Value-at-Risk, Expected Shortfall, and Expectile. The authors follow a
similar method: correcting the target estimate with a difference between source-based estimates. Notably,
their method is the only one that does not rely on a dependence model between target and source variables,
which is often challenging to estimate when paired observations are limited.
This paper presents new variance-reduced EVI estimators in a semi-supervised framework, using the con-
trol variates method. The focus is placed on the Hill estimator, which can be formulated as a ratio of means,
allowing the approximate control variates approach to be applied to both the numerator and denominator.
The proposed transferred Hill estimator guarantees variance reduction and exhibits asymptotic indepen-
dence of the relative variance reduction from the target and source EVI values under suitable conditions.
The asymptotic relative variance reduction is also shown to be proportional to the tail dependence between
target and source samples.
This paper is organized as follows.
Section 2 presents central concepts of EVT and introduces the
notations used throughout the article. It emphasizes the central role of the EVI and presents the considered
EVI estimators. Section 3 introduces the control variates method in its exact and approximate forms, for
mean estimation and for ratio of means estimation. Section 4 presents new variance-reduced EVI estimators
using the approximate control variates method, and describes some properties of the proposed transferred
Hill estimator. In Section 5, simulation results are presented, showcasing the efficiency of the proposed
estimators and investigating the influence of key parameters on variance reduction. Finally, in Section 6,
the new EVI estimators are applied to two practical cases: ice accretion on airplane wings, with spatial
dependence, and water surge modeling, with multi-fidelity dependence.
2
Extreme Value Theory
2.1
Domains of attraction
Extreme Value Theory (EVT) offers a statistical framework to analyze the tails of probability distributions,
enabling the study of rare events that fall outside the range of observed data. The way extremes are defined
varies across EVT approaches: the Block Maxima (BM) method or the Peaks-Over-Threshold (POT). In
2

the BM framework, the sample of size n is divided into k sub-samples, each of size r, and only the maximum
value within each block is retained. However, the BM method may fail to capture all extremes, as some
blocks might contain multiple extremes while others may have none. The POT approach instead focuses on
all data points that exceed a given high threshold u, such that k extremes are considered. In this work, the
POT framework is adopted, as it makes better use of the available information.
This section presents key results of EVT and introduces the EVI, the parameter of interest. For more
details on EVT, see (de Haan and Ferreira, 2006) for a rigorous theoretical framework, and (Bousquet and
Bernardara, 2021) for a practical introduction.
Let (Y1, . . . , Yn) be some i.i.d.
samples of the random variable Y ∈R, and Y1:n ≤· · · ≤Yn:n the
associated order statistics.
Let F be their cumulative distribution function (cdf), with right endpoint
y∗= sup{y : F(y) < 1}.
A key result in EVT is the Fisher–Tippett–Gnedenko theorem stated below, which characterizes the
asymptotic behavior of the sample maxima Yn:n and defines the max-domain of attraction.
Theorem 1 ((Fisher and Tippett, 1928; Gnedenko, 1943)) Assume there exist sequences of constants
(an > 0) and (bn) such that the normalized sample maximum (Yn:n −bn)/an converges in distribution to a
non-degenerate limit. Then
lim
n→∞P
Yn:n −bn
an
≤y

= lim
n→∞F n(any + bn) = GEVγ(y)
(1)
where the limiting distribution is the Generalized Extreme Value (GEV) distribution, defined by
GEVγ(y) :=
(
exp(−(1 + γy))−1
γ
if γ ̸= 0,
1 + γy > 0;
exp(−e−y)
if γ = 0,
y ∈R
(2)
It can also be said that the distribution F belongs to the max-domain of attraction D(GEVγ) of a GEVγ
distribution, where γ is the EVI, characterizing the tail behavior of F.
The following theorem is of particular importance as it describes the asymptotic behaviour of the selected
extremes in the POT framework, the values exceeding a predefined threshold.
Theorem 2 ((Pickands III, 1975; Balkema and de Haan, 1974)) Let Fu(y) = P(Y −u ≤y|Y > u)
be the distribution of exceedances over threshold u and σ(u) a positive scaling function.
F ∈D(GEVγ) ⇔lim
u→y∗Fu (σ(u)y) := GPγ(y)
(3)
where the limiting distribution is the Generalized Pareto Distribution (GPD), defined by
GPγ(y) =
(
1 −(1 + γy)−1
γ
if γ ̸= 0,
0 < y < (0 ∨(−γ))−1;
1 −exp(−y)
if γ = 0,
y ∈R
(4)
In other words, any distribution of data above a sufficiently high threshold can be approximated by a GPγ
with EVI γ, provided that F ∈D(GEVγ). This result provides the theoretical foundation for estimations in
the POT framework.
With a positive EVI, the distribution has a heavy tail with an infinite right endpoint, meaning extreme
events are more intense. It can model natural disasters (Bousquet and Bernardara, 2021), financial risks or
insurance claims (Embrechts et al., 1997), or cyber attacks (Zhan et al., 2015). With a negative EVI, the
distribution has a short tail with a finite right endpoint, making it suitable to model bounded quantities like
lifespan (Einmahl et al., 2019) or physical constraints (De la Luz et al., 2018). When the EVI is zero, the
distribution has a light tail with a finite or infinite right endpoint, meaning extreme events are possible but
occur rarely, as in queuing times (Asmussen, 1998). These behaviors correspond respectively to the three
classical domains of attraction: the Fréchet domain for γ > 0, associated with heavy-tailed distributions
3

such as the Pareto distribution; the Weibull domain for γ < 0, associated with short-tailed distributions
such as the Beta distribution; and the Gumbel domain for γ = 0, associated with light-tailed distributions
such as the Normal distribution.
Choosing the threshold u in the POT framework is a delicate balance: setting it too low introduces bias
by including non-extreme events, while setting it too high increases variance due to the reduced sample size.
In practice, choosing Yn−k:n as threshold ensures a fixed number of exceedances k rather than focusing on
a set threshold value u. Using the random (n −k)-th order statistic as threshold results in EVI estimators
with smaller variance than the ones with a deterministic threshold (remark 2.1 in (Bobbia et al., 2025)).
Threshold selection is still a key question in EVT; for further details, refer to (Caeiro and Gomes, 2015).
While the choice of k affects the variance and the bias of EVI estimators, its optimization is not explored in
this work.
F being in the max-domain of attraction F ∈D(GEVγ) can be expressed in terms of the asymptotic
behavior of its tail quantile function U, as described in the first-order condition.
Definition 1 (First-order extended regular variation (de Haan, 1984)) Let a(·) be a positive mea-
surable function, and U(·) the tail quantile function defined for t > 1 by U(t) = F ← 1 −1
t

, where
F ←(y) = inf{x : F(x) ≥y} is the left-continuous inverse. Then
F ∈D(GEVγ) ⇔lim
t→∞
U(ty) −U(t)
a(t)
=
( yγ−1
γ
if γ ̸= 0;
ln y
if γ = 0
(5)
U(·) is of first order extended regular variation, written U ∈ERVγ.
The second-order condition quantifies the rate of convergence, which is essential for studying the finite-
sample properties and convergence speed of EVI estimators (de Haan, 1975).
Definition 2 (Second-order extended regular variation (Alves et al., 2007)) Assume A(·) exists, a
function such that A(t) −→
t→∞0 and ∀y > 0,
lim
t→∞
U(ty)−U(t)
a(t)
−yγ−1
γ
A(t)
= Hγ,ρ(y) := 1
ρ
yγ+ρ −1
γ + ρ
−yγ −1
γ

(6)
where ρ ≤0 a parameter controlling the speed of convergence towards the limit law. Then U(·) is of second
order extended regular variation, written U ∈2ERVγ,ρ.
2.2
Extreme Value Index estimators
The following section presents two commonly used EVI estimators that can be formulated as ratios of means,
a necessary condition to apply the variance reduction method to be introduced in Section 3. For more details
on EVI estimators, see Chapter 3 of (de Haan and Ferreira, 2006).
2.2.1
The Hill estimator
The Hill estimator is a common estimator for a positive EVI.
Definition 3 (Hill estimator (Hill, 1975)) Let k ∈{1, . . . , n−1}, and assume Yn−k:n > 0, F ∈D(GEVγ)
and γ > 0. The Hill estimator of the EVI γ is defined as
bγH = 1
k
k
X
i=1
ln
Yn−i+1:n
Yn−k:n

(7)
The Hill estimator is consistent under the first and second-order condition, provided that
√
kA( n
k ) →0,
with the number of extremes k growing to infinity but remaining small compared to the total sample size n
4

(i.e. k = k(n) →∞and k/n →0, as n →∞). The estimator’s asymptotic behaviour can be characterized
under the second-order condition of Definition 2, as presented in Theorem 3.2.5 of (de Haan and Ferreira,
2006). Its asymptotic bias is the limit of A(n/k)
1−ρ
where ρ is the second-order parameter, and its asymptotic
variance is equivalent to γ2
k . If the second-order term A(n/k) vanishes sufficiently fast as k/n →0, the
estimator becomes asymptotically unbiased. The variance decreases as k →∞, highlighting the bias-variance
trade-off in the choice of k. Bias-corrected EVI estimators have been proposed, one of which is presented
below.
2.2.2
The moment estimator
Definition 4 (Moment estimator (Dekkers et al., 1989)) Let k ∈{1, . . . , n−1}, and assume Yn−k:n >
0, F ∈D(GEVγ) and γ > −1/2. Define the empirical log-moments for j ∈{1, 2} by
M (j) =
1
n
Pn
i=1(ln(Yi) −ln(Yn−k:n))j1{Yi>Yn−k:n}
1
n
Pn
i=1 1{Yi>Yn−k:n}
(8)
The moment estimator of the EVI γ is defined as
bγM = M (1) + 1 −1
2
 
1 −
 M (1)2
M (2)
!−1
(9)
The moment estimator is consistent under the first and second-order conditions.
Compared to the Hill
estimator, it exhibits lower bias and is not restricted to the heavy-tailed case.
3
The control variates method
As discussed in the introduction, transfer learning in a semi-supervised framework is a promising approach
for reducing the variance of EVI estimators. The transfer method explored in this work is based on control
variates (CV), which are introduced in this section.
Let (Ai)i=1...n be i.i.d. real samples of a random variable A ∈L1. The Monte Carlo estimator An of
E[A] is defined as
An = 1
n
n
X
i=1
Ai
(10)
To reduce the variance of the Monte Carlo estimator An of E[A], the idea of control variates is to consider
an auxiliary variable B, correlated with the target random variable A. This approach is a form of statistical
transfer learning as it leverages knowledge from a related variable B to compensate for the lack of informa-
tion about the target variable A.
Let (Ai, Bi)i=1...n be i.i.d. real samples from the joint distribution of the random variables A, B ∈L2.
Assume E[B] is known. The control variates estimator (Asmussen and Glynn, 2007) of E[A] is defined as
bACV = An + αc(E[B] −Bn)
(11)
where the coefficient αc is set to minimize the variance of bACV :
αc := argmin
α∈R
Var
 An + α(E[B] −Bn)

= Cov(A, B)
Var(B)
(12)
The method can only reduce the variance compared to the baseline Monte Carlo estimator. The extent of
variance reduction depends on the strength of the correlation between A and B: the higher the absolute value
of the correlation, the greater the reduction. When the correlation is zero, the control variates estimator
coincides with the Monte Carlo one. Another strength of the method is that there is no added bias. A small
5

plug-in bias may be added by the estimation of the coefficient α on the same sample as the one used to
estimate E[A], but it is usually negligible (Owen, 2013).
In practice, the assumption that the control variate mean E[B] is known is often unrealistic. The ap-
proximate control variates (ACV) method (Gorodetsky et al., 2020) overcomes this by estimating the mean
from additional data. Let (Ai, Bi)i=1...n be i.i.d. real samples from the joint distribution of the random
variables A, B ∈L2, and let (Bi)i=n+1...n+m be additional i.i.d. samples of B. The approximate control
variates estimator of E[A] is defined as
bAACV = An + αc(Bn+m −Bn)
(13)
Assume the quantity of interest is a ratio of means R = E[A]/E[C]. The variance of its Monte Carlo
estimator RMC/MC = An/Cn can be reduced by applying the control variates method to both numerator
and denominator (Bocquet-Nouaille et al., 2025). The approximate control variates estimator for a ratio of
means is defined as follows.
Definition 5 (ACV/ACV estimator (Bocquet-Nouaille et al., 2025)) Let (Ai, Bi, Ci, Di)i=1...n be i.i.d.
real samples from the joint distribution of the random variables A, B, C, D ∈L2, where B and D are control
variates. The ACV/ACV estimator of R = E[A]/E[C] is defined as
bR ACV
ACV = An + α(Bn+m −Bn)
Cn + β(Dn+m −Dn)
(14)
Assume |Corr(B, D)| < 1. The optimal coefficients for the ACV/ACV estimator, guaranteeing variance
reduction, are defined as
α = Var(D)Cov(A, B) −RVar(D)Cov(B, C) + RCov(B, D)Cov(C, D) −Cov(B, D)Cov(A, D)
Var(B)Var(D) −Cov(B, D)2
(15)
β = Cov(B, D)Cov(A, B) −RCov(B, D)Cov(B, C) + RVar(B)Cov(C, D) −Var(B)Cov(A, D)
R (Var(B)Var(D) −Cov(B, D)2)
(16)
4
Variance-reduced Extreme Value Index estimators using control
variates
The following section addresses the problem of variance reduction for EVI estimators that can be expressed
as functions of ratios of means. Let Y T , Y S ∈R denote the target and source variables. A semi-supervised
framework is considered: only a small number of paired target and source i.i.d. samples (Y T
i , Y S
i )i=1...n are
available, supplemented by a larger set of additional source i.i.d. samples (Y S
i )i=n+1...n+m. This setting
assumes that new samples cannot be acquired. The target-source relationship and the profusion of source
data allow to improve the estimation of target data quantities. This is achieved through transfer learning
with the control variates estimator presented in the previous section.
4.1
Transferred Hill estimator
The Hill estimator (Definition 3) is derived from the mean log-excess function, that converges to the EVI
(Remark 1.2.3 of (de Haan and Ferreira, 2006)):
E[ln(Y ) −ln(u)|Y > u] −→
u→y∗γ
(17)
Choosing the threshold u as the (n−k)-th order statistic Yn−k:n, and expressing the conditional expectation
as a ratio, for k = k(n) →∞and k/n →0 as n →∞, it gives:
E[(ln(Y ) −ln(Yn−k:n))1Y >Yn−k:n]
E[1Y >Yn−k:n]
−→
n→∞γ
(18)
6

This leads to a formulation of the Hill estimator as a ratio of means:
bγH =
1
n
Pn
i=1(ln(Yi) −ln(Yn−k:n))1{Yi>Yn−k:n}
1
n
Pn
i=1 1{Yi>Yn−k:n}
(19)
Using the notations of Section 3, the Hill estimator is expressed as
bγT
H = An
Cn
(20)
where
A = (ln(Y T ) −ln(Y T
n−k:n))1{Y T >Y T
n−k:n}
C = 1{Y T >Y T
n−k:n}
(21)
To be rigorous, A and C should be denoted Ak,n and Ck,n as they depend on the sample size n and the
number of extremes k, however we choose not to use the indices to keep the notations light.
This ratio of means form allows to apply the ACV/ACV estimator introduced in Definition 5 to reduce
variance, leading to the new transferred Hill estimator introduced hereafter.
Definition 6 (Transferred Hill estimator) Let k ∈{1, . . . , n −1}, and assume Y T
n−k:n > 0, FT ∈
D(GEVγT ) and γT > 0. Define the random variables
A = (ln(Y T ) −ln(Y T
n−k:n))1{Y T >Y T
n−k:n}
B = (ln(Y S) −ln(Y S
n−k:n))1{Y S>Y S
n−k:n}
(22)
C = 1{Y T >Y T
n−k:n}
D = 1{Y S>Y S
n−k:n}
(23)
The proposed transferred Hill estimator of the EVI, based on approximate control variates, is given by
bγT
T H = An + α(Bn+m −Bn)
Cn + β(Dn+m −Dn)
(24)
where the coefficients α and β are given by
α = Var(D)Cov(A, B) −RVar(D)Cov(B, C) + RCov(B, D)Cov(C, D) −Cov(B, D)Cov(A, D)
Var(B)Var(D) −Cov(B, D)2
(25)
β = Cov(B, D)Cov(A, B) −RCov(B, D)Cov(B, C) + RVar(B)Cov(C, D) −Var(B)Cov(A, D)
R (Var(B)Var(D) −Cov(B, D)2)
(26)
where R = E[A]/E[C].
Proposition 1 The estimator bγT
T H is consistent under the first and second conditions, as the Hill estimator,
for m →∞, k = k(n) →∞, k/n →0 as n →∞.
Proof of Proposition 1 is given in Appendix A.
In practice, the coefficients α and β are estimated on the same dataset as the estimator bγT
T H, which may
introduce a plug-in bias, usually negligible as discussed in (Owen, 2013).
The control variate is typically chosen to mirror the variable it controls. In this case, B and D are defined
similarly to A and C, using the source data in place of the target data. With this choice, the condition
|Corr(B, D)| < 1 is fulfilled and variance reduction is guaranteed. With the definitions of AB, C, D given
above, all four variables belong to L2, ensuring the applicability of the control variates method.
The threshold for the control variates B and D is chosen to minimize the estimated variance of the esti-
mator. The optimal source threshold was consistently found close to the (n-k)-th order statistic, as shown
in Appendix C. Since estimating the variance for each possible threshold can be computationally expensive,
7

and the benefit in variance reduction is minimal, the source threshold is set to Y S
n−k:n.
As described in (Bocquet-Nouaille et al., 2025), it is delicate to determine which relations between the
variables A, B, C, and D allow for greater variance reduction. The potential for variance reduction can be
assessed by examining the correlation between C and D, which captures the co-occurrence of extremes in
the target and source data. The correlation between A and B goes further, reflecting both the co-occurrence
and the magnitude of the extremes, that is, how far above the threshold they go. Correlations Corr(A, B)
and Corr(C, D) may offer some qualitative insight, but a linear relation with variance reduction cannot be
established. In Section 5.2, it is shown that the control variates estimator works best in practice when the
target and source extremes are correlated.
In essence, these correlations resemble the concept of tail dependence (Malevergne and Sornette, 2002),
which can also be used as an indicator of variance reduction. It measures the probability of observing a large
value of Y T given that Y S is also large, or vice-versa, and is defined as:
λ = lim
u→1 P
 Y T > F −1
T (u) | Y S > F −1
S (u)

= lim
u→1 P
 Y S > F −1
S (u) | Y T > F −1
T (u)

(27)
It can be estimated by
bλ = 1
k
n
X
i=1
1{Y T > Y T
n−k:n, Y S > Y S
n−k:n}.
(28)
In (Ahmed et al., 2025), tail dependence is a key indicator of variance reduction potential, as their
estimator explicitly relies on an estimate of this quantity. In contrast, the estimator presented in this work
implicitly benefits from source–target dependence without requiring its estimation. The following proposition
establishes a connection between tail dependence and the relative variance reduction (RVR), a performance
measure that quantifies the variance reduction achieved by a new estimator bγnew compared to a baseline
estimator bγbase:
RVR = Var(bγbase) −Var(bγnew)
Var(bγbase)
(29)
Here the baseline is the Hill estimator bγT
H, compared to the new transferred Hill estimator bγT
T H.
Proposition 2 The asymptotic RVR of the transferred Hill estimator is studied for k = k(n) →∞, k/n →0
as n →∞.
1. For any source distribution, the asymptotic RVR is
RV R
≈
n→∞
m
n(n + m)
1
p2
Cov(ϵ′
A, B)2Var(D) + Cov(ϵ′
A, D)2Var(B) −Cov(ϵ′
A, B)Cov(ϵ′
A, D)Cov(B, D)
Var(B)Var(D) −Cov(B, D)2
2. For a heavy-tailed source distribution, i.e.
F S ∈D(GEVγS) with γS > 0, the scaled log-excesses
Z =

ln(Y S/u)
γS
Y S > u

asymptotically follow a standard exponential distribution. The asymptotic
RVR is
RV R
≈
n→∞λ2
m
n(n + m)
c2
AB + c2
AD
2−p
1−p −cABcAD
p
(31)
where p = P(Y T > Y T
n−k:n) = P(Y S > Y S
n−k:n),
ϵ′
A =
A
γT −C
≈
n→∞(Z −1)1{Y T >Y T
n−k:n},
cAD and cAB defined as
cAD
≈
n→∞E
"
Z −1
Y T > Y T
n−k:n, Y S > Y S
n−k:n
#
cAB
≈
n→∞E
"
(Z −1) Z
Y T > Y T
n−k:n, Y S > Y S
n−k:n
#
8

The proof is provided in Appendix B. This proposition establishes a clear link between RVR and squared
tail dependence. The expression also introduces the coefficients cAD and cAB, which do not correspond to
any previously defined dependence measures. Notably, these coefficients are independent of both γT and γS.
The implications of Proposition 2 are summarized in the following corollary.
Corollary 2.1 The asymptotic RVR of the transferred Hill estimator is studied for k = k(n) →∞, k/n →0
as n →∞.
• For any source distribution, the asymptotic RVR is independent of the target EVI γT .
• For a heavy-tailed source distribution, i.e. F S ∈D(GEVγS) with γS > 0, the asymptotic RVR is
independent of the target and the source EVIs γT and γS.
This highlights a key strength of the method: the variance reduction does not require similarity in tail
heaviness between the source and target distributions.
4.2
Transferred moment estimator
Another variance-reduced EVI estimator can be derived from the moment estimator (Definition 4), by
applying the ACV/ACV method to both moments as follows.
Definition 7 (Transferred moment estimator) Let k ∈{1, . . . , n −1}, and assume Y T
n−k:n > 0, FT ∈
D(GEVγT ) and γT ∈R. Define the random variables
A = (ln(Y T ) −ln(Y T
n−k:n))1{Y T >Y T
n−k:n}
B = (ln(Y S) −ln(Y S
n−k:n))1{Y S>Y S
n−k:n}
(32)
C = 1{Y T >Y T
n−k:n}
D = 1{Y S>Y S
n−k:n}
(33)
G =
 ln(Y T ) −ln(Y T
n−k:n)
2 1{Y T >Y T
n−k:n}
H =
 ln(Y S) −ln(Y S
n−k:n)
2 1{Y S>Y S
n−k:n}
(34)
The variance-reduced empirical log-moments for j ∈{1, 2} are defined by
M (1)
CV = An + α(Bn+m −Bn)
Cn + β(Dn+m −Dn)
M (2)
CV = Gn + α′(Hn+m −Hn)
Cn + β′(Dn+m −Dn)
(35)
The transferred moment estimator of the EVI, using control variates, is given by
bγT
T M = M (1)
CV + 1 −1
2


1 −

M (1)
CV
2
M (2)
CV



−1
(36)
where the coefficients (α, β, α′, β′) are chosen to minimize the variance of each empirical moment and given
by
α = Var(D)Cov(A, B) −M (1)Var(D)Cov(B, C) + M (1)Cov(B, D)Cov(C, D) −Cov(B, D)Cov(A, D)
Var(B)Var(D) −Cov(B, D)2
(37)
β = Cov(B, D)Cov(A, B) −M (1)Cov(B, D)Cov(B, C) + M (1)Var(B)Cov(C, D) −Var(B)Cov(A, D)
M (1) (Var(B)Var(D) −Cov(B, D)2)
. (38)
α′ = Var(D)Cov(G, H) −M (2)Var(D)Cov(H, C) + M (2)Cov(H, D)Cov(C, D) −Cov(H, D)Cov(G, D)
Var(H)Var(D) −Cov(H, D)2
(39)
β′ = Cov(H, D)Cov(G, H) −M (2)Cov(H, D)Cov(H, C) + M (2)Var(H)Cov(C, D) −Var(H)Cov(G, D)
M (2) (Var(H)Var(D) −Cov(H, D)2)
(40)
where M (1) = E[A]/E[C] and M (2) = E[G]/E[C].
9

The estimator bγT
T M, as the moment estimator, is consistent for k = k(n) →∞, k/n →0 as n →∞.
With the definitions of A, B, C, D, G, H given above, all six variables belong to L2, ensuring the ap-
plicability of the control variates method.
As the variables fulfill the conditions |Corr(B, D)| < 1 and
|Corr(H, D)| < 1, the variance reduction is guaranteed for each moment individually. However, the ex-
pressions of the coefficients (α, β, α′, β′) proposed here are not optimal: they minimize the variance of each
moment M (1)
CV and M (2)
CV independently, and not the variance of the EVI estimator bγT
T M. This can lead to a
variance increase. Determining the optimal coefficients is an open question to be addressed. Here, the goal
is simply to demonstrate that the method applies to another EVI estimator.
5
Simulation study
Various results are presented here in order to study the properties of the variance-reduced EVI estimators
introduced in this work. Reported results are averaged over 10,000 independent repetitions. Performance is
measured with the RVR. Throughout all experiments, the number of extremes is set to k = 0.1n.
The target samples (Y T
i )i=1...n and source samples (Y S
i )i=1...n+m are simulated with Pareto marginals,
defined by the cdf
F(y) =



1 −

y
ym
−γ
if y ≥ym > 0
0
otherwise
(41)
where ym > 0 is the scale parameter and γ > 0 is the EVI, set to γT and γS for the target and source
samples respectively.
This distribution is selected because it satisfies the assumptions under which the
studied EVI estimators become asymptotically unbiased. It also allows direct control of the EVI value.
The scale parameter is set to ym = 10−3 to ensure all samples are strictly positive, as required by the EVI
estimators considered in this study.
The dependence between the source and target samples is modeled with a Gumbel copula CG, which is a
bivariate distribution function with uniform marginals that models strong dependence in the upper tail. It
is defined as
CG : (u1, u2) ∈[0, 1]2 7→exp

−
 (−log(u1))θ + (−log(u2))θ)
 1
θ 
(42)
where θ ≥1 controls how strong the the tail dependence is.
5.1
Comparison with the baseline estimators
In this section, the proposed variance-reduced estimators, the transferred Hill and the transferred moment
estimators, are compared to their respective baselines. The MLE-based estimator from (Ahmed et al., 2025)
is also included for comparison, with the parameter g set to the target EVI as recommended for optimal
results. It is important to note that the variance reduction approaches start from very different baselines:
the Hill estimator exhibits significantly lower variance than the MLE estimator, but also a higher bias. The
three different variance-reduced estimators and their baselines are presented together to give an overview of
possible results, but not for comparison. The Semi-Supervised Estimator (SSE) from (Ahmed et al., 2025) is
thus only included for context, since it is the only method with available code employing a semi-supervised
framework for a variance-reduced EVI estimator.
In Figure 1, the Gumbel copula parameter is set to θ = 10, resulting in a highly favorable setting with
strong dependence between target and source samples: [
Corr(A, B) = 0.99, [
Corr(C, D) = 0.92, and bλ = 0.93.
In this setting, the transferred estimators achieve an RVR of 71% when respectively compared to the Hill
and moment baseline estimators.
In Figure 2, the Gumbel copula parameter is set to θ = 1.4, resulting in a less favorable setting with
only mild dependence between the target and source data: [
Corr(A, B) = 0.50, [
Corr(C, D) = 0.35, and
bλ = 0.41. The RVR achieved by the transferred Hill and moment estimators remains similar, 12% and 10%
10

Figure 1: Boxplots of EVI estimations for different methods with strong target-source dependence
(γT = 0.25, γS = 0.5, n = 1, 000, k = 100, m = 5, 000, θ = 10)
Figure 2: Boxplots of EVI estimations for different methods with weaker target-source dependence
(γT = 0.25, γS = 0.5, n = 1, 000, k = 100, m = 5, 000, θ = 1.4)
respectively, but it is notably lower than in the stronger dependence scenario. The impact of dependence on
variance reduction is analysed in greater detail in Section 5.2.
11

The transferred estimators exhibit a slight bias compared to their baselines; this bias comes from the
estimation of the control variates coefficients, however it is often negligible in practice as discussed in (Owen,
2013).
5.2
Influence of the dependence between target and source samples on the
variance reduction
(a) RVR vs tail dependence bλ
(b) Variance vs tail dependence bλ
Figure 3: Variance reduction according to the target-source tail dependence
(γT = 0.25, γS = 0.5, n = 1, 000, k = 100, m = 5, 000)
Figure 3 presents the variance reduction achieved by the transferred Hill and moment estimators across
various target-source dependence settings, with the SSE estimator from (Ahmed et al., 2025) included for
comparison. The results illustrate that stronger dependence between target and source increases variance re-
duction. In particular, the figure highlights the theoretical link between asymptotic RVR and tail dependence
for the transferred Hill estimator, as established in Proposition 2.
5.3
Influence of the parameters on the variance reduction
In this section, the Gumbel copula parameter is set to θ = 5, creating a favorable framework where
[
Corr(A, B) = 0.96, [
Corr(C, D) = 0.84, and bλ = 0.86.
The first parameter studied is m, the number of additional source samples. Figure 4 shows that increasing
the number of additional source samples leads to greater variance reduction. This result is expected, as the
approximate control variates method benefits from a more accurate estimation of the control variate mean,
which improves with larger m. Indeed, when m →∞, the variance reduction obtained with approximate
control variates approaches that of the exact control variates method.
The parameters n and k are studied next, where n denotes the number of coupled samples and k the
number of extremes considered. For the sake of simplicity, only the value of n is described in the figure,
setting k = 0.1n. As shown in Figure 5, smaller sample sizes n lead to greater variance reduction, which is
expected given the higher variance of the baseline estimators in these scenarios. Notably, for n = 100 and
k = 10, the variance of the Hill estimator is significantly reduced using the transferred Hill estimator. This
is not the case for the moment estimator, which is excluded from the figure due to instability. This likely
stems from the fact that the coefficients employed are optimized for each moment individually, rather than
for reducing the overall variance of the EVI estimator. Additionally, they are more challenging to estimate
accurately, leading to the presence of outliers and increased variability. In the small-sample scenario with
12

(a) Variance vs number of additional source samples m
(b) RVR vs number of additional source samples m
Figure 4: (γT = 0.25, γS = 0.5, n = 1, 000, k = 100, θ = 5)
(a) Variance vs number of coupled samples n
(b) RVR vs number of coupled samples n
Figure 5: (γT = 0.25, γS = 0.5, m = 5, 000, θ = 5)
n = 100 and k = 10, the SSE estimator from (Ahmed et al., 2025) also underperforms.
The influence of different source EVI values is illustrated in Figure 6.
The values of γS tested are
{−0.66, −0.5, −0.33, −0.2, 0, 0.2, 0.25, 0.33, 0.5, 1}. Source samples with γS = 0 are simulated with a standard
Normal marginal, while those with γS < 0 follow a Beta marginal.
The results show that the variance reduction achieved by the transferred Hill estimator remains constant
for a range of positive source EVI values, as described in Corollary 2.1. When the source EVI is non-positive,
the variance reduction is lower but still satisfactory. The same results are observed with the transferred mo-
ment estimator. In contrast, the SSE estimator from (Ahmed et al., 2025) maintains stable performance
across all source EVI values. This is because the source samples are transformed to have a fixed, chosen EVI
g, making the initial source EVI irrelevant to the variance reduction.
The variance reduction for different target EVI values is also studied and illustrated in Figure 7. The
values of γT tested are {0.2, 0.25, 0.33, 0.5, 1, 1.33, 2}. The variance reduction achieved with the transferred
Hill estimator is independent of the target EVI estimated, as shown in Corollary 2.1.
13

(a) Variance vs source EVI γS
(b) RVR vs source EVI γS
Figure 6: (γT = 0.5, n = 1, 000, k = 100, m = 5, 000, θ = 5)
(a) Variance vs target EVI γT
(b) RVR vs target EVI γT
Figure 7: (γS = 0.5, n = 1, 000, k = 100, m = 5, 000, θ = 5)
6
Application
In this section, two applications are presented. The first one is based on a multi-fidelity model of water surge,
where the high-fidelity (HF) output is the target sample, and the low-fidelity (LF) output is the source. Since
both HF and LF models approximate the same physical process, their outputs are inherently dependent.
The second application uses a physics-based model of ice accretion on airplane wings. Two output variables,
computed at different locations along the same wing profile, are considered as the source and target samples.
The dependence between them is due to spatial continuity in the underlying physical phenomenon. These
two different examples highlight that the proposed variance reduction method for EVI estimators can be
applied in a wide range of scenarios.
The results presented in the following are obtained by bootstrapping 500 random subsamples of size n
from the n+m available joint observations, to assess the statistical variability and robustness of the methods
tested.
14

6.1
Water surge model
The water surge model is an analytical physics-based model initially developed in (Baudin et al., 2017) for
flood risk assessment. The high-fidelity (HF) version is derived from a simplified form of the one-dimensional
Saint-Venant equations, under the assumptions of a uniform, constant flow rate and large rectangular cross-
sections. The low-fidelity (LF) model used here was introduced in (Espoeys, 2025).
A reference value for the target EVI is obtained by computing the Hill, moment, and maximum-likelihood
estimators on a large HF dataset of size 10,000. Because the HF model is available and fast to evaluate,
generating such a large sample is possible and yields a highly accurate EVI estimate. The Hill plot method
(Caeiro and Gomes, 2015) allows to study the stability of the EVI estimates across values of k, and allows
here to check that k = 0.1n is a good choice. Figure 8 confirms that k = 1, 000 lies in a stable region and the
target EVI is estimated to be 0.239 with the MLE, known to be asymptotically unbiased. The figure also
highlights that the Hill estimator is biased for the water surge dataset, as discussed theoretically in Section
2.2.
Figure 8: Hill plot on 10,000 water surge HF samples
(a) (n, k, m) = (100, 10, 5000)
([
Corr(A, B) = 0.90, [
Corr(C, D) = 0.75, bλ = 0.78)
(b) (n, k, m) = (1000, 100, 5000)
([
Corr(A, B) = 0.95, [
Corr(C, D) = 0.77, bλ = 0.79)
Figure 9: Boxplots of EVI estimations on the water surge dataset
Two configurations are considered here: n = 100 or n = 1, 000 coupled HF-BF samples, with m = 5, 000
additional BF samples. The results are presented in Figure 9.
15

The correlations and tail dependence estimations are similar in both cases, though the dependence seems
to be lighter in the case n = 100. This is likely due to the smaller sample size, which may exclude the most
strongly dependent HF-LF observations. The transferred Hill estimator yields high RVR values, consistent
with the results obtained on simulated data when the dependence between target and source is high. The
variance reduction is stronger when n = 100 as the baseline estimator has a larger variance to begin with.
The bias, inherent to the baseline Hill estimator, is not increased.
The transferred moment estimator shows different results: when n = 1, 000, the variance is reduced but
a bias appears, and when n = 100 many outliers appear and the variance is increased. This can be explained
by the choice of coefficients (α, β, α′, β′), derived to reduce the variance of each moment and not that of the
whole estimator, and their complex expressions composed of many terms to estimate. As said previously, the
goal here is only to show that the transfer method can be applied to other EVI estimators; the coefficients
of the Moment estimator would need to be optimized for the whole estimator rather than for each moment
independently in order to guarantee variance reduction.
6.2
Ice accretion model
The ice accretion samples come from a physics-based simulation model (Trontin et al., 2017). Aircraft icing
occurs when supercooled water droplets freeze upon contact with the surface of an aircraft, which modifies
the geometry of the aircraft and can lead to performance degradation. It is mainly influenced by the angle of
attack (the angle between the wing and the airflow), the airspeed, the ambient temperature, and the liquid
water content. The ice accretion phenomenon has been involved in numerous fatal accidents and remains a
critical area of aeronautics research.
Figure 10: Mean and 95% empirical interval for all profiles of ice accretion
The dataset consists of 2,500 samples, each represented by a vector of 128 values measured along a
curvilinear abscissa of the wing profile. In the following analysis, the source and target samples correspond
to data at two different positions on the wing profile. Figure 10 shows the mean ice accretion and its 95%
empirical interval at each abscissa, providing an overview of the data. The values for abscissae between 0
and 25, as well as between 75 and 128, are all zero and therefore excluded from the analysis. The parameters
are set to n = 500 coupled samples, k = 50 extremes, and m = 2, 000 additional source samples.
To choose which samples to consider as target and source, a grid search across all possible abscissae pairs
is performed by computing the associated correlations [
Corr(A, B) and [
Corr(C, D) and the tail dependence
bλ. Pairs with high correlation and tail dependence can lead to strong variance reduction, allowing to il-
lustrate the proposed method. The results of the grid search are presented in Figure 11. The correlation
heatmaps are not exactly symmetrical, as the source mean estimation is based on n + m points, while the
target mean estimation is based on only n points. As expected, source and target samples exhibit strong
dependence when they are spatially close on the profile, which can be seen on the main diagonal. Particularly
high dependence is observed for abscissae 25 to 35, around 55, and from 70 to 75. Additionally, there are
regions of moderate dependence even when the source and target samples are relatively distant, suggesting
the presence of broader structural dependencies beyond local proximity. For the rest of the analysis, the
16

Figure 11: Tail dependence bλ for all combinations of abscissae
following pairs of abscissae are considered: a target index at 36 and a source index at 31, representing closely
located positions with strong correlation; and another with a target index at 67 and a source index at 43,
representing more distant positions with moderate correlation.
The reference EVI values are computed using all 2,500 available target samples with the Hill plot method
illustrated in Figure 12. The target EVI for index 36 is estimated to be 0.294, and for index 67, -0.475. As
noted in section 2.2, the Hill estimator is known to suffer from bias, and this is observed in the estimates for
both target indices 36 and 67 in the ice accretion dataset.
Figure 13 presents the results of the various EVI estimators for the two combinations of abscissae consid-
ered. The variance reduction obtained with the transferred Hill estimator is more moderate here, which can
be explained by the limited number of additional source samples m = 2, 000. With the target index 67, the
EVI to estimate is negative, and the transferred moment estimator offers a substantial variance reduction of
17%.
17

(a) Target index=36
(b) Target index=67
Figure 12: Hill plots on 2,500 ice accretion HF samples
(a) Target index=36 and source index=31
([
Corr(A, B) = 0.72, [
Corr(C, D) = 0.91, bλ = 0.92)
(b) Target index=67 and source index=43
([
Corr(A, B) = 0.65, [
Corr(C, D) = 0.62, bλ = 0.66)
Figure 13: Boxplots of EVI estimations on the ice accretion dataset
18

7
Conclusion
In this paper, new variance-reduced EVI estimators using transfer learning have been introduced by apply-
ing the approximate control variates method for ratio of means estimator. The proposed transferred Hill
estimator achieves significant variance reduction under strong tail dependence between the target and source
distributions, as demonstrated theoretically and in simulations. Notably, under suitable assumptions, its
asymptotic RVR is independent of the target and source EVIs, allowing the method to remain effective even
when the two distributions differ substantially in tail heaviness. The variance reduction benefits from a
larger number m of additional source samples. Thanks to the fundamental property of control variates, the
transferred Hill estimator necessarily yields a reduced, or at least non-increased, variance compared to the
standard Hill estimator.
Two different applications were presented, on water surge multi-fidelity data and on ice accretion data,
showing how widely the new estimators presented can be used.
A natural next step is to leverage the proposed variance-reduced EVI estimators for the estimation of
extreme quantiles and rare event probabilities, which are critical in many risk assessment and engineering
applications.
The proposed approach has been applied to the Hill estimator to estimate γT > 0. We showed that it
could be applied to the moment estimator to estimate γT > −1
2. However, its coefficients (α, β, α′, β′) should
be optimized for the whole estimator rather than to minimize the variance of each moment independently,
in order to get the variance reduction guarantee. Future work could aim to apply the approach to other EVI
estimators, in particular for γT ≤−1
2.
Acknowledgements
We gratefully acknowledge our ONERA colleagues Lokman Bennani, Ghislain Blanchard, Maxime Bouyges,
and Patricia Klotz for providing the ice accretion dataset.
Declarations
Supplementary material
All codes used to produce the figures on simulated data are available on GitHub at https://github.com/
LouB-N/Variance-reduced-extreme-value-index-estimators.git.
Competing Interests
All authors certify that they have no affiliations with or involvement in any organization or entity with any
financial interest or non-financial interest in the subject matter or materials discussed in this manuscript.
Declaration of generative AI use in the manuscript preparation process
During the preparation of this work, the authors used Chat-GPT 5 in order to improve language and
readability.
After using this tool, the authors reviewed and edited the content as needed and take full
responsibility for the content of the published article.
19

A
Proof of Proposition 1: studying the consistence of the trans-
ferred Hill estimator
Since the samples of B and D are i.i.d. and their means are finite, the differences of Monte Carlo estimators
on n + m and on n points almost surely tend to 0:
Bn+m −Bn
a.s.
−→
n→∞
m→∞
0
and
Dn+m −Dn
a.s.
−→
n→∞
m→∞
0
Therefore, the transferred Hill estimator is asymptotically equivalent to the Hill estimator:
bγT
T H −bγT
T = An + α(Bn+m −Bn)
Cn + α(Dn+m −Dn) −An
Cn
a.s.
−→
n→∞
m→∞
0
=⇒
bγT
T H −bγT
T
P
−→
n→∞
m→∞
0
Hence the transferred Hill estimator is asymptotically consistent under the same conditions as the Hill
estimator, i.e. first and second order conditions for m →∞, k = k(n) →∞, k/n →0 as n →∞.
B
Proof of Proposition 2: studying the asymptotic variance reduc-
tion with the transferred Hill estimator
In this section, the variance reduction with the transferred Hill estimator is studied. The following formula
of variance reduction with the approximate control variates estimator compared to the baseline Monte Carlo
estimator for a ratio of means comes from (Bocquet-Nouaille et al., 2025).
Var
 bγT
H

−Var
 bγT
T H

≈
n→∞−
m
n(n + m)
1
E[C]2
V ar
 γT Cov(B, C) −Cov(A, B)

D −
 γT Cov(C, D) −Cov(A, D)

B

Var(B)Var(D) −Cov(B, D)2
where A = (ln(Y T ) −ln(Y T
n−k:n))1{Y T >Y T
n−k:n}
B = (ln(Y S) −ln(Y S
n−k:n))1{Y S>Y S
n−k:n}
C = 1{Y T >Y T
n−k:n}
D = 1{Y S>Y S
n−k:n}
We want to study the variance reduction asymptotically, that is when k = k(n) →∞, k
n →0 for n →∞.
That means the thresholds Y T
n−k:n and Y S
n−k:n tend to the target and source endpoints yT ∗and yS∗. For the
sake of simplicity, we note the limits as n →∞.
B.1
Preliminary results
As stated in Theorem 2 (Pickands–Balkema–de Haan), the conditional excess distribution of a random
variable Y over a threshold u converges to the Generalized Pareto distribution:
F ∈D(GEVγ) ⇐⇒lim
u→y∗Fu (σ(u)y) = GPγ(y)
:=
(
1 −(1 + γy)−1
γ
if γ ̸= 0,
0 < y < (0 ∨(−γ))−1;
1 −exp(−y)
if γ = 0,
y ∈R
where Fu(y) = P(Y −u ≤y|Y > u) and σ(·) a positive scaling function.
20

To analyze the asymptotic variance reduction, it is necessary to study the asymptotic distribution of the
log-excesses. Observe the relationship between the distribution of excesses and that of the log-excesses:
P

ln
Y
u

≤y
Y > u

= P
Y
u ≤ey
Y > u

= P (Y −u ≤u(ey −1)|Y > u)
= Fu (u(ey −1))
≈
u→y∗GPγ
 1
γ (ey −1)

if γ > 0
This allows to compute the asymptotic mean log-excess. The asymptotic cdf is GPγ

1
γ (ey −1)

, ∀y ≥0,
therefore the asymptotic pdf is
d
dy GPγ
 1
γ (ey −1)

= d
dy

1 −e−y
γ

= 1
γ e−y
γ
We note that this is the pdf of an exponential distribution with parameter 1/γ.
The asymptotic mean log-excess is derived as:
E
"
ln
Y
u
 Y > u
#
≈
u→y∗E [X] =
Z +∞
0
y
γ e−y
γ dy
where X has cdf GPγ
 1
γ (ey −1)

= γ
Z +∞
0
ze−zdz
with the change of variable z = y
γ
= γ
To conclude, the asymptotic mean log-excess is:
E
"
ln
Y
u
 Y > u
#
≈
u→y∗γ
if γ > 0
(43)
Note that when γ > 0, the log-excesses are asymptotically exponentially distributed with mean γ, which
implies that the scaled log-excesses Z :=

ln(Y/u)
γ
Y > u

asymptotically follow a standard exponential
distribution.
B.2
Studying the asymptotic variance reduction
B.2.1
Proof of the first statement in Proposition 2
Define ϵA = A−γT C, the random deviation of the log excesses from it expected value, with the useful prop-
erty E[ϵA] = E[A] −γT E[C]
→
n→∞0, as E[A]
E[C] = E[ln(Y T ) −ln(Y T
n−k:n)|Y T > Y T
n−k:n]
→
n→∞γT (see Remark
1.2.3 of (de Haan and Ferreira, 2006) or previous section).
By replacing A with ϵA + γT C,the following terms are simplified:
γT Cov(B, C) −Cov(A, B) = γT Cov(B, C) −Cov(ϵA + γT C, B) = −Cov(ϵA, B)
and γT Cov(C, D) −Cov(A, D) = γT Cov(C, D) −Cov(ϵA + γT C, D) = −Cov(ϵA, D)
21

The variance expression can be written as:
Var
 bγT
H

−Var
 bγT
T H

≈
n→∞
m
n(n + m)
1
E[C]2
V ar

−Cov(ϵA, B)D + Cov(ϵA, D)B

Var(B)Var(D) −Cov(B, D)2
≈
n→∞
m
n(n + m)
1
E[C]2
Cov(ϵA, B)2Var(D) + Cov(ϵA, D)2Var(B) −Cov(ϵA, B)Cov(ϵA, D)Cov(B, D)
Var(B)Var(D) −Cov(B, D)2
Define ϵ′
A = ϵA/γT that is asymptotically independent from γT .
Indeed, ϵ′
A = (
ln(Y T )−ln(Y T
n−k:n)
γT
−
1)1{Y T >Y T
n−k:n} = (Z −1)/1{Y T >Y T
n−k:n} where Z asymptotically follows a standard exponential distribution,
therefore ϵ′
A is asymptotically independent from γT .
The variance reduction can be written as:
Var
 bγT
H

−Var
 bγT
T H

≈
n→∞(γT )2
m
n(n + m)
1
E[C]2
Cov(ϵ′
A, B)2Var(D) + Cov(ϵ′
A, D)2Var(B) −Cov(ϵ′
A, B)Cov(ϵ′
A, D)Cov(B, D)
Var(B)Var(D) −Cov(B, D)2
:=(γT )2W
Considering the relative variance reduction:
RV R = Var
 bγT
H

−Var
 bγT
T H

Var
 bγT
H

≈
n→∞W
as Var
 bγT
H

≈
n→∞(γT )2
To prove the RVR is asymptotically independent from γT , we need to prove W is asymptotically independent
from γT . The variables B and D are independent of γT as they are functions of only Y S. We showed ϵ′
A is
asymptotically independent from γT . The variable C follows a Bernoulli distribution with success probability
p = k/n, independent from γT . Considering all the random variables in W are asymptotically independent
from γT , so is W.
B.2.2
Proof of the second statement in Proposition 2
Let us study W in more detail. Assume Y S ∈D(GγS) and γS > 0 for now. We will need the following
expressions:
• E[C] = E[D] := p
• E[B] = E[ln(Y S) −ln(Y S
n−k:n)|Y S > Y S
n−k:n]P(Y S > Y S
n−k:n)
≈
n→∞γSp
• E[B2] = E[
 ln(Y S) −ln(Y S
n−k:n)
2 |Y S > Y S
n−k:n]P(Y S > Y S
n−k:n)
≈
n→∞E[Z2]p = 2(γS)2p
where Z is a standard exponential r.v.
• E[BD] = E[B]
≈
n→∞γSp
• E[ϵ′
A]
≈
n→∞0
• E[ϵ′
AD] = E
"
ln(Y T ) −ln(Y T
n−k:n)
γT
−1
Y T > Y T
n−k:n, Y S > Y S
n−k:n
#
P(Y T > Y T
n−k:n, Y S > Y S
n−k:n)
≈
n→∞cADλp
• E[ϵ′
AB] = E
" 
ln(Y T ) −ln(Y T
n−k:n)
γT
−1
!
 ln(Y S) −ln(Y S
n−k:n)

Y T > Y T
n−k:n, Y S > Y S
n−k:n
#
× P(Y T > Y T
n−k:n, Y S > Y S
n−k:n)
≈
n→∞γScABλp
22

where λ is the tail dependence.
cAD = E
"
ln(Y T ) −ln(Y T
n−k:n)
γT
−1
Y T > Y T
n−k:n, Y S > Y S
n−k:n
#
≈
n→∞E
"
Z −1
Y T > Y T
n−k:n, Y S > Y S
n−k:n
#
cAB = E
" 
ln(Y T ) −ln(Y T
n−k:n)
γT
−1
!  
ln(Y S) −ln(Y S
n−k:n)
γS
! Y T > Y T
n−k:n, Y S > Y S
n−k:n
#
≈
n→∞E
"
(Z −1)Z
Y T > Y T
n−k:n, Y S > Y S
n−k:n
#
cAD and cAB are measures of extremal dependence. Considering Z is a standard exponential variable,
independent from γT and γS, then cAD and cAB are asymptotically independent from γT and γS.
To rewrite the terms in the variance reduction in an asymptotic form:
• Var(D) = p(1 −p)
• Var(B) = E[B2] −E[B]2
≈
n→∞2(γS)2p −(γS)2p2 = (γS)2p(2 −p)
• Cov(B, D) = E[BD] −E[B]E[D]
≈
n→∞γSp −γSp2 = γSp(1 −p)
• Cov(ϵ′
A, D) = E[ϵ′
AD] −E[ϵ′
A]E[D]
≈
n→∞cADλp
• Cov(ϵ′
A, B) = E[ϵ′
AB] −E[ϵ′
A]E[B]
≈
n→∞γScABλp
Using these expressions, we show the RVR is asymptotically independent from γT and γS > 0:
RV R
≈
n→∞
m
n(n + m)
1
p2
Cov(ϵ′
A, B)2Var(D) + Cov(ϵ′
A, D)2Var(B) −Cov(ϵ′
A, B)Cov(ϵ′
A, D)Cov(B, D)
Var(B)Var(D) −Cov(B, D)2
≈
n→∞
m
n(n + m)
(γS)2c2
ABλ2p3(1 −p) + c2
ADλ2p3(2 −p)(γS)2 −cABcADλ2p3(1 −p)(γS)2
p2 ((γS)2p2(2 −p)(1 −p) −(γS)2p2(1 −p)2)
≈
n→∞λ2
m
n(n + m)
c2
AB + c2
AD
2−p
1−p −cABcAD
p
We can also clearly see a link with the tail dependence, even though the RVR also depends on cAB and cAD,
which also measure a form of extremal dependence.
C
Selecting the source threshold
The goal here is to determine the optimal number of source extremes l, that is the optimal source threshold,
given a fixed number of target extremes k = 0.1n, using simulated data. As in Section 5, the data is generated
using Pareto marginals with γT = 0.25 and γS = 0.5, a Gumbel copula with parameter θ = 5, n = 1, 000
coupled target-source samples, k = 100 target extremes, and m = 5, 000 additional source data. The results
of 10,000 simulations are presented in Figure 14.
The analytical variance of the transferred Hill estimator is computed in each of the 10,000 simulations,
and the resulting values are displayed in Figure 14. Some variance estimates appear negative, particularly
for small values of l, which may be due to the limited number of extreme observations used in the estimation:
it makes the analytical expression unstable and unreliable.
23

Figure 14: Boxplots of the analytical variance of the transferred Hill estimator for different numbers of
source extremes l
Left: full range of l ∈{1, 999}. Right: zoomed-in view for l ∈{60, 140}. The red dotted line marks k = 100.
The minimum estimated variance is found slightly below l = 100, which coincides with the number of
target extremes k = 100. However, as seen in the right plot, differences in variance values are relatively
small in this region.
When the dependence between the source and target is weaker, the optimal number of source extremes
minimizing variance tends to shift slightly upward. Nevertheless, using the same number of extremes for both
source and target samples remains a reasonable and practical choice. Setting l = k simplifies the analysis
and retains nearly optimal performance across different dependence structures.
References
Ahmed, H. and Einmahl, J. H. (2019). Improved estimation of the extreme value index using related variables.
Extremes, 22:553–569.
Ahmed, H., Einmahl, J. H., and Zhou, C. (2025). Extreme Value Statistics in Semi-Supervised Models.
Journal of the American Statistical Association, 120(549):291–304.
Alves, M. I. F., Gomes, M. I., de Haan, L., and Neves, C. (2007). A Note on Second Order Conditions in
Extreme Value Theory: Linking General and Heavy Tail Conditions. REVSTAT-Statistical Journal, pages
285–304.
Asmussen, S. (1998). Extreme Value Theory for Queues Via Cycle Maxima. Extremes, pages 137–168.
Asmussen, S. and Glynn, P. W. (2007). Variance-Reduction Methods. In Stochastic Modelling and Applied
Probability. Springer New York.
Balkema, A. A. and de Haan, L. (1974). Residual life time at great age. The Annals of Probability, pages
792–804.
Baudin, M., Dutfoy, A., Iooss, B., and Popelin, A.-L. (2017). OpenTURNS: An Industrial Software for
Uncertainty Quantification in Simulation. In Handbook of Uncertainty Quantification, pages 2001–2038.
Springer International Publishing.
Bobbia, B., Dombry, C., and Varron, D. (2025). A Donsker and Glivenko-Cantelli theorem for random
measures linked to extreme value theory. Scandinavian Journal of Statistics.
24

Bocquet-Nouaille, L., Morio, J., and Bobbia, B. (2025). Control variates for variance-reduced ratio of means
estimators. arXiv preprint.
Bousquet, N. and Bernardara, P., editors (2021). Extreme Value Theory with Applications to Natural Hazards:
From Statistical Theory to Industrial Practice. Springer International Publishing.
Caeiro, F. and Gomes, M. I. (2015). Threshold selection in extreme value analysis. Extreme value modeling
and risk analysis: Methods and applications, pages 69–87.
Caeiro, F., Henriques-Rodrigues, L., Gomes, M. I., and Cabral, I. (2020). Minimum-variance reduced-bias
estimation of the extreme value index: A theoretical and empirical study. Computational and Mathematical
Methods.
Cai, J.-J., de Haan, L., and Zhou, C. (2013). Bias correction in extreme value statistics with index around
zero. Extremes, 16(2):173–201.
de Haan, L. (1975). On regular variation and its application to the weak convergence of sample extremes.
Centrum Voor Wiskunde en Informatica.
de Haan, L. (1984). Slow Variation and Characterization of Domains of Attraction. In Statistical Extremes
and Applications. Springer Netherlands.
de Haan, L. and Ferreira, A. (2006). Extreme Value Theory. Springer Series in Operations Research and
Financial Engineering. Springer.
De la Luz, V., Balanzario, E. P., and Tsiftsi, T. (2018). Estimating the Maximum Intensities of Soft X-Ray
Flares Using Extreme Value Theory. Solar Physics.
Dekkers, A. L., Einmahl, J. H., and de Haan, L. (1989). A moment estimator for the index of an extreme-value
distribution. The Annals of Statistics, pages 1833–1855. Publisher: JSTOR.
Einmahl, J. H. and Peng, L. (2024). Variance-Reduced Risk Inference in Semi-Supervised Settings. Technical
report, CentER, Center for Economic Research.
Einmahl, J. J., Einmahl, J. H. J., and de Haan, L. (2019). Limits to Human Life Span Through Extreme
Value Theory. Journal of the American Statistical Association, pages 1075–1080.
Embrechts, P., Klüppelberg, C., and Mikosch, T. (1997).
Modelling Extremal Events.
Springer Berlin
Heidelberg.
Espoeys, R. (2025). Optimisation multi-fidélité sous incertitudes, application à la conception de systèmes
complexes. PhD thesis, Université de Toulouse.
Fisher, R. A. and Tippett, L. H. C. (1928). Limiting forms of the frequency distribution of the largest
or smallest member of a sample.
In Mathematical proceedings of the Cambridge philosophical society,
volume 24, pages 180–190. Cambridge University Press.
Gnedenko, B. (1943). Sur la distribution limite du terme maximum d’une série aleatoire. The Annals of
Mathematics, pages 423–453.
Gomes, M. I., Brilhante, M. F., and Pestana, D. (2016). New reduced-bias estimators of a positive extreme
value index. Communications in Statistics-Simulation and Computation, pages 833–862.
Gorodetsky, A. A., Geraci, G., Eldred, M. S., and Jakeman, J. D. (2020).
A generalized approximate
control variate framework for multifidelity uncertainty quantification. Journal of Computational Physics,
408:109257.
Hill, B. M. (1975). A simple general approach to inference about the tail of a distribution. The Annals of
Statistics, pages 1163–1174.
25

Kim, M., Brown, B., and Pipiras, V. (2024). Parametric multi-fidelity Monte Carlo estimation with appli-
cations to extremes.
Malevergne, Y. and Sornette, D. (2002). Investigating Extreme Dependences: Concepts and Tools.
Owen, A. B. (2013).
Variance reduction.
In Monte Carlo theory, methods and examples, pages 28–33.
\url{https://artowen.su.domains/mc/}.
Peherstorfer, B., Willcox, K., and Gunzburger, M. (2018). Survey of Multifidelity Methods in Uncertainty
Propagation, Inference, and Optimization. SIAM Review, 60:550–591.
Pickands III, J. (1975). Statistical inference using extreme order statistics. The Annals of Statistics, pages
119–131.
Trontin, P., Blanchard, G., Kontogiannis, A., and Villedieu, P. (2017). Description and assessment of the
new ONERA 2D icing suite IGLOO2D. In 9th AIAA Atmospheric and Space Environments Conference,
pages 1–28. American Institute of Aeronautics and Astronautics.
Zhan, Z., Xu, M., and Xu, S. (2015). Predicting cyber attack rates with extreme values. IEEE Transactions
on Information Forensics and Security, pages 1666–1677.
Zhu, Z., Yan, Y., Li, G., and Zhang, R. (2025). Recent Developments on Statistical Transfer Learning.
International Statistical Review.
26
