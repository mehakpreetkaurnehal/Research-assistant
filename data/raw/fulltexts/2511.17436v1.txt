A Framework for Adaptive Stabilisation of Nonlinear Stochastic
Systems â‹†
Seth Siriya a, Jingge Zhu b, Dragan NeÅ¡iÄ‡ b, Ye Pu b
aLeibniz University Hannover, Institute of Automatic Control, 30167 Hannover, Germany
bUniversity of Melbourne, Department of Electrical and Electronic Engineering, Parkville VIC 3010, Australia
Abstract
We consider the adaptive control problem for discrete-time, nonlinear stochastic systems with linearly parameterised uncer-
tainty. Assuming access to a parameterised family of controllers that can stabilise the system in a bounded set within an
informative region of the state space when the parameter is well-chosen, we propose a certainty equivalence learning-based
adaptive control strategy, and subsequently derive stability bounds on the closed-loop system that hold for some probabilities.
We then show that if the entire state space is informative, and the family of controllers is globally stabilising with appropri-
ately chosen parameters, high probability stability guarantees can be derived.
Key words: Adaptive control; discrete-time systems; least squares; nonlinear systems; stochastic systems.
1
Introduction
Adaptive control (AC) is concerned with the control of
dynamical systems with parameters which are uncer-
tain, online, in a single trajectory. It is useful in situ-
ations where one is not afforded the luxury of running
many experiments to collect data offline for the purpose
of system identification. Rigorously characterising the
stochastic stability properties of these methods is im-
portant for understanding the situations in which an AC
strategy can be successfully deployed on a system. Of
great interest are methods that can provably handle non-
linear systems subject to stochastic process noise, since
many real-world systems are nonlinear and influenced
by factors with random characteristics.
The stability problem in stochastic AC has a rich his-
tory, with the first stability results for AC in unstable
linear plants obtained back in the 1980s by Goodwin and
Caines [7]. Although results for linear systems are well
explored, the nonlinear setting continues to attract at-
tention. In a series of works [8,22,13,14], the fundamental
â‹†This paper was not presented at any IFAC meeting. Cor-
responding author S. Siriya.
Email addresses: siriya@irt.uni-hannover.de (Seth
Siriya), jingge.zhu@unimelb.edu.au (Jingge Zhu),
dnesic@unimelb.edu.au (Dragan NeÅ¡iÄ‡),
ye.pu@unimelb.edu.au (Ye Pu).
limits of the stabilisation problem for a class of discrete-
time systems with linearly parameterised uncertainties
â€” that is, systems where the model uncertainties are
formulated as a linear combination of known nonlinear
basis functions of the states and controls â€” is investi-
gated. These works require that it is possible for controls
to completely cancel all system dynamics in a single step,
and they show that a certainty equivalence least squares-
based AC strategy provably stabilises the system un-
der various assumptions, often involving restrictions on
the growth of basis functions. In [6], stability-based re-
gret bounds were derived for an online gradient-based
discrete-time AC method for linearly parameterised sys-
tems with matched uncertainties â€” that is, problems
where the controls may not necessarily cancel the entire
system dynamics, but just the model uncertainties. The
AC problem for discrete-time input-constrained linear
systems subject to unbounded stochastic disturbances
was also recently addressed in [19] and [20] under vari-
ous assumptions, which can be viewed as a linearly pa-
rameterised nonlinear system. Moreover, the adaptive
stabilisation problem for stochastic control-affine SISO
systems and stochastic discrete-time parametric strict-
feedback systems has also been addressed in [22] and [21]
respectively. Although all these results are interesting,
it is desirable to obtain results which are applicable to
other systems with linearly parameterised uncertainty
without such structural restrictions.
arXiv:2511.17436v1  [eess.SY]  21 Nov 2025

Some works in the continuous-time, deterministic set-
ting do not impose such structural restrictions. In [5],
a framework for learning-based AC is proposed which
combines an integral input-to-state stabilising controller
with an extremum seeking-based parameter update law.
By learning, we mean that the parameter estimates con-
verge towards the true parameters [4], and by learning-
based we mean that the stability guarantees are reliant
on learning. Moreover, in [11], an AC framework is pro-
posed for a class of linearly parameterised systems that
combines a dead-beat parameter estimator with a cer-
tainty equivalence control law, meaning the controller as
chosen as if the estimated parameter is the true param-
eter. These results provide a framework for AC, such
that the systems they can be applied to depend on the
specifically chosen controller. However, stability guaran-
tees require that the chosen controller can globally sta-
bilise the system when given the true parameter, which
is restrictive in many real-world situations.
There are some AC works applicable to linearly pa-
rameterised systems without requiring the aforemen-
tioned structural restrictions and global stabilisability,
mainly from the robust adaptive model predictive con-
trol (MPC) community (see [1], [2], [12], [17]). However,
they typically require the knowledge of a bounded un-
certainty set which the true parameter belongs to, and
that a feasible solution exists to the robust MPC prob-
lem that accounts for all possible parameters in this set.
However, one may not always know enough about the
system to determine such a set.
Motivated by these aforementioned gaps, we aim to pro-
vide a modular framework for the AC of a broad class of
discrete-time stochastic nonlinear systems with linearly
parameterised uncertainties, which does not require a
priori knowledge of a set of parameters which renders the
system bounded. Moreover, we aim to derive stochastic
stability guarantees for the closed-loop system which are
applicable even when the system is not globally stabilis-
able. This guarantee need to be derived under assump-
tions that can be easily verified based on the system
model offline. Our contributions are as follows.
Firstly, we provide a framework for certainty equivalence
AC in linearly parameterised systems, that combines a
parameterised stabilising policy with regularised least
squares (RLS) for parameter estimation. The framework
is intuitive since the parameterised controller is selected
based on the CE principle.
Secondly, we derive a probabilistic guarantee that the
states of the system will remain positively invariant on
a subset of the state space for all time, and that a non-
asymptotic bounds on the parameter estimation error
will holds for sufficiently large time, under some assump-
tions. These bounds asymptotically converge towards
zero, and thus characterise a bound on how fast learn-
ing is occurring. The assumptions are related to the in-
stability of the system and the growth rate of the basis
functions. They also rely on the assumption that when
the parameter estimation error is sufficiently small, the
chosen controller parameterised policy will render the
states of the system positively invariant in a subset of
the state space satisfying a regional excitation condition.
This latter condition ensures the regressor data is infor-
mative for learning, so the parameter estimation error
will eventually be small enough for the control policy to
enforce invariance.
Thirdly, we derive probabilistic stability bounds under
the previous assumptions, and by additionally assuming
the existence of stochastic Lyapunov function over the
positively invariant set for the closed-loop system when
the parameter estimate used for control is close to the
true parameter. This guarantee is enabled via a learning-
based analysis, where the convergence of the parameter
estimates ensures that eventually the controller performs
similar to the case when the true parameter is known,
and thus is able to stabilise the system.
Fourthly, by strengthening the assumptions to require
that the system produces informative regressor data over
the entire state space such that global excitation holds,
and the existence of a global stochastic Lyapunov func-
tion when the parameter estimation error is sufficiently
small, we derive high probability stability bounds â€” that
is, stability bounds which hold with arbitrary probabil-
ity less than 1.
Finally, we demonstrate our proposed framework on the
adaptive control problem for a stochastic PWA system,
and an input-constrained linear system subject to Gaus-
sian disturbances. In particular, we show that with an
appropriately selected policy, the probabilistic guaran-
tee for the estimation error and positive invariance holds
on both examples. Moreover, the probabilistic stability
bounds can be established for the PWA system example,
and the stronger high probability stability bound result
can be established for the input-constrained linear sys-
tem example.
The work is organised as follows. In Section 2, we intro-
duce the class of discrete-time stochastic systems and the
AC framework considered in this paper, as well as stand-
ing assumptions. Section 3 contains our main results,
where we recall the definition of regional and global ex-
citation, introduce our notion of a stochastic Lyapunov
function, and derive the estimation error bound and sta-
bility bound results. Section 4 contains the PWA sys-
tem and input-constrained linear systems examples that
demonstrate the benefit of our main results. Section 5
contains the proof of our results. Our conclusions are
presented in Section 6.
Notation
Denote by RnÃ—m the set of real matri-
ces of dimension n âˆˆN and m âˆˆN. The space Rn
2

stands for RnÃ—1. For a matrix A âˆˆRnÃ—m, |A| de-
notes its induced 2-norm, |A|F denotes its Frobenius
norm, and Br(A) := { ËœA âˆˆRnÃ—m | | ËœA âˆ’A| â‰¤r}.
For a vector v âˆˆRn and a positive definite matrix
A âˆˆRn, |v|A =
âˆš
vâŠ¤Av denotes the weighted Eu-
clidean norm. Denote the unit sphere embedded in Rd
by Sdâˆ’1. Consider the function f : Râ‰¥0 â†’Râ‰¥0. Given
the function g : Râ‰¥0 â†’Râ‰¥0, we say f(r) = O(g(r)) if
limrâ†’âˆž
f(r)
g(r) < âˆž, and h(r) = o(r) if limrâ†’âˆž
f(r)
g(r) = 0.
Consider a set S. The power set of S is denoted by 2S.
The indicator function of S is defined by 1S(x) := 1 if
x âˆˆS, and 1S(x) := 0 otherwise. Consider a collection
of subsets C âŠ†2S. The collection C âŠ†2S is called a
Ïƒ-field in S if it is closed under countable union and in-
tersection, as well as under complement. Ïƒ(C) denotes
the Ïƒ-field generated by C, which is the intersection of all
Ïƒ-fields in S containing C. Consider the matrix subsets
X âŠ†Y âŠ†RnÃ—m. We say X is an open subset of Y if for
every x âˆˆX, there exists r > 0 such that the open ball
of radius r centred at x is a subset of X. B(Y ) denotes
the Borel Ïƒ-field of Y , which is defined as B(Y ) := Ïƒ(O)
where O âŠ†2Y is the collection of all open subsets of
Y . Consider a measurable space (S, S) and a mapping
f : S â†’RnÃ—m. The set A âŠ†S is S-measurable if A âˆˆS.
Given Y âŠ†T, f âˆ’1(Y ) := {s âˆˆS | f(s) âˆˆY }. We
say that f is S-measurable if fâˆ’1(X) is S-measurable
for all X âˆˆB(RnÃ—m). Additionally, if S âŠ†RpÃ—q, we
say f is Borel measurable if f is B(S)-measurable.
Consider a probability space (â„¦, F, P). We call a map-
ping X : â„¦â†’RnÃ—m a random variable if X is mea-
surable, and additionally a random vector if m = 1,
and a scalar random variable if n = m = 1. We
define a random sequence as a sequence {X(i)}iâˆˆI
of random variables X(i) : â„¦â†’RnÃ—m over i in
an index set I âŠ†N. Consider a collection of ran-
dom variables X1, X2, . . . taking values in X1, X2, . . .
and a predicate Q : X1 Ã— X2 Ã— Â· Â· Â· â†’{true, false}.
With an abuse of notation, {Q(X1, X2, . . .)} stands for
{Ï‰ âˆˆâ„¦| Q(X1(Ï‰), X2(Ï‰), . . .)}, and P (Q(X1, X2, . . .))
stands for P ({Q(X1, X2, . . .)}). The function h : Râ‰¥0 â†’
Râ‰¥0 is said to be n-order sub-exponential (n-SE) if
ln(h(rn)) = o(r). The function Î± : Râ‰¥0 â†’Râ‰¥0 is in class
K if it is continuous, strictly increasing, and Î±(0) = 0.
The function Î± : Râ‰¥0 â†’Râ‰¥0 is in class Kâˆžif Î±(Â·) âˆˆK
and unbounded, i.e., limsâ†’âˆžÎ±(s) = âˆž. The function
Î± : Râ‰¥0 â†’Râ‰¥0 is in class Kn-SE
âˆž
if Î± âˆˆKâˆžand Î± is
n-SE. A function h : Râ‰¥0 â†’Râ‰¥0 is said to be asymptot-
ically polynomially bounded (APB) if there exists k âˆˆN
such that h(r) = O(rk). The function Î· : N0 â†’Râ‰¥0 is
in class L if it is non-increasing and limtâ†’âˆžÎ·(t) = 0.
The function Î² : Râ‰¥0 Ã— N0 â†’Râ‰¥0 is in class KL if
Î²(Â·, t) âˆˆK for any t âˆˆN0 and Î²(r, Â·) âˆˆL for any r â‰¥0.
2
Problem Setup and Framework
We start by describing the stochastic system and adap-
tive control framework considered in this work in Sec-
tion 2.1. Afterwards, in Section 2.2, we make various as-
sumptions that ensure stochastic properties of interest
for our system are well-defined, and allow us to derive es-
timation error and stability bounds in our main results.
2.1
Discrete-Time Stochastic System and Adaptive
Control Framework
Let (â„¦, F, P) be the probability space on which all of our
random variables are defined, and denote expectation
and variance by E and Var respectively. Consider the
discrete-time, stochastic, nonlinear system
X(t + 1) =f(X(t), U(t)) + Î¸âŠ¤
âˆ—Ïˆ(X(t), U(t))
+ W(t + 1), t âˆˆN0,
(1)
with X(0) = x0. Here, the process noise {W(t)}tâˆˆN
is a random sequence taking values in WâŠ†Rn, and
{X(t)}tâˆˆN0 and {U(t)}tâˆˆN0 are the sequence of states
and controls taking values in X âŠ†Rn and U âŠ†Rm re-
spectively. Moreover, f : XÃ—U â†’Rn is a known nominal
system model, Ïˆ : XÃ—U â†’Rd is a known vector of basis
functions, Î¸âˆ—âˆˆRdÃ—n is the true unknown system pa-
rameter, and x0 âˆˆX is the initial state. For convenience,
we also define g(x, u, w) := f(x, u) + Î¸âŠ¤
âˆ—Ïˆ(x, u) + w,
and we only consider g with the codomain X to ensure
solutions are well-defined for all time.
Our adaptive control framework for stabilising (1) is
summarised in Algorithm 1.
Algorithm 1 Adaptive Control Framework
Hello
Inputs: f, Ïˆ, Î±, Âµs, Ï‘0 âˆˆRdÃ—n, Î³ > 0
Measure X(0)
for t = 0, 1, . . . do
Compute estimate Ë†Î¸(t âˆ’1) following (3)
Sample S(t)
i.i.d.
âˆ¼Âµs
Compute control U(t) following (2)
Apply U(t) to (1)
Measure state X(t + 1) from (1)
end for
We now describe our framework in further detail. The
control sequence is generated via
U(t) = Î±(X(t), S(t), Ë†Î¸(t âˆ’1)), t âˆˆN0.
(2)
where Î± : X Ã— S Ã— RdÃ—n â†’U is a known control pol-
icy that designs that control input U(t) according to the
state X(t), an injected noise term S(t), and a parameter
estimate Ë†Î¸(t âˆ’1). Intuitively, we can view Î± as a policy
we could apply to stabilise the system when the true pa-
rameter Î¸âˆ—is used instead of a parameter estimate. In
this sense, we can view strategies following the frame-
work outlined in Algorithm 1 as a certainty equivalence
3

adaptive control law. This will be formalised in Section 3.
The random sequence of exploratory noise {S(t)}tâˆˆN is
sampled i.i.d. from a distribution Âµs with the support
S âŠ†Rq, and is injected to help facilitate convergence of
the estimate Ë†Î¸(t). The sequence of parameter estimates
{Ë†Î¸(t)}tâˆˆN taking values in RdÃ—n are obtained via regu-
larised least squares (RLS) estimation:
Ë†Î¸(t) =
ï£±
ï£´
ï£²
ï£´
ï£³
Ï‘0, t âˆˆ{âˆ’1, 0},
arg minÎ¸âˆˆRdÃ—n Pt
s=1
X(s)âˆ’Î¸âŠ¤Z(s)
âˆ’f(X(s âˆ’1), U(s âˆ’1))
2 + Î³|Î¸|2
F , t âˆˆN,
(3)
where {Z(t)}tâˆˆN is sequence of regressors taking values
in Rd and satisfying Z(t) = Ïˆ(X(tâˆ’1), U(tâˆ’1)). More-
over, Î³ > 0 is a user-chosen regularisation parameter,
and Ï‘0 âˆˆRdÃ—n is an initial deterministic parameter es-
timate. Note that the RLS estimates also satisfy
Ë†Î¸(t) = G(t)âˆ’1
t
X
s=1
Z(s) (X(s) âˆ’f(X(s âˆ’1), U(s âˆ’1)))âŠ¤
for t âˆˆN, where G(t) = Pt
i=1 Z(i)Z(i)âŠ¤+ Î³I is known
as the regularised Gramian.
Note
that
{X(t)}tâˆˆN0,
{U(t)}tâˆˆN0,
{Z(t)}tâˆˆN
and
{Ë†Î¸(t)}tâˆˆN are defined via construction through (1)-(2),
and depend on the noise sequences {W(t)}tâˆˆN and
{S(t)}tâˆˆN0. Since the former are sequences of mappings
from â„¦to X, U and RnÃ—d respectively, they can infor-
mally be viewed as random sequences. However it is
unclear from our description so far whether they for-
mally satisfy the required definition, and hence whether
all stochastic properties of interest are well-defined. We
address this concern in Section 2.2 by imposing assump-
tions that ensure such requirements are satisfied.
2.2
Standing Assumptions
Firstly, we make the following regularity assumption on
f, Ïˆ and Î±. It helps ensure that all stochastic properties
of interest for our system are well-defined.
Assumption 1 (Measurability of system mappings)
The nominal system model f, basis functions Ïˆ, and
policy Î±, are all Borel measurable.
Next, we recall the definition of sub-Gaussian random
variables, which are random variables whose distribu-
tions have tails that decay at least as fast as the Gaus-
sian distribution.
Definition 1 (sub-Gaussian random variable) Given a
sub sigma-field G âŠ†F and scalar random variable X,
we say X | G is Ïƒ2
x-sub-Gaussian if for all Î» âˆˆR,
E[exp(Î»X) | G] â‰¤exp(Î»2Ïƒ2
x/2) 1 . If X is an Rd-valued
random vector, we say X | G is Ïƒ2
x-sub-Gaussian if Î¶âŠ¤X |
G is Ïƒ2
x-sub-Gaussian for all Î¶ âˆˆSdâˆ’1. For both cases,
we say X is Ïƒ2
x-sub-Gaussian when G is chosen as the
trivial sigma-field {âˆ…, â„¦}.
We make the following assumption on {W(t)}tâˆˆN over
the probability space. It is related to independence, and
ensures the tails of its distribution decays sufficiently
fast for parameter estimation.
Assumption 2 (Independent and sub-Gaussian process
noise)
(1) The process noise sequence {W(t)}tâˆˆN is i.i.d. with
distribution denoted by Âµw.
(2) The sequences {W(t)}tâˆˆN and {S(t)}tâˆˆN0 are mu-
tually independent.
(3) W(t) is zero-mean Ïƒ2
w-sub-Gaussian for any t âˆˆN,
i.e. E[exp(Î³Î¶âŠ¤W(t))] â‰¤exp(Î³2Ïƒ2
w/2) for any Î³ âˆˆR
and Î¶ âˆˆSnâˆ’1.
Let Ï•(t, Î¾, {u(i)}tâˆ’1
i=0, {w(i)}t
i=1) denote the determinis-
tic state solution at time t âˆˆN0 to the problem described
in (1) given the initial state Î¾ âˆˆX, deterministic control
input sequence {u(i)}tâˆ’1
i=0 âˆˆUt and deterministic process
noise sequence {w(i)}t
i=1 âˆˆWt. We make the following
assumption, which bounds the reachable states of this
deterministic solution as a function of energy-like esti-
mates of the control inputs and process noise. It natu-
rally restricts the instability of the system which helps
establish the convergence of parameter estimates. , as re-
quired for estimation in [18]. The continuous-time ana-
logue of this property is equivalent to a concept called
forward completeness [3].
Assumption 3 (Sub-exponential input-to-state bound
on reachable states) There exist functions Ï‡1, Ï‡3, Ïƒ2 âˆˆ
K1-SE
âˆž
, Ï‡4 âˆˆK2-SE
âˆž
, Ï‡2, Ïƒ1 âˆˆKâˆžand a constant c1 â‰¥0
such that
Ï•(t, Î¾, {u(i)}tâˆ’1
i=0, {w(i)}t
i=1)
 â‰¤Ï‡1(t) + Ï‡2(|Î¾|)
+ Ï‡3
 tâˆ’1
X
i=0
Ïƒ1 (|u(i)|)
!
+ Ï‡4
 
t
X
i=1
Ïƒ2 (|w(i)|)
!
+ c1
for all t âˆˆN, Î¾ âˆˆX, {u(i)}tâˆ’1
i=0 âˆˆUt and {w(i)}t
i=1 âˆˆWt.
We assume the controls generated by the policy Î± sat-
isfy a magnitude constraint. Such constraints are com-
monly satisfied in strategies like model predictive con-
trol (MPC), and are natural in most real-world appli-
cations due to actuator saturation. They are useful for
1 Unless otherwise stated, inequalities involving random
variables should be interpreted surely, i.e. given two random
variables X and Y , X â‰¤Y stands for X(Ï‰) â‰¤Y (Ï‰) for all
Ï‰ âˆˆâ„¦.
4

restricting the growth of the states of the system during
instability, as required for estimation in [18].
Assumption 4 (Constrained controls) There exists
umax â‰¥0 such that for any x âˆˆX, s âˆˆS and Ï‘ âˆˆRdÃ—n,
|Î±(x, s, Ï‘)| â‰¤umax.
We assume that the magnitude of the basis functions Ïˆ
grow polynomially as a function of the states and con-
trols, which aids in bounding the regressor sequence, as
required for estimation in [18].
Assumption 5 (APB basis functions) There exists an
APB function Ï‡5 : Râ‰¥0 â†’Râ‰¥0 such that |Ïˆ(x, u)| â‰¤
Ï‡5
 [xâŠ¤yâŠ¤]âŠ¤
.
3
Main Results
We now provide the main theoretical results of this work.
In Section 3.1 we define the regional excitation and global
excitation conditions, alongside the concept of a robustly
positive invariant (RPI) set. Under the assumption that
regional excitation holds and an RPI set exists, we pro-
vide bounds on the estimaton error for a class of systems
controlled by our adaptive framework. We then define
the concept of stochastic Lyapunov functions and global
stochastic Lyapunov functions, and under the assump-
tion that the former exists, we provide probabilistic sta-
bility bounds for the adaptively controlled system. Sub-
sequently, in Section 3.2, we provide high probability
stability bounds for the system under the assumption of
global excitation and the existence of a global stochastic
Lyapunov function.
3.1
Stability and Estimation with Regional Control and
Excitation
For any Borel measurable function h : S Ã— W â†’R,
we denote E [h(S, W)] :=
R
W
R
S h(sâ€², wâ€²)dÂµs(sâ€²)dÂµw(wâ€²)
and Var(h(S, W)) :=
E
h
(h(S, W) âˆ’E [h(S, W)])2i
. They can be respectively
interpreted as the expectation and variance of h(S, W)
viewing (S, W) as random variables sampled from the
product distribution Âµs Ã— Âµw over S Ã— W Moreover,
given a predicate 2 Q : S Ã— W â†’{true, false}, we define
P(Q(S, W)) := E[1{(s,w)âˆˆSÃ—W|Q(s,w)}(S, W)] , which
can be interpreted as the probability of Q(S, W) hold-
ing. This notation will be used to emphasise that some
important objects can be constructed as a simple inte-
gral with respect to only Âµs Ã— Âµw, which is useful from
a verification standpoint, in contrast to E, Var and P.
2 Recall that a predicate is just a mapping from some objects
to the truth-values true and false. For example, given a âˆˆR,
â€œx â‰¤aâ€ is a predicate with x as the free variable, which takes
the value true if x â‰¤a holds, and false if x > a holds.
We now define regional and global excitation as follows,
which we recall from [18].
Definition 2 (Regional and global excitation) The fea-
ture map Ïˆ and controller family Î± are said to be region-
ally excited with noise distribution Âµs and Âµw over X âŠ†X
with finite constants cPE, pPE > 0 if for all Ï‘ âˆˆRdÃ—n,
x âˆˆX and Î¶ âˆˆSdâˆ’1,
P
Î¶âŠ¤Ïˆ (x + W, Î±(x + W, S, Ï‘))
2 â‰¥cPE

â‰¥pPE.
For convenience, we say (Ïˆ, Î±, Âµw, Âµs) is (X, cPE, pPE)-
regionally excited. Moreover, we say (Ïˆ, Î±, Âµw, Âµs) is
(cPE, pPE)-globally excited if (Ïˆ, Î±, Âµw, Âµs) is (X, cPE, pPE)-
regionally excited
Recall that from the perspective of LS estimation, re-
gional excitation ensures that for trajectories evolving
through X, the corresponding regressors will have a non-
degenerate distribution and will therefore be informa-
tive for estimation, by which we mean that the minimum
eigenvalue of the Gramian G(t) will be lower bounded
with high probability by a linearly growing function,
which is known as persistency of excitation (PE). Global
excitation in Definition 2 is a strengthening of regional
excitation so that it holds over the entire state space X.
In the general context of nonlinear system identification,
such a condition may be restrictive, but stronger state-
ments on the estimation error can be made when the
global excitation condition holds.
Alongside being used to establish PE, recall that regional
excitation is useful since it is a data-independent condi-
tion characterised entirely by the basis functions Ïˆ, con-
trol policy Î±, and the distribution of the process and ex-
ploratory noises Âµw, Âµs entering the system. All of these
objects are assumed to be known a priori, and therefore
regional excitation in Definition 2 can be readily checked
without knowing the entirety of the system dynamics.
There are many different ways to verify regional excita-
tion, one being to bound the first and second moments
of
Î¶âŠ¤Ïˆ (x + W, Î±(x + W, S, Ï‘))
2 from below and above
respectively, as in Lemma 1. This result is the same as
Lemma 1 from [18].
Lemma 1 Consider feature map Ïˆ and controller family
Î± satisfying Assumption 1, and noise distributions Âµw, Âµs
satisfying Assumption 2. Suppose there exists a subset
X âŠ†X and constants cPE1 > 0 and cPE2 â‰¥0 such that
for all Ï‘ âˆˆRdÃ—n, x âˆˆX and Î¶ âˆˆSdâˆ’1,
E
Î¶âŠ¤Ïˆ (x + W, Î±(x + W, S, Ï‘))

â‰¥cPE1,
Var
 Î¶âŠ¤Ïˆ (x + W, Î±(x + W, S, Ï‘))

â‰¤cPE2.
Then, (Ïˆ, Î±, Âµs, Âµw) is (X, cPE, pPE)-regionally excited
5

with
pPE := 1
4
cPE2
c2
PE1
+ 1
âˆ’1
,
cPE := 1
4c2
PE1.
Throughout this section, we assume that regional exci-
tation holds.
Assumption 6 (Ïˆ, Î±, Âµw, Âµs)
is
(XPE, cPE, pPE)-
regionally excited for some set XPE âŠ†X and constants
cPE, pPE > 0.
We define the one-step predicted reachable set map as
Î“(X) := {g(x, u, 0) | x âˆˆX, |u| â‰¤umax} , X âŠ†X.
which is the set of reachable states from X âŠ†X when
the control input magnitude is bounded by umax and the
process noise is set to zero.
Next, we define the concept of a robustly positive invari-
ant (RPI) set.
Definition 3 The set X âŠ†X is said to be a robustly
positive invariant (RPI) set with error constant Â¯Ï‘ > 0
for the system g under the influence of the policy Î± if
for all x âˆˆX, w âˆˆW, s âˆˆS, and Ï‘ âˆˆBÂ¯Ï‘(Î¸âˆ—), it holds
that g(x, Î±(x, s, Ï‘), w) âˆˆX. For convenience, we say that
(g, Î±) is (X, Â¯Ï‘, Âµw, Âµs)-RPI.
Intuitively, a set X is RPI if starting from any state x
inside X, regardless of value of the process noise w âˆˆW
and injected noise s âˆˆS, if the parameter Ï‘ used for con-
trol is sufficiently close to the true parameter Î¸âˆ—such that
|Ï‘ âˆ’Î¸âˆ—| â‰¤Â¯Ï‘, then the evolved state g(x, Î±(x, s, Ï‘), w)
remains inside X. Throughout Section 3, we assume the
existence of such a set XRPI and an associated error con-
stant Â¯Ï‘.
Assumption 7 There exists a subset XRPI
âŠ†
X
and error bound Â¯Ï‘
>
0 such that (g, Î±, Âµw, Âµs) is
(XRPI, Â¯Ï‘, Âµw, Âµs)-RPI and Î“(XRPI) âŠ†XPE.
Note that in Assumption 7, we also require that
Î“(XRPI) âŠ†XPE. This connects the RPI set XRPI to the
region of excitation XPE, allowing us to establish PE
when the state trajectory X(t) evolves inside XRPI.
Remark 1 In many adaptive control works based on ro-
bust control techniques like robust adaptive MPC, knowl-
edge of a bounded parameter set with nonempty interior
containing Î¸âˆ—is needed for controller design, such that
the robust control algorithm can render some set robustly
positive invariant accounting for all possible parameters
in the bounded set (e.g. [1,2,12,17]). This is not what is
required in this work. Even though Â¯Ï‘ is required in As-
sumption 7 for the estimation and stability results, it is
not required to implement the framework described in Al-
gorithm 1.
Before providing our main results, we introduce a few
objects required to state our result. We define the process
noise bound w : N0 Ã— (0, 1) â†’Râ‰¥0, state bound x : N Ã—
(0, 1)Ã—X â†’Râ‰¥0 and regressor bound z : NÃ—(0, 1)Ã—X â†’
Râ‰¥0 as
w(t, Î´) :=
(
Ïƒw
q
2n ln
  nÏ€2t2
3Î´

,
t âˆˆN,
0,
t = 0,
x(t, Î´, x0) := Ï‡1(t) + Ï‡2 (|x0|) + Ï‡3 (tÏƒ1 (umax)) + Ï‡4 (tÏƒ2 (w(t, Î´)))
(4)
z(t, Î´, x0) := Ï‡5
p
x(t âˆ’1, Î´, x0)2 + u2max

,
(5)
with Ï‡1-Ï‡4 and c1 from Assumption 3, and and Ï‡5 from
Assumption 5. Under Assumptions 2-5, these objects
provide high probability upper bounds on the magnitude
of {W(t)}tâˆˆN, {X(t)}tâˆˆN0 and {Z(t)}tâˆˆN respectively.
Next, we introduce objects that provide probabilistic
upper and lower semi-definite bounds on the regularised
Gramian G(t). We define the Gramian upper bound as
Î²max(t, Î´, x0) :=
t
X
i=1
z2(i, Î´, x0) + Î³,
(6)
with Î³ from (3). It is a high probability upper bound on
the maximum eigenvalue of G(t), which is established in
the proof of Theorem 1.
Next, we define the contained time bound as
Tcontained(Î´, x0) := sup

T âˆˆN | Bx(T ,Î´/3,x0)(0) âˆ©X âŠ†XRPI
	
.
Tcontained(Î´, x0) can be interpreted as a high probability
lower bound on the horizon over which the state X(t)
remains inside XRPI. Moreover, define the burn-in time
bound as
Tburn-in(Î´, x0) := inf

T âˆˆN
 t â‰¥
2
(1 âˆ’ln(2))pPE
Ã—
 
d ln
 
1 + 16 Pt
i=1 z2(i, Î´/3, x0)
cPE3pPE(t âˆ’1)
!
+ ln
Ï€2(t âˆ’T + 1)2
2Î´
!
+ 1 for all t â‰¥T

,
Intuitively, Tburn-in(Î´, x0) can be viewed as a high prob-
ability upper bound on the time it takes for PE to start
holding in the sense that cPEpPE
4
(t âˆ’1) + Î³ is a lower
bound on Î»min(G(t)), assuming that the predicted state
6

g(X(t âˆ’1), U(t âˆ’1), 0) remains inside XPE, which no-
tably occurs if X(t âˆ’1) is inside XRPI due to Assump-
tion 7.
We also define Tconverge as
Tconverge(Î´, x0) := max (Tburn-in(Î´, x0),
inf

T âˆˆN | e(t, Î´, x0) â‰¤Â¯Ï‘, âˆ€t â‰¥T
	
.
(7)
Tconverge(Î´, x0) can be interpreted as a high probability
upper bound on the time the parameter estimate Ë†Î¸(t)
converges into a Â¯Ï‘-ball around the true parameter Î¸âˆ—,
assuming that the predicted state g(X(tâˆ’1), U(tâˆ’1), 0)
remains inside XPE.
We are now ready to state Theorem 1, which provides
probabilistic guarantees on the estimation error |Ë†Î¸tâˆ’Î¸âˆ—|,
and the invariance of the state Xt within the set XRPI,
uniformly over all time.
Theorem 1 (Regional estimation error bound and pos-
itive invariance guarantee) Suppose Assumptions 1, 2, 3,
4, 5, 6 and 7 are satisfied. Then, for any x0 âˆˆXRPI and
Î´ âˆˆ(0, 1), if
Tconverge(Î´, x0) + 1 â‰¤Tcontained(Î´, x0),
(8)
then
P
Ë†Î¸(t) âˆ’Î¸âˆ—
 â‰¤e(t, Î´, x0), âˆ€t â‰¥Tburn-in(Î´, x0)
and X(t) âˆˆXRPI, âˆ€t â‰¥0

â‰¥1 âˆ’Î´,
(9)
where the error bound e(t, Î´, x0) is defined as
e(t, Î´, x0) :=
1
p cPEpPE
4
(t âˆ’1) + Î³

Î³1/2|Î¸âˆ—|F +
(10)
Ïƒw
p
2n(ln(3n/Î´) + (d/2) ln(Î²max(t, Î´/3, x0)Î³âˆ’1))

and Î²max is defined in (6). Moreover, for any x0 âˆˆXRPI
and Î´ âˆˆ(0, 1),
(1) limtâ†’âˆže(t, Î´, x0) = 0;
(2) Tburn-in(Î´, x0) < âˆž;
(3) Tconverge(Î´, x0) < âˆž.
Theorem 1 provides 1) an upper bound e(t, Î´, x0) on the
estimation error
Ë†Î¸(t) âˆ’Î¸âˆ—
 that holds uniformly over all
t â‰¥Tburn-in(Î´, x0), and 2) a guarantee of the invariance
of X(t) inside XRPI for all t âˆˆN0, that are satisfied
with probability 1 âˆ’Î´. These guarantees hold whenever
condition (8) is satisfied, for any Î´ âˆˆ(0, 1) and x0 âˆˆX.
Condition (8) ensures that with high probability, the
estimate Ë†Î¸(t âˆ’1) will converge into a Â¯Ï‘-ball around Î¸âˆ—
before X(t) escapes XRPI. Then, since Î“(XRPI) âŠ†XPE,
by making use of Assumption 7 which guarantees RPI
when the estimation error is smaller than Â¯Ï‘, it can be
inductively established for subsequent time steps that
PE holds, ensuring the estimation error remains smaller
than Â¯Ï‘, so the state remains inside XRPI, and so on,
producing the invariance portion of the statement in (9).
Simultaneously, the error bound portion of (9) holds
for infinite time since the state trajectory is guaranteed
to remain inside XRPI with high probability, ensuring
PE holds (see Remark 2 for a more detailed discussion).
We also observe that the error bound is asymptotically
convergent to zero in the sense that e(t, Î´, x0) â†’âˆžas
t â†’âˆž, which is particularly insightful because it means
that with probability at least 1 âˆ’Î´, the the parameter
estimate Ë†Î¸(t) will eventually enter and remain inside any
arbitrarily small ball around Î¸âˆ—.
Remark 2 Theorem 1 bears similarities with Theorem 1
from [18]. The formula for the error bound e(t, Î´, x0) on
the estimation error |Ë†Î¸(t) âˆ’Î¸âˆ—| is the same in both re-
sults, which means that the bound in this work is sim-
ilarly smaller in systems experiencing a large degree of
excitation and less instability. Moreover, both guarantees
require some kind of condition to be verified for a given Î´
and x0. The key difference between the two is that the er-
ror bound in Theorem 1 holds for infinite time, whereas
the one in [18] holds only over a finite interval. This oc-
curs because in Theorem 1, the RPI property of the con-
trolled system in Assumption 7 combined with condition
(8) ensures the system remains inside XRPI for all time,
which guarantees PE holds over an infinite time interval.
On the other hand, there is no RPI assumption in Theo-
rem 1 from [18], such that we are unable to characterise
a probabilistic event where the state trajectory is remains
inside a region guaranteeing PE for all time. Instead,
Theorem 1 from [18] involves verifying a condition that
enables the construction of a probabilistic event where
the lower bound cPEpPE
4
(t âˆ’1) + Î³ on Î»min(G(t)) starts
holding before X(t) escapes the exciting region, allowing
us to derive an error bound over a finite time interval.
Just like Theorem 1 from [18], (8) is verifiable of-
fline, meaning that it does not rely on any online
data
collection.
Moreover,
although
Tconverge(Î´, x0)
(and Tburn-in(Î´, x0)) are finite for any Î´ âˆˆ(0, 1) and
x0 âˆˆXRPI, without choosing a particular system, we
cannot say whether or not the condition will be satis-
fied. However, qualitatively, it is more likely to hold in
systems with a greater degree of excitation, and with
less instability. This is because Tburn-in(Î´, x0) is smaller
and e(t, Î´, x0) decays faster when z(t, Î´/3, x0) grows
slowly, and cPE and pPE are larger, resulting in a smaller
value for Tconverge(Î´, x0). Moreover, Tcontained(Î´/3, x0)
is larger when z(t, Î´/3, x0) grows slowly. On the other
hand, it may not hold in systems with a smaller RPI set,
small degree of excitation, and greater instability. Of
particular note is that Tconverge(Î´, x0) is smaller when
7

Â¯Ï‘ is larger, and Tcontained(Î´, x0) is larger when XRPI is
larger. However, Â¯Ï‘ and XRPI are intrinsically linked,
and a tradeoff between them is likely to exist in specific
problems.
We now progress towards stating our main stability re-
sult with regional control and excitation. Before doing
so, we introduce some concepts. Given a Borel measur-
able function V : X â†’Râ‰¥0 with X âŠ†X, we define
âˆ†V (x, ËœÏ‘) := E[V (g(x, W, Î±(x, S, ËœÏ‘ + Î¸âˆ—)] âˆ’V (x)(11)
for x âˆˆX, ËœÏ‘ âˆˆRdÃ—n. Note that ËœÏ‘ in (11) does not
represent the parameter estimate, but the estimation
error.
Next, we introduce the notion of a stochastic Lyapunov
function.
Definition 4 (Stochastic
Lyapunov
function)
The
Borel measurable function V : XRPI â†’Râ‰¥0 over the
domain XRPI âŠ†X is said to be a stochastic Lyapunov
function with the estimation error bound Â¯Ï‘, for the sys-
tem g under the influence of the policy Î± and the noise
distributions Âµw, Âµs, if 1) (g, Î±) is (XRPI, Â¯Ï‘, Âµw, Âµs)-
RPI, and 2) there exist Î±1, Î±2, Î±3 âˆˆKâˆž, Ïƒ3 âˆˆK, and
Ëœd â‰¥0, such that
Î±1(|x|) â‰¤V (x) â‰¤Î±2(|x|),
âˆ†V (x, ËœÏ‘) â‰¤âˆ’Î±3(|x|) + Ëœd + Ïƒ3(|ËœÏ‘|),
(12)
are satisfied for all x âˆˆXRPI, and ËœÏ‘ âˆˆB Â¯Ï‘(0), and Î±3â—¦Î±âˆ’1
2
is lower bounded by some convex function in Kâˆž. For con-
venience, we say (g, Î±, Âµw, Âµs) is (V, XRPI, Â¯Ï‘)-stochastic
Lyapunov. If (g, Î±, Âµw, Âµs) is (V, X, Â¯Ï‘)-stochastic Lya-
punov, we say that (g, Î±, Âµw, Âµs) is (V, Â¯Ï‘)-global stochas-
tic Lyapunov.
Intuitively, the existence of the stochastic Lyapunov
function in Definition 4 implies that if the parameter Ï‘
used for control is sufficiently close to the true parame-
ter Î¸âˆ—such that |ËœÏ‘| = |Ï‘ âˆ’Î¸âˆ—| â‰¤Â¯Ï‘, then from any initial
state x inside an RPI set XRPI, we expect the closed-loop
trajectory to decrease in magnitude, up to some value
that monotonically depends on Ëœd and |ËœÏ‘|. On the other
hand, a global stochastic Lyapunov function means that
from any state x over the entire state space X, this
decreasing property is expected. The definition of the
stochastic Lyapunov function in Definition 4 is similar
to existing definitions for stochastic Lyapunov functions
in nonlinear stochastic stability theory, in particular
the stochastic input-to-state Lyapunov function from
[15]. The main difference is that the dissipation inequal-
ity (12) includes an additional determinisitc additive
component Ïƒ3(|ËœÏ‘|) representing the influence of the esti-
mation error. Another key difference is the requirement
that Î±3 â—¦Î±âˆ’1
2
is lower bounded by some convex function
in Kâˆž, which is trivially satisfied when XRPI is bounded
as in [15]. We assume the existence of a stochastic
Lyapunov function for the remainder of this section.
Assumption 8 There exist a Borel measurable function
V : XRPI â†’Râ‰¥0 over XRPI âŠ†X satisfying Î“(XRPI) âŠ†
XPE, and a constant Â¯Ï‘ > 0, such that (g, Î±, Âµw, Âµs) is
(V, XRPI, Â¯Ï‘)-stochastic Lyapunov.
We now our main stability result in this section.
Theorem 2 (Probabilistic
regional
stability
bound)
Suppose Assumptions 1, 2, 3, 4, 5, 6, and 8 are satisfied.
Then, for all Î´ âˆˆ(0, 1), there exists c2 â‰¥0 such that for
any initial state x0 âˆˆXRPI, if (Î´, x0) satisfy
Tconverge(Î´/2, x0) + 1 â‰¤Tcontained(Î´/2, x0),
(13)
then there exists Î· âˆˆL such that
P(|X(t)| â‰¤Î·(t) + c2) â‰¥1 âˆ’Î´
(14)
for all t âˆˆN0.
Theorem 2 says that, for any chosen failure probability
Î´ âˆˆ(0, 1), there is some constant c2 â‰¥0 such that for
any initial state x0 âˆˆXRPI, if Î´ and x0 satisfy condition
(13), there exists some function Î· âˆˆL such that magni-
tude of X(t) will be less than Î·(t) + c2 with probability
at least 1 âˆ’Î´. We can interpret this magnitude bound
as a stability bound since it exhibits the properties of
both boundedness and convergence â€” boundedness in
the sense that it is bounded from above by Î·(0) + c2
over all time (with Î·(0) dependent on x0), and conver-
gent in the sense that it converges to c2 regardless of x0.
Intuitively, we can view Î·(t) as a transient component,
and c2 as a steady-state component. This result requires
condition (13) to hold since it is essentially established
by relying on the convergence of the estimate Ë†Î¸(t) into
a Â¯Ï‘-ball around Î¸âˆ—, then using the existence of a Lya-
punov function when the estimation error is sufficiently
small in Assumption 8 to derive the stability bound. We
require (13) rather than (8) due to the use of the union
bound in the derivation of Theorem 2.
Remark 3 Although Theorem 2 only talks about the ex-
istence of transient component Î· and steady-state com-
ponent c2, they can be explicitly constructed. Given Î´ âˆˆ
(0, 1), c2 can be constructed via
c2 = Î±âˆ’1
1
â—¦2
Î´ ËœÎ³(2 Ëœd)
(15)
where Î±1 âˆˆKâˆžand Ëœd are part of Definition 4, and ËœÎ³ âˆˆ
Kâˆžis constructed as
ËœÎ³(r) := 2 max(Î±âˆ’1
v (r), r).
8

Here, Î±v is any convex function in Kâˆžthat lower bounds
Î±3 â—¦Î±âˆ’1
2 , whose existence is required in Definition 4. On
the other hand, given x0 âˆˆXRPI and Î´ âˆˆ(0, 1), Î· can be
constructed via
Î·(t) := max
tâ€²â‰¥t ËœÎ·(tâ€²)
(16)
where ËœÎ· is x0- and Î´-dependent and in turn constructed
via (17). In turn, it relies on
Î»1(r) = r âˆ’Î±v(r) + Î±v(r/2),
Î»(r) = 1
2(r + max
râ€²âˆˆ[0,1] Î»1(râ€²)),
Î²1(r, t) = Î±âˆ’1
1
â—¦2
Î´ Î»t â—¦Î±2(r),
Î²2(r, t) = Î±âˆ’1
1
â—¦2
Î´ Î»t0+âŒˆt/2âŒ‰â—¦ËœÎ³(2Ïƒ3(r)),
Î·2(t) = Î±âˆ’1
1
â—¦2
Î´ Î»t0+âŒˆt/2âŒ‰â—¦ËœÎ³(2 Ëœd),
Î³3(r) = Î±âˆ’1
1
â—¦2
Î´ ËœÎ³(2Ïƒ3(r)).
Here, Î±1, Î±2, Î±3 âˆˆKâˆžand Ïƒ3 âˆˆK are all from Defini-
tion 4, x is from (4), and e is from (9). Note that the
steady-state component c2 does not depend on the esti-
mation error bound e(t, Î´/2, x0), only on Ëœd. Instead, this
information is captured entirely in the transient compo-
nent Î·(t).
ËœÎ·(t) =
ï£±
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£²
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£³
x(Tconverge(Î´/2, x0) + 1, Î´/6, x0),
0 â‰¤t â‰¤Tconverge(Î´/2, x0),
max

Î²1 (x (Tconverge (Î´/2, x0) + 1, Î´/6, x0) , t âˆ’(Tconverge (Î´/2, x0) + 1)) ,
Î·2 (t âˆ’(Tconverge (Î´/2, x0) + 1))
+Î²2(maxTconverge(Î´/2,x0)â‰¤iâ‰¤Tconverge(Î´/2,x0)+âŒŠ(tâˆ’(Tconverge(Î´/2,x0)+1))/2âŒ‹e (i, Î´/2, x0) ,
t âˆ’(Tconverge(Î´/2, x0) + 1)),
Î³3
 maxTconverge(Î´/2,x0)+1+âŒŠ(tâˆ’(Tconverge(Î´/2,x0)+1))/2âŒ‹â‰¤iâ‰¤tâˆ’1 e (i, Î´/2, x0)
 
,
t â‰¥Tconverge(Î´/2, x0) + 1,
(17)
3.2
Stability with Global Control and Excitation
We now assume global excitation and the existence of
a global stochastic Lyapunov function, and establish
Corollary 1 under these assumptions.
Assumption 9 (Ïˆ, Î±, Âµw, Âµs) is (cPE, pPE)-globally ex-
cited for some constants cPE, pPE > 0.
Assumption 10 There exist a Borel measurable func-
tion V : X â†’Râ‰¥0, and a constant Â¯Ï‘ > 0 such that
(g, Î±, Âµw, Âµs) is (V, Â¯Ï‘)-global stochastic Lyapunov.
Corollary 1 (High probability global stability bound)
Suppose Assumptions 1, 2, 3, 4, 5, 9, and 10 are sat-
isfied. Then, for all Î´ âˆˆ(0, 1), there exists c2 â‰¥0 such
that for all x0 âˆˆX, there exists Î· âˆˆL such that
P(|X(t)| â‰¤Î·(t) + c2) â‰¥1 âˆ’Î´.
(18)
for all t âˆˆN0.
Corollary 1 is similar to Theorem 2, but considers the
specific case where global excitation holds and a global
stochastic Lyapunov function exists. The key difference
between the two is that under these strengthened as-
sumptions, condition (8) no longer needs to be manu-
ally verified, such that the statement in (18) can be es-
tablished for any x0 and Î´, resulting in a high probabil-
ity stability bound. The reason for this is explained in
Remark 4. Moreover, the transient component Î·(t) and
steady-state component c2 of the bound in (18) can also
be constructed via (15) and (16) from Remark 3.
Remark 4 Corollary 1 follows from Theorem 2 since
under Assumptions 9 and 10, Assumption 6 holds with
XPE = X and Assumption 8 holds with XRPI = X, and
moreover Tcontained(Î´, x0) = âˆž, such that condition (8)
is automatically verified.
4
Examples
In Example 1, we consider a piecewise affine (PWA) sys-
tem with unknown parameters that is only regionally
controllable and excited. We propose an adaptive con-
trol strategy based on the framework in Algorithm 1,
and subsequently show that the assumptions required
to establish Theorems 1 and 2 both hold. This provides
probabilistic guarantees on the positive invariance of the
system on the excited and controllable region, alongside
non-asymptotic bounds on the estimation error and sta-
bility bounds.
In Example 2, we propose an adaptive control strat-
9

egy for input-constrained stochastic linear systems based
on the framework described in Algorithm 1, and subse-
quently show how Corollary 1 can be used to establish
high probability stability guarantees for the closed-loop
system.
4.1
Example 1: Piecewise-Affine System
We consider stochastic systems of the form
X(t + 1) = X(t) + 0.11{|X(t)|â‰¤Â¯x}U(t) + W(t), t âˆˆN,
X(0) = x0 âˆˆR, (19)
where {X(t)}tâˆˆN0, {U(t)}tâˆˆN0 and {W(t)}tâˆˆN are ran-
dom sequences taking values in R, and x0 is the initial
state. Here, Â¯x > 0 determines region where (19) is con-
trollable. We assume {W(t)}tâˆˆN is sampled i.i.d. from
Uniform(âˆ’Â¯w, Â¯w) with Â¯w > 0. The nominal system f,
true unknown parameter Î¸âˆ—and basis function Ïˆ in (1)
then correspond to
f(x, u) = 0,
Î¸âˆ—=
"
1
0.1
#
,
Ïˆ(x, u) =
"
x
1{Ëœx||Ëœx|â‰¤Â¯x}u
#
,
and Âµw is the probability measure associated with
Uniform(âˆ’Â¯w, Â¯w), such that W = [âˆ’Â¯w, Â¯w].
We now describe the adaptive control strategy based on
the framework in Algorithm 1. Before doing so, given
r > 0 and x âˆˆRn, let us define the radial saturation
function as satr(x) := x if |x| â‰¤r and satr(x) =
x
|x|r
if |x| â‰¤r, and let M â€  denote the pseudo-inverse of the
matrix M. Now, let Â¯u1, Â¯u2 > 0 be constants, and let
Â¯umax = Â¯u1 + Â¯u2. Moreover, let Âµs be the probability
measure associated with Uniform(âˆ’Â¯s, Â¯s) where Â¯s > 0,
such that S = [âˆ’Â¯s, Â¯s]. The family of control policies Î±
chosen for our framework is then given by
Î±(x, s, Ï‘) := satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘1x) + s
for s âˆˆS and Ï‘ =
h
Ï‘1 Ï‘2
iâŠ¤
âˆˆR2.
Next, we verify the assumptions required to establish
Theorems 1 and 2. In order to do so, we assume that the
objects in the problem setup satisfy the following:
Â¯x â‰¥Â¯w + 0.1(umax + Â¯u1),
(20)
0.1Â¯u1 > 0.1Â¯s + Â¯w.
(21)
We start by verifying Assumption 1. We know f(x, u) =
0 is Borel measurable since constants are Borel measur-
able, Ïˆ(x, u) =
h
x 1{Ëœx||Ëœx|â‰¤Â¯x}(x)u
iâŠ¤
is Borel measurable
since the indicator function of a Borel measurable set is
also Borel measurable, and Borel measurability is pre-
served under multiplication and coordinate functions.
Moreover, Î±(x, s, Ï‘) = satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘1x) + s is Borel mea-
surable since satÂ¯u1(Â·) and the pseudo-inverse (Â·)â€  of a
matrix are Borel measurable, and Borel measurability is
preserved under multiplication, addition, and composi-
tion (see [10] for these standard results).
Next, Assumption 2 holds since {W(t)}tâˆˆN is i.i.d.,
{W(t)}tâˆˆN and {S(t)}tâˆˆN0 are mutually independent,
and W(t) is zero-mean and Â¯w2-sub-Gaussian for all
t âˆˆN (since it has a bounded support).
We now verify Assumption 3. Firstly, note that for any
initial state Î¾ âˆˆX, time t âˆˆN0, and deterministic input
and noise sequences {u(i)}Ï„âˆ’1
i=0 âˆˆUt and {w(i)}t
i=1 âˆˆ
Wt, the deterministic trajectory Ï• corresponding to the
system (19) satisfies
Ï•(t, Î¾, {u(i)}tâˆ’1
i=0, {w(i)}t
i=1)

â‰¤|Î¾| + 0.1
 tâˆ’1
X
i=0
|u(i)|
!
+
t
X
i=1
|w(i)|
Thus, Assumption 3 is satisfied with Ï‡2(Â·) = Id(Â·),
Ï‡3(Â·) = 0.1Id(Â·), Ï‡4(Â·) = Ïƒ1(Â·) = Ïƒ2(Â·) = Id(Â·), and with
arbitrary Ï‡1 âˆˆK1-SE
âˆž
.
Next, Assumption 4 holds since for all x âˆˆX, s âˆˆS and
Ï‘ âˆˆR,
|Î±(x, s, Ï‘)| â‰¤|satÂ¯u1(âˆ’Ï‘â€ x) + s| â‰¤Â¯u1 + Â¯u2 = umax.
Note that Assumption 5 is satisfied with Ï‡4(Â·) = Id(Â·),
since
|Ïˆ(x, u)| = |1{Ëœx||Ëœx|â‰¤Â¯x}(x)u| â‰¤|u|.
We now verify Assumption 6. The steps we take
bear similarities to Example 1 from [18], where re-
gional excitation was also established by making use
of Lemma 1. There are some minor differences, pri-
marily due to the assumption that the process noise
distribution is bounded, and that the control inputs
applied do not consist solely of injected noise, but also
included a component computed from past data. This
required us to make use of some steps inspired by Ex-
ample 2 in [18], which also included such a component.
Let XPE := [âˆ’(Â¯x âˆ’Â¯w), Â¯x âˆ’Â¯w]. Suppose x âˆˆXPE,
Ï‘ =
h
Ï‘1 Ï‘2
iâŠ¤
âˆˆR2, and Î¶ âˆˆS1. Then,
E
Î¶âŠ¤Ïˆ(x + W, Î±(x + W, S, Ï‘)

= E
Î¶1(x + W) + Î¶21{Ëœx||Ëœx|â‰¤Â¯x}(x + W)
Â·(satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)

i
10

= E
hÎ¶1(x + W) + Î¶2(satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)

i
(22)
Moreover,
E
hÎ¶1(x + W) + Î¶2(satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)

i
= E[E[|Î¶1(x + W)
+Î¶2(satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)
 | S
ii
(23)
â‰¥E
hE
h
Î¶1(x + W)
+Î¶2(satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S) | S
i
i
= E
hÎ¶1x + Î¶2E
h
satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W))
i
+ Î¶2S

i
(24)
â‰¥|Î¶2|E[|S|] = |Î¶2| Â¯u2
2
(25)
where (23) follows from the tower property, (24) follows
from the independence of W and S, and (25) follows from
the optimality property of medians and E[|S|] =
Â¯u2
2 .
Similarly, we have
E
hÎ¶1(x + W) + Î¶2(satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)

i
= E
h
E
hÎ¶1(x + W)
+Î¶2(satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)
 | W
ii
(26)
â‰¥E
hE
h
Î¶1(x + W)+
Î¶2(satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S) | W
i
i
= E
hÎ¶1(x + W) + Î¶2satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W))

i
(27)
â‰¥|Î¶1|E[|(x + W)|]
âˆ’|Î¶2|E
hsatÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W))

i
(28)
â‰¥|Î¶1|E[|W|] âˆ’|Î¶2|u1
(29)
= |Î¶1| Â¯w
2 âˆ’|Î¶2|u1
(30)
where (26) follows from the tower property, (27) follows
from the independence of W and S, (28) follows from the
reverse triangle inequality, (29) follows from the optimal-
ity property of medians and the fact that satÂ¯u1 is upper
bounded by u1, and (30) follows from E[|W|] = Â¯
w
2 . Note
that if |Î¶2| â‰¤
Â¯
w
4Â¯u1+2 Â¯
w, then |Î¶1| â‰¥1 âˆ’
Â¯
w
4Â¯u1+2 Â¯
w, and so
|Î¶1| Â¯
w
2 âˆ’|Î¶2|u1 â‰¥

1 âˆ’
Â¯
w
4Â¯u1+2 Â¯
w

Â¯
w
2 âˆ’
Â¯
wÂ¯u1
4Â¯u1+2 Â¯
w =
Â¯
w
4 . More-
over, if |Î¶2| >
Â¯
w
4Â¯u1+2 Â¯
w, then |Î¶2| u2
2 >
Â¯
wÂ¯u2
8Â¯u1+4 Â¯
w. Combining
this with (22), (25) and (30), we have
E
Î¶âŠ¤Ïˆ(x + W, Î±(x + W, S, Ï‘)

â‰¥max

|Î¶2|u2
2 , |Î¶1| Â¯w
2 âˆ’|Î¶2|u1

â‰¥min
 Â¯w
4 ,
Â¯wÂ¯u2
8Â¯u1 + 4 Â¯w

=: cPE1.
On the other hand, we have
Var
Î¶âŠ¤Ïˆ(x + W, satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘1(x + W)) + S)


= Var
Î¶1(x + W) + Î¶21{Ëœx||Ëœx|â‰¤Â¯x}(x + W)
Â·(satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘1(x + W)) + S)


= Var
Î¶1(x + W) + Î¶2(satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘1(x + W)) + S)


= E
h
Î¶1W + Î¶2S + Î¶2

satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘1(x + W))
âˆ’E
h
satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘1(x + W))
i2
â‰¤3

E
h
(Î¶1W)2i
+ E
h
(Î¶2S)2i
+ E
h
Î¶2

satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘1(x + W))
âˆ’E
h
satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘1(x + W))
i2
(31)
â‰¤3 max
 Â¯w2
3 , u2
2
3 + 4u2
1

(32)
where (31) follows from the QM-AM inequality, and
(32) follows from E

W 2
â‰¤
Â¯
w2
3 , E

S2
â‰¤
u2
2
3
and
E
h
(Î¶2(Î±2(x + W, Ï‘) âˆ’E[Î±2(x + W, Ï‘)]))2i
â‰¤
4Â¯u2
1.
Thus, using Lemma 1 we find that (Ïˆ, Î±, Âµs, Âµw) is
(XPE, cPE, pPE)-regionally excited with cPE :=
1
4c2
PE1
and pPE := 1
4

cPE2
c2
PE1 + 1
âˆ’1
, such that Assumption 6 is
satisfied.
Next, we verify that Assumption 7 holds. Before doing
so, we note the following lemma holds (as a trivial con-
sequence of Lemma 1 from [20].
Lemma 2 Consider A âˆˆRnÃ—n and B âˆˆRnÃ—m with
n, m âˆˆN. Suppose A is full rank, |A| â‰¤1 and (A, B) is
Îº-step reachable, that is rank(RÎº(A, B)) = n for some
Îº âˆˆN. Let Â¯u > 0 be a constant. Then, there exist m, C >
0 such that for any x âˆˆRn and Ë†Ï‘ =
h
Ë†Ï‘1 Ë†Ï‘2
iâŠ¤
âˆˆÂ¯Bm(Î¸âˆ—),
satÂ¯u(Ë†Ï‘â€ 
2 Ë†Ï‘1x) âˆ’satÂ¯u(RÎº(A, B)â€ AÎºx)
 â‰¤C
Ë†Ï‘ âˆ’Ï‘âˆ—
.
Now, let XRPI := [âˆ’(Â¯xâˆ’Â¯w âˆ’0.1umax), Â¯xâˆ’Â¯w âˆ’0.1umax].
Moreover, let Â¯Ï‘, C > 0 be such that 0.1Â¯u1 â‰¥0.1(C Â¯Ï‘ +
Â¯s) + Â¯w, whose existence is verified via the assumption
11

in (21) and Lemma 2. Then, note that Î“(XRPI) âŠ†XPE.
Furthermore, for all x âˆˆXRPI, u âˆˆU, s âˆˆS and Ë†Ï‘ =
h
Ë†Ï‘1 Ë†Ï‘2
iâŠ¤
âˆˆÂ¯B Â¯Ï‘(Î¸âˆ—), we have
|g(x, Î±(x, s, Ë†Ï‘â€ 
2 Ë†Ï‘1), w)|
= |x + 0.11{Ëœx||Ëœx|â‰¤Â¯x}(x) Â· (satÂ¯u1(âˆ’Ë†Ï‘â€ 
2 Ë†Ï‘1x) + s) + w|
= |x + 0.1(satÂ¯u1(âˆ’Ë†Ï‘â€ 
2 Ë†Ï‘1x) + s) + w|
= |x + 0.1satÂ¯u1(âˆ’10x)
+ 0.1(s + satÂ¯u1(âˆ’Ë†Ï‘â€ 
2 Ë†Ï‘1x) âˆ’satÂ¯u1(âˆ’10x)) + w|
â‰¤|x + 0.1satÂ¯u1(âˆ’10x)|
+ |0.1(s + satÂ¯u1(âˆ’Ë†Ï‘â€ 
2 Ë†Ï‘1x) âˆ’satÂ¯u1(âˆ’10x)) + w|
â‰¤|x + 0.1satÂ¯u1(âˆ’10x)| + 0.1(C Â¯Ï‘ + Â¯s) + Â¯w
â‰¤Â¯x âˆ’Â¯w âˆ’0.1umax,
where the final inequality follows from the fact that mak-
ing use of (20) and (21), we know that if |x| â‰¤0.1Â¯u1
and |x| â‰¤Â¯x âˆ’Â¯w âˆ’0.1umax, then |x + 0.1satÂ¯u1(âˆ’10x)| +
0.1(C Â¯Ï‘ + Â¯s) + Â¯w = 0.1(C Â¯Ï‘ + Â¯s) + Â¯w â‰¤0.1Â¯u1 â‰¤Â¯x âˆ’Â¯w âˆ’
0.1umax, and if |x| > 0.1Â¯u1 and |x| â‰¤Â¯x âˆ’Â¯w âˆ’0.1umax,
we have |x + 0.1satÂ¯u1(âˆ’10x)| + 0.1(C Â¯Ï‘ + Â¯s) + Â¯w = |x| âˆ’
0.1Â¯u1 + 0.1(C Â¯Ï‘ + Â¯s) + Â¯w â‰¤|x| â‰¤Â¯x âˆ’Â¯w âˆ’0.1umax. This
implies g(x, Î±(x, s, Ë†Ï‘), w) âˆˆXRPI. Therefore, we have
established that (g, Î±, Âµw, Âµs) is (XRPI, Â¯Ï‘, Âµw, Âµs)-RPI.
We now verify that Assumption 8 holds. Firstly,
note that we already established that (g, Î±, Âµw, Âµs) is
(XRPI, Â¯Ï‘, Âµw, Âµs)-RPI. Since we assumed (21), it triv-
ially follows that
h := ln(E[exp(0.1|S|)]) + ln(E[exp(|W|)]) < 0.1Â¯u1.(33)
Following similar steps to the proof of Lemma 2 from
[20], we find that for all x âˆˆXRPI and Ë†Ï‘ =
h
Ë†Ï‘1 Ë†Ï‘2
iâŠ¤
âˆˆ
Â¯B Â¯Ï‘(Î¸âˆ—),
E
h
exp

|x + 0.11{Ëœx||Ëœx|â‰¤Â¯x}(x)
Â·

âˆ’satÂ¯u1

Ë†Ï‘â€ 
2 Ë†Ï‘1x

+ S

+ W|

âˆ’1
i
= E
h
exp

|x + 0.1

âˆ’satÂ¯u1

Ë†Ï‘â€ 
2 Ë†Ï‘1x

+ S

+ W|

âˆ’1
i
â‰¤max

exp

h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


,
exp

|x| âˆ’0.1Â¯u1 + h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1
= max

exp

h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1,
exp(|x|) exp

âˆ’0.1Â¯u1 + h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1

â‰¤max

exp

h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1, (exp(|x|) âˆ’1)
Â· exp

âˆ’0.1Â¯u1 + h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


(34)
â‰¤(exp(|x|) âˆ’1) exp

âˆ’0.1Â¯u1 + h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


+ exp

h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1
= (exp(|x|) âˆ’1) âˆ’

1 âˆ’exp

âˆ’0.1Â¯u1
+h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


(exp(|x|) âˆ’1)
+ exp

h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1
â‰¤(exp(|x|) âˆ’1) âˆ’
 1 âˆ’exp
 âˆ’0.1Â¯u1 + h + C Â¯Ï‘

Â· (exp(|x|) âˆ’1) + exp

h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1
(35)
â‰¤(exp(|x|) âˆ’1) âˆ’
 1 âˆ’exp
 âˆ’0.1Â¯u1 + h + C Â¯Ï‘

Â· (exp(|x|) âˆ’1) + exp(h) âˆ’1
+ exp

0.2C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1,
(36)
where
(34)
follows
from
(33),
(35)
follows
from
Ë†Ï‘ âˆ’Î¸âˆ—
 â‰¤Â¯Ï‘, and (36) follows from the weak triangle
inequality. Thus, Assumption 8 is satisfied with V , Î±1,
Î±2, Î±3 chosen as
V (x) = exp(|x|) âˆ’1,
Î±1(r) = Î±2(r) = exp(r) âˆ’1,
Î±3(r) =

1 âˆ’exp

âˆ’0.1Â¯u1 + h + 0.1C
Ë†Ï‘ âˆ’Î¸âˆ—


Â· (exp(r) âˆ’1),
Ëœd = exp(h) âˆ’1,
Ïƒ3(r) = exp(0.1Cr) âˆ’1,
noting that Î±3â—¦Î±âˆ’1
2 (r) â‰¥
 1 âˆ’exp
 âˆ’0.1Â¯u1 + h + C Â¯Ï‘

r
for r â‰¥0 where the RHS of the inequality is clearly
convex.
Since we have verified Assumptions 1-7, we know via
Theorem 1 that if (Î´, x0) satisfy (8), the probabilistic
guarantees in (9) hold when applying the described
adaptive control strategy to (19). Moreover, since we
also verified Assumption 8, we also know via Theorem 2
that if (Î´, x0) satisfy (13), the probabilistic stability
bounds in (14) hold. By keeping all other constants
fixed and choosing Â¯x sufficiently large, both conditions
(8) and (13) can be verified for the described system
and adaptive control algorithm.
Finally, we also simulated the closed-loop adaptive PWA
system over 100 trials with x = 3000, u1 = 0.9, u2 = 0.1,
Â¯w = 0.07, Î³ = 0.0001 and x0 = 0.5. The median and
90th percentile of the system state over 100 sample paths
are shown in Figure 1. The figure highlights the sta-
ble behaviour of the adaptive system, supporting The-
orem 2. Note that with these parameters, the condi-
tions in Theorem 2 are satisfied. However, Tconverge(Î´, x0)
and Tcontained(Î´, x0) were found to be significantly larger
than the times in Figure 1, reflecting the conservative-
ness of our analysis.
12

Fig. 1. Median and 90th percentile of |X(t)| over 100 trials.
4.2
Example 2: Input-Constrained Stochastic Linear
System
We consider stochastic linear systems of the form
X(t + 1) = AX(t) + BU(t) + W(t + 1), t âˆˆN0,
with X(0) = x0, where the random sequences {X(t)}tâˆˆN0,
{U(t)}tâˆˆN0 and {W(t)}tâˆˆN are the states, controls, and
process noise, taking values in Rn, Rm, and Rn respec-
tively, x0 âˆˆRn is the initial state, and A âˆˆRnÃ—n and
B âˆˆRnÃ—m are the true, unknown, system matrices.
We assume that {W(t)}tâˆˆN is sampled i.i.d. from the
normal distribution N(0, Î£w) with Î£w â‰»0. Moreover,
we assume that A is full rank and satisfies |A| â‰¤1, and
(A, B) is Îº-step reachable, that is, rank(RÎº(A, B)) = n,
where RÎº( ËœA, ËœB) :=
h
ËœB ËœA ËœB . . . ËœAÎºâˆ’1 ËœB
i
is the Îº-step
reachability matrix given ËœA âˆˆRnÃ—n and ËœB âˆˆRnÃ—m.
The Îº-step sub-sampled system can be written as the
linear system
Â¯X(Ï„ + 1) = AX(Îº(Ï„ + 1) âˆ’1) + BU(Îº(Ï„ + 1) âˆ’1)
+ W(Îº(Ï„ + 1) âˆ’1)
= AÎº Â¯X(Ï„) + Râˆ—Â¯U(Ï„) + Â¯W(Ï„ + 1)
(37)
for Ï„ âˆˆN0, with Râˆ—:= RÎº(A, B). Here, { Â¯X(Ï„)}tâˆˆN0
is the sub-sampled state sequence taking values in Rn,
{ Â¯U(Ï„)}Ï„âˆˆN0 is the control sequence for the sub-sampled
system defined as
Â¯U(Ï„) :=
h
U(Îº(Ï„ + 1) âˆ’1)âŠ¤. . . U(ÎºÏ„)âŠ¤
iâŠ¤
,
and { Â¯W(Ï„)}Ï„âˆˆN is the process noise for the sub-sampled
system defined as
Â¯W(Ï„) := RÎº(A, I)
h
W(Îº(Ï„ + 1) âˆ’1)âŠ¤. . . W(Ï„)âŠ¤
iâŠ¤
.
Note that { Â¯W(Ï„)}Ï„âˆˆN is an i.i.d. random sequence
sampled from the distribution N(0, Î£ Â¯
w), where Î£ Â¯
w :=
RÎº(A, I)(IÎº âŠ—Î£w)RÎº(A, I)âŠ¤with âŠ—denoting the Kro-
necker product.
We consider the Îº-step sub-sampled system from (37)
as the dynamical system to be controlled, such that the
nominal system f, unknown parameter Î¸âˆ—, and basis
functions Ïˆ in (1) correspond to
f(x, u) = 0,
Î¸âˆ—=
h
AÎº Râˆ—
iâŠ¤
,
Ïˆ(x, u) =
"
x
u
#
,
for x âˆˆRn and u âˆˆRÎºm. We make this choice because
considering the sampled system is a common technique
for analyse the stability of input-constrained linear sys-
tems with unbounded stochastic disturbances. This is
reasonable because the stability of the original system
is typically implied by the stability of the sub-sampled
system. Moreover, Âµw is the probability measure associ-
ated with the distribution N(0, Î£ Â¯
w).
We now describe the adaptive control strategy based on
the framework in Algorithm 1. Firstly, let Â¯u1 âˆˆ(0, umax)
be a user-chosen parameter that specifies the level of
the saturated component of the policy Î±. Moreover, let
Â¯u2 =
1
âˆšÎºm(umaxâˆ’Â¯u1), and we choose Âµs as the probabil-
ity measure associated with the joint distribution of Îºm
independent uniform distributions over [âˆ’Â¯u2, Â¯u2], such
that S = [âˆ’Â¯u2, Â¯u2]Îºm. The family of control policies Î±
chosen for our framework is then given by
Î±(x, s, Ï‘) := satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1x) + s
for s âˆˆS and Ï‘ =
h
Ï‘1 Ï‘2
iâŠ¤
with Ï‘1 âˆˆRnÃ—n and Ï‘2 âˆˆ
RnÃ—Îºm.
Next, we verify the assumptions required to establish
Corollary 1. We start by verifying Assumption 1. We
know f(x, u) = 0 is Borel measurable since constants
are Borel measurable, and Ïˆ(x, u) =
h
xâŠ¤uâŠ¤
iâŠ¤
is Borel
measurable since coordinate functions preserve Borel
measurability. Moreover, Î±(x, s, Ï‘) = satÂ¯u1(Ï‘â€ 
2Ï‘Îº
1x)+s is
Borel measurable since 1) addition, multiplication, com-
position, and coordinate functions preserve Borel mea-
surability, and 2) both satÂ¯u1(Â·) and the pseudo-inverse
(Â·)â€  are Borel measurable functions.
Next, Assumption 2 holds since { Â¯W(Ï„)}Ï„âˆˆN is an i.i.d.
sequence by construction, { Â¯W(Ï„)}Ï„âˆˆN and {S(Ï„)}Ï„âˆˆN0
are mutually independent, and Â¯W(Ï„) is zero-mean and
Î»max(Î£ Â¯
w)-sub-Gaussian.
We now verify Assumption 3. Firstly, note that for any
initial state Î¾ âˆˆX, sub-sampled time Ï„ âˆˆN0, and deter-
ministic input and noise sequences for the sub-sampled
13

system {u(i)}Ï„âˆ’1
i=0 âˆˆUÏ„ and {w(i)}Ï„
i=1 âˆˆWÏ„, the deter-
ministic trajectory Ï• corresponding to the sub-sampled
system (37) satisfies
|Ï•(Ï„, Î¾, {u(i)}Ï„âˆ’1
i=0 , {w(i)}Ï„
i=1)|
â‰¤|AÎºÏ„x0 +
Ï„âˆ’1
X
i=0
AÎºiRâˆ—u(Ï„ âˆ’1 âˆ’i) +
Ï„âˆ’1
X
i=0
AÎºiw(Ï„ âˆ’i)|
â‰¤|AÎºÏ„x0| + |
Ï„âˆ’1
X
i=0
AÎºiRâˆ—u(Ï„ âˆ’1 âˆ’i)|
+ |
Ï„âˆ’1
X
i=0
AÎºiRÎº(A, I)w(Ï„ âˆ’i)|
â‰¤|x0| + |Râˆ—|
Ï„âˆ’1
X
i=0
|u(i)| + |RÎº(A, I)|
Ï„
X
i=1
|w(i)|.
Thus, Assumption 3 is satisfied with Ï‡2(Â·) = Id(Â·),
Ï‡3(Â·) = |Râˆ—|Id(Â·),
Ï‡4(Â·) = |RÎº(A, I)|Id(Â·) and Ïƒ1(Â·) = Ïƒ2(Â·) = Id(Â·), and
with arbitrary Ï‡1 âˆˆK1-SE
âˆž
.
Next, Assumption 4 holds since for all x âˆˆX, s âˆˆS and
Ï‘ =
h
Ï‘1 Ï‘2
iâŠ¤
âˆˆRdÃ—n,
|Î±(x, s, Ï‘)| := | satÂ¯u1(Ï‘â€ 
2Ï‘Îº
1x)| + |s| â‰¤Â¯u1 + âˆšÎºmÂ¯u2
= umax
Note that Assumption 5 is satisfied with Ï‡4(Â·) = Id(Â·).
We now verify Assumption 9. The steps we take to verify
this follow similarly to Example 2 in [18]. In both cases,
Lemma 1 is used to establish regional excitation, and lin-
ear systems with bounded policies and Gaussian process
noise are considered. However, differences arise since we
consider multi-dimensional systems, rather than specif-
ically the double integrator which is a 2-dimensional
system. Suppose x âˆˆRn, Ï‘ âˆˆR(n+Îºm)Ã—n, and Î¶ =
[Î¶âŠ¤
1 Î¶2]âŠ¤âˆˆSn+Îºmâˆ’1 (where Î¶1 âˆˆRn and Î¶2 âˆˆRÎºm).
Then,
E
Î¶âŠ¤Ïˆ(x + W, Î±(x + W, S, Ï‘)

= E
hÎ¶âŠ¤
1 (x + W) + Î¶âŠ¤
2 (satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)

i
.
(38)
Moreover,
E
hÎ¶âŠ¤
1 (x + W) + Î¶âŠ¤
2 (satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)

i
= E

E
Î¶âŠ¤
1 (x + W)
+Î¶âŠ¤
2 (satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)
 | S
ii
(39)
â‰¥E
E

Î¶âŠ¤
1 (x + W)
+Î¶âŠ¤
2 (satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S) | S
i
i
= E
Î¶âŠ¤
1 x
+Î¶âŠ¤
2 E
h
satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W))
i
+ Î¶âŠ¤
2 S

i
(40)
â‰¥|Î¶2|E[|S|] = |Î¶2|âˆšÎºm Â¯u2
2
(41)
where (39) follows from the tower property, and (40)
follows from the independence of W and S. Moreover,
(41) follows from the optimality property of medians and
E[|S|] â‰¥
1
âˆšÎºmE[|S|1] =
1
âˆšÎºm
PÎºm
i=1 E[|Si|] = âˆšÎºm Â¯u2
2 ,
where Si denotes the ith coordinate of S and we make
use of E[|Si|] = Â¯u2
2 . Similarly, we have
E
hÎ¶âŠ¤
1 (x + W) + Î¶âŠ¤
2 (satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)

i
= E

E
Î¶âŠ¤
1 (x + W)
+Î¶âŠ¤
2 (satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)
 | W
ii
(42)
â‰¥E
hE
h
Î¶âŠ¤
1 (x + W)
+Î¶âŠ¤
2 (satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S) | W
i
i
= E
hÎ¶âŠ¤
1 (x + W) + Î¶âŠ¤
2 satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W))

i
(43)
â‰¥|Î¶1|E[|(x + W)|]
âˆ’|Î¶2|E
hsatÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W))

i
(44)
â‰¥|Î¶1|E[|W|] âˆ’|Î¶2|u1
(45)
= |Î¶1|
r
2Î»min(Î£ Â¯
w)n
Ï€
âˆ’|Î¶2|u1
(46)
where (42) follows from the tower property, (43) follows
from the independence of W and S, (44) follows from
the reverse triangle inequality, (45) follows from the
optimality property of medians and the fact that satÂ¯u1
is upper bounded by u1, and (46) follows from E[|W|] =
E
hÎ£1/2
Â¯
w Î£âˆ’1/2
Â¯
w
W

i
â‰¥
p
Î»min(Î£ Â¯
w)E
hÎ£âˆ’1/2
Â¯
w
W

i
â‰¥
q
Î»min(Î£ Â¯
w)
n
E
hÎ£âˆ’1/2
Â¯
w
W

1
i
=
q
Î»min(Î£ Â¯
w)
n
Pn
i=1 E
h

Î£âˆ’1/2
Â¯
w
W

i

i
=
q
2Î»min(Î£ Â¯
w)n
Ï€
,
where

Î£âˆ’1/2
Â¯
w
W

i
denotes
the
ith
coordinate
of
Î£âˆ’1/2
Â¯
w
W and we make use of E
h

Î£âˆ’1/2
Â¯
w
W

i

i
=
q
2
Ï€
since
Î£âˆ’1/2
Â¯
w
W
has
distribution
N(0, I).
Note
that
if
|Î¶2|
â‰¤
âˆš
Î»min(Î£ Â¯
w)n
Â¯u1
âˆš
2Ï€+2âˆš
Î»min(Î£ Â¯
w)n,
then
|Î¶1|
â‰¥
1 âˆ’
âˆš
Î»min(Î£ Â¯
w)n
Â¯u1
âˆš
2Ï€+2âˆš
Î»min(Î£ Â¯
w)n, and so |Î¶1|
q
2Î»min(Î£ Â¯
w)n
Ï€
âˆ’
|Î¶2|u1
â‰¥

1 âˆ’
âˆš
Î»min(Î£ Â¯
w)n
Â¯u1
âˆš
2Ï€+2âˆš
Î»min(Î£ Â¯
w)n
q
2Î»min(Î£ Â¯
w)n
Ï€
âˆ’
âˆš
Î»min(Î£ Â¯
w)nÂ¯u1
Â¯u1
âˆš
2Ï€+2âˆš
Î»min(Î£ Â¯
w)n
=
q
Î»min(Î£ Â¯
w)n
2Ï€
.
Moreover,
if
14

|Î¶2|
>
âˆš
Î»min(Î£ Â¯
w)n
Â¯u1
âˆš
2Ï€+2âˆš
Î»min(Î£ Â¯
w)n,
then
|Î¶2|âˆšÎºm u2
2
>
âˆš
Î»min(Î£ Â¯
w)nmÎºÂ¯u2
2
âˆš
2Ï€Â¯u1+4âˆš
Î»min(Î£ Â¯
w)n. Combining this with (38), (41)
and (46), we have
E
hÎ¶âŠ¤
1 (x + W) + Î¶âŠ¤
2 (satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)

i
â‰¥max
 
|Î¶2|âˆšÎºm Â¯u2
2 , |Î¶1|
r
2Î»min(Î£ Â¯
w)n
Ï€
âˆ’|Î¶2|u1
!
â‰¥min
 
p
Î»min(Î£ Â¯
w)nmÎºÂ¯u2
2
âˆš
2Ï€Â¯u1 + 4pÎ»min(Î£ Â¯
w)n,
r
Î»min(Î£ Â¯
w)n
2Ï€
!
.
On the other hand, we have
Var
Î¶âŠ¤Ïˆ(x + W, satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)


â‰¤Var

Î¶âŠ¤Ïˆ(x + W, satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W)) + S)

= E
h
Î¶âŠ¤
1 W + Î¶âŠ¤
2 S + Î¶âŠ¤
2

satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W))
âˆ’E
h
satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W))
i2
â‰¤3

E
h Î¶âŠ¤
1 W
2i
+ E
h Î¶âŠ¤
2 S
2i
+ E
h
Î¶âŠ¤
2

satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W))
âˆ’E
h
satÂ¯u1(âˆ’Ï‘â€ 
2Ï‘Îº
1(x + W))
i2
(47)
â‰¤3

max

Ïƒ2
w, u2
2
3

+ 4u2
1

,
(48)
where (47) follows from the QM-AM inequality, and
(48) follows from E
h Î¶âŠ¤
1 W
2i
= Î¶âŠ¤
1 E

WW âŠ¤
Î¶1 â‰¤
Î»max(Î£ Â¯
w) and E

(Î¶âŠ¤
2 S)2
= Î¶âŠ¤
2 E

SSâŠ¤
Î¶2 = Â¯u2
2
3 . Thus,
using Lemma 1 we find that (Ïˆ, Î±, Âµs, Âµw) is (cPE, pPE)-
globally excited with cPE := 1
4c2
PE1 and
pPE
:=
1
4

cPE2
c2
PE1 + 1
âˆ’1
,
where
cPE1
:=
min

âˆš
Î»min(Î£ Â¯
w)nmÎºÂ¯u2
2
âˆš
2Ï€Â¯u1+4âˆš
Î»min(Î£ Â¯
w)n,
q
Î»min(Î£ Â¯
w)n
2Ï€

and
cPE2 := 3

max

Ïƒ2
w, u2
2
3

+ 4u2
1

such that Assump-
tion 9 is satisfied.
We now show that Assumption 10 is satisfied under the
additional constraint
h := ln(E[exp(|Râˆ—S|)]) + ln(E[exp(|W|)]) < Ïƒmin(Râˆ—)Â¯u1.
(49)
To see this, we first note under this constraint and using
Lemma 2, we know there exist Â¯Ï‘, C > 0 such that for any
x âˆˆRn and Ë†Ï‘ =
h
Ë†Ï‘1 Ë†Ï‘2
iâŠ¤
âˆˆÂ¯B Â¯Ï‘(Î¸âˆ—), both h+|Râˆ—|C Â¯Ï‘ <
Ïƒmin(Râˆ—)Â¯u1
and
satÂ¯u1(Ë†Ï‘â€ 
2 Ë†Ï‘1x) âˆ’satÂ¯u1(Râ€ 
âˆ—AÎºx)

â‰¤
C
Ë†Ï‘ âˆ’Ï‘âˆ—
 hold. Now, let Â¯Ï‘, C satisfy this requirement.
Following similar steps to the proof of Lemma 2 in [20],
we find that for all x âˆˆRn and Ë†Ï‘ =
h
Ë†Ï‘1 Ë†Ï‘2
iâŠ¤
âˆˆÂ¯B Â¯Ï‘(Î¸âˆ—),
E
h
exp

|AÎºx + Râˆ—

âˆ’satÂ¯u1

Ë†Ï‘â€ 
2 Ë†Ï‘1x

+ S

+ W|

âˆ’1
i
â‰¤âˆ’1 + max

exp

h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


,
exp

|x| âˆ’Ïƒmin(Râˆ—)Â¯u1 + h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


= max

exp

h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1, exp(|x|)
Â· exp

âˆ’Ïƒmin(Râˆ—)Â¯u1 + h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1

â‰¤max

exp

h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1, (exp(|x|) âˆ’1)
Â· exp

âˆ’Ïƒmin(Râˆ—)Â¯u1 + h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


(50)
â‰¤exp

âˆ’Ïƒmin(Râˆ—)Â¯u1 + h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


Â· (exp(|x|) âˆ’1) + exp

h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1
= (exp(|x|) âˆ’1) âˆ’(exp(|x|) âˆ’1)
Â·

1 âˆ’exp

âˆ’Ïƒmin(Râˆ—)Â¯u1 + h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


+ exp

h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1
â‰¤(exp(|x|) âˆ’1) âˆ’(exp(|x|) âˆ’1)
Â·
 1 âˆ’exp
 âˆ’Ïƒmin(Râˆ—)Â¯u1 + h + C Â¯Ï‘

+ exp

h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1
(51)
â‰¤(exp(|x|) âˆ’1) âˆ’(exp(|x|) âˆ’1)
Â·
 1 âˆ’exp
 âˆ’Ïƒmin(Râˆ—)Â¯u1 + h + C Â¯Ï‘

+ exp(2h) âˆ’1 + exp

2|Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


âˆ’1,
(52)
where
(50)
follows
from
(49),
(51)
follows
from
Ë†Ï‘ âˆ’Î¸âˆ—
 â‰¤Â¯Ï‘, and (52) follows from the weak triangle
inequality. Thus, Assumption 10 is satisfied with V , Î±1,
Î±2, Î±3 chosen as
V (x) = exp(|x|) âˆ’1,
Î±1(r) = Î±2(r) = exp(r) âˆ’1,
Î±3(r) = (exp(r) âˆ’1)
Â·

1 âˆ’exp

âˆ’Ïƒmin(Râˆ—)Â¯u1 + h + |Râˆ—|C
Ë†Ï‘ âˆ’Î¸âˆ—


,
Ëœd = exp(h) âˆ’1,
Ïƒ3(r) = exp(2|Râˆ—|Cr) âˆ’1,
noting
that
Î±3
â—¦
Î±âˆ’1
2 (r)
â‰¥
(1 âˆ’exp(âˆ’Ïƒmin(Râˆ—)Â¯u1 + h + Cm))r for r â‰¥0 where
the RHS of the inequality is clearly convex.
Since, we have shown that Assumptions 1, 2, 3, 4, 5 are
9 satisfied, and 10 is also satisfied under the extra as-
15

sumption (49), the premise of Corollary 1 has been veri-
fied. Thus, we have successfully established the existence
of a high probability stability bounds for the learning-
based adaptive control problem in input-constrained lin-
ear systems subject to Gaussian disturbances. We point
out that high probability stability bounds were estab-
lished in [20], but using an analysis specific to the prob-
lem setup in (37). On the other hand, here we made use
of the general analytical framework from Section 3 to
establish such bounds.
5
Proofs
We now provide the proofs of all results in this paper.
In Section 5.1, we establish the estimation error bound
and invariance guarantee result from Theorem 1. In Sec-
tion 5.2, we prove the probabilistic stability bound re-
sults in Theorem 2 and Corollary 1.
5.1
Estimation Error Bounds and Invariance Guaran-
tee
Firstly, we provide Lemma 3. It ensures that the states,
controls, and parameter estimates, are all random se-
quences, such that all stochastic properties of interest
are well-defined. This result is the same as Lemma 2 in
[18], which we refer to for the proof. We will not refer to
Lemma 3 directly in our proofs to simplify the exposi-
tion.
Lemma 3 Suppose
Assumption
1
holds.
Then,
{X(t)}tâˆˆN0, {U(t)}tâˆˆN0, {Z(t)}tâˆˆN and {Ë†Î¸(t)}tâˆˆN, all
satisfy the definition of a random sequence.
Next, we provide Lemma 4, which is a high probability,
upper bound on the estimation error |Ë†Î¸(t) âˆ’Î¸âˆ—| as a
function of Î»min(G(t)) and Î»max(G(t)). This is the same
as Lemma 7 in [18], which we refer to for the proof.
Lemma 4 (Data-Dependent
Least-Squares
Error
Bounds) Suppose Assumptions 1 and 2 are satisfied.
Then, for any Î´ âˆˆ(0, 1) and x0 âˆˆX
P

|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤
1
Î»min(G(t))1/2

Î³1/2|Î¸âˆ—|F +
Ïƒw
p
2n(ln(n/Î´) + (d/2) ln(Î»max(G(t))Î³âˆ’1))

, âˆ€t âˆˆN

â‰¥1 âˆ’Î´.
In order to move from the data-dependent bound in
Lemma 4 to a data-independent bound, we need to ob-
tain a probabilistic upper bound on Î»max(G(t)) and
lower bound on Î»min(G(t)). The upper bound can be ob-
tained with the help of Lemma 5, which provides high
probability upper bounds on |Z(t)| and |X(t)| that hold
uniformly over all time. This is the same as Lemma 4 in
[18], which we refer to for the proof.
Lemma 5 (High
Probability
State
and
Regressor
Bounds) Suppose Assumptions 1, 2, 3, 4 and 5 hold.
Then, there exists APB function Ï‡5 : Râ‰¥0 â†’Râ‰¥0, such
that for any x0 âˆˆX and Î´ âˆˆ(0, 1),
P(|X(t âˆ’1)| â‰¤x(t âˆ’1, Î´, x0)
and |Z(t)| â‰¤z(t, Î´, x0), âˆ€t âˆˆN) â‰¥1 âˆ’Î´,
with x and z defined in (4) and (5) respectively.
Next,
we
probabilistically
lower
bound
Î»min(Pt
i=1 Z(i)Z(i)âŠ¤) using Lemma 6. It says that
there exists a high probability event E2, such that for all
time steps t â‰¥Tburn-in(3Î´, x0), if 1) our sample belongs
to this event, 2) the upper bound |Z(i)| â‰¤z(i, Î´, x0)
holds on the regressor for all i â‰¤t, and 3) the one-step
predicted state E[X(i) | X(i âˆ’1), U(i âˆ’1)] remains in
XPE for all i â‰¤t âˆ’1, then a linearly increasing lower
bound on Î»min
Pt
i=1 Z(i)Z(i)âŠ¤
holds â€” i.e. PE is
holding. We interpret this as a regional PE result due
to the requirement that the one-step predicted state re-
mains in XPE. Note that conditioning on the event E2 is
required due to the stochastic nature of the problem, in
the sense that PE also depends on the injected and pro-
cess noise affecting the system. This result is the same
as Lemma 5 in [18], which we refer to for the full proof.
Lemma 6 (Regional Persistency of Excitation) Sup-
pose Assumptions 1, 2, 3, 4, 5 and 6 are satisfied. More-
over, suppose that (Ïˆ, Î±, Âµw, Âµs) is (XPE, cPE, pPE) for
some XPE âŠ†X, cPE, pPE > 0. Then, for any x0 âˆˆX
and Î´ âˆˆ(0, 1), there exists an event E2 âˆˆF satisfying
P(E2) â‰¥1 âˆ’Î´, such that for any t â‰¥Tburn-in(3Î´, x0),
Î»min
 
t
X
i=1
Z(i)Z(i)âŠ¤
!
â‰¥cPEpPE
4
(t âˆ’1)
on the event 3
E2 âˆ©{|Z(i)| â‰¤z(i, Î´, x0), âˆ€i â‰¤t}âˆ©
{E[X(i) | X(i âˆ’1), U(i âˆ’1)] âˆˆXPE, âˆ€i â‰¤t âˆ’1}.
3 We use â€œon the eventâ€ to relate a predicate involving a ran-
dom variable to a probabilistic event, with the understanding
it means that when an outcome belongs to that event, the
predicate evaluated on the random variable is true. Specifi-
cally, given a collection of random variables X1, X2, . . . tak-
ing values in X1, X2, . . ., a predicate Q : X1 Ã— X2 Ã— Â· Â· Â· â†’
{true, false}, and an event E âˆˆF, we write â€œon the event E,
Q(X1, X2, . . .)â€, or equivalently â€œQ(X1, X2, . . .) on the event
Eâ€, if E âŠ†{Q(X1, X2, . . .)}.
16

We now provide Proposition 1. It can be viewed as a
result similar to Theorem 1 that provides estimation er-
ror bounds and the guarantee of invariance of the state
X(t) inside XRPI, but it also contains the information
that this event is a superset of another event E2 âˆ©E3 âˆ©E4
(defined in Proposition 1). We provide this more infor-
mative representation since it is useful for the stability
analysis later in Section 5.2.
Proposition 1 Suppose Assumptions 1, 2, 3, 4, 5, 6 and
7 are satisfied. Then, for any x0 âˆˆXRPI and Î´ âˆˆ(0, 1)
such that (8) is satisfied, there exists an event E2 âˆˆF
satisfying P(E2) â‰¥1 âˆ’Î´/3 such that on the event E2 âˆ©
E3 âˆ©E4,
|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤e(t, Î´, x0) for all t â‰¥Tburn-in(Î´, x0)
and X(t) âˆˆXRPI for all t âˆˆN0,
(53)
where the events E3, E4 âˆˆF are defined as
E3 :=
(
|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤
1
Î»min(V (t))1/2

Î³1/2|Î¸âˆ—|F +
Ïƒw
p
2n(ln(3n/Î´) + (d/2) ln(Î»max(V (t))Î³âˆ’1))

, âˆ€t âˆˆN
)
,
E4 := {|X(t âˆ’1)| â‰¤x(t âˆ’1, Î´/3, x0),
|Z(t)| â‰¤z(t, Î´/3, x0), âˆ€t âˆˆN}.
and moreover P(E2 âˆ©E3 âˆ©E4) â‰¥1 âˆ’Î´. Furthermore, for
any x0 âˆˆXRPI and Î´ âˆˆ(0, 1),
(1) limtâ†’âˆže(t, Î´, x0) = 0;
(2) Tburn-in(Î´, x0) < âˆž;
(3) Tconverge(Î´, x0) < âˆž.
PROOF. Throughout this proof, suppose x0 âˆˆXRPI,
Î´ âˆˆ(0, 1) and (8) are satisfied. We will first prove (53),
then statements 1)-3) at the end.
We start by proving (53). Let E2 âˆˆF be an event such
that for all t â‰¥Tburn-in(Î´, x0),
Î»min
 
t
X
i=1
Z(i)Z(i)âŠ¤
!
â‰¥cPE3pPE
4
(t âˆ’1)
on the event
E2 âˆ©{|Z(i)| â‰¤z(i, Î´/3, x0), âˆ€i â‰¤t}âˆ©
{E[X(i) | X(i âˆ’1), U(i âˆ’1)] âˆˆXPE, âˆ€i â‰¤t âˆ’1}, (54)
and P(E2) â‰¥1âˆ’Î´/3, where the existence of a satisfactory
E2 is established in Lemma 6, which we can make use of
due to Assumptions 1, 2, 3, 4, 5 and 6. Moreover, recall
that E3, E4 âˆˆF are both defined in the statement of this
proposition, and correspond to the event that that the
data-dependent estimation error bound from Lemma 4
holds, and the event that the state and regressor bound
from Lemma 5 holds, respectively. We will establish (53)
by separately proving that on the event E2 âˆ©E3 âˆ©E4,
|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤e(t, Î´, x0)
(55)
for all t âˆˆ{Tburn-in(Î´, x0), . . . , Tconverge(Î´, x0) âˆ’1},
and that on the event E2 âˆ©E3 âˆ©E4,
|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤e(t, Î´, x0) for all t â‰¥Tconverge(Î´, x0)
and X(t) âˆˆXRPI for all t âˆˆN0.
(56)
We first establish (55). Note that E4
âŠ†
{X(i)
âˆˆ
XRPI
for all
i
â‰¤
Tconverge(Î´, x0) âˆ’3}
since
Tconverge(Î´, x0) â‰¤Tcontained(Î´, x0) âˆ’1 due to (8). This
implies that {X(i) âˆˆXRPI for all i â‰¤Tconverge(Î´, x0) âˆ’
3}
âŠ†
{g(X(i), U(i), 0)
âˆˆ
Î“(XRPI)
for all
i
â‰¤
Tconverge(Î´, x0) âˆ’3}âŠ†{E[X(i) | X(i âˆ’1), U(i âˆ’1)] âˆˆ
XPE for all i â‰¤Tconverge(Î´, x0) âˆ’2}, where we used the
fact that E[X(i + 1) | X(i), U(i)] = g(X(i), U(i), 0) and
g(X(i), U(i), 0) âˆˆÎ“(XRPI) on the event {X(i) âˆˆXRPI
due to Assumption 4. Making use of (54), it follows
that for all t âˆˆ{Tburn-in(Î´, x0), . . . , Tconverge(Î´, x0) âˆ’2},
E2 âˆ©E4 âˆ©{E[X(i) | X(i âˆ’1), U(i âˆ’1)] âˆˆXPE for all i â‰¤
Tconverge(Î´, x0) âˆ’2} âŠ†{Î»min(G(t)) â‰¥
cPEpPE
4
(t âˆ’1)},
and therefore E2 âˆ©E3 âˆ©E4 âŠ†{|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤e(t, Î´, x0)},
which follows by the definition of E3, E4 and e(t, Î´, x0)
from (10). Then, since E2 âˆ©E3 âˆ©E4 is independent of t,
we subsequently have established (55).
In order to establish (56), we first prove using an induc-
tion argument that for all t â‰¥Tconverge(Î´, x0), on the
event E2 âˆ©E3 âˆ©E4,
|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤e(t, Î´, x0) and X(i) âˆˆXRPI for all i â‰¤t + 1.
(57)
Base case: Note that E4 âŠ†{X(i) âˆˆXRPI for all i â‰¤
Tconverge(Î´, x0) + 1} since
Tconverge(Î´, x0)
â‰¤
Tcontained(Î´, x0) âˆ’1 due to (8).
Moreover,
we
have
{X(i)
âˆˆ
XRPI
for all
i
â‰¤
Tconverge(Î´, x0) + 1}
âŠ†
{X(i)
âˆˆ
XRPI for all i
â‰¤
Tconverge(Î´, x0) âˆ’2} âŠ†{g(X(i), U(i), 0) âˆˆÎ“(XRPI) i â‰¤
Tconverge(Î´, x0) âˆ’2} âŠ†{E[X(i) | X(i âˆ’1), U(i âˆ’1)] âˆˆ
XPE for all i â‰¤Tconverge(Î´, x0) âˆ’1}. Next, note that
E2 âˆ©E4 âˆ©{E[X(i) | X(i âˆ’1), U(i âˆ’1)] âˆˆXPE for all i â‰¤
Tconverge(Î´, x0) âˆ’1}
âŠ†
{Î»min(G(Tconverge(Î´, x0)))
â‰¥
cPEpPE
4
(Tconverge(Î´, x0)âˆ’1)+Î³} making use of (54), and
also observe that E3 âˆ©E4 âˆ©{Î»min(G(Tconverge(Î´, x0))) â‰¥
cPEpPE
4
(Tconverge(Î´, x0)âˆ’1)+Î³} âŠ†{|Ë†Î¸(Tconverge(Î´, x0))âˆ’
Î¸âˆ—| â‰¤e(Tconverge(Î´, x0), Î´, x0)}. Thus, by combining
these set-theoretic inclusions together and making use
of the definitions of E3, E4 âˆˆF and e(t, Î´, x0) from (10),
we find that E2 âˆ©E3 âˆ©E4 âŠ†{|Ë†Î¸(Tconverge(Î´, x0)) âˆ’Î¸âˆ—| â‰¤
17

e(Tconverge(Î´, x0), Î´, x0) and X(i) âˆˆXRPI for all i â‰¤
Tconverge(Î´, x0) + 1}, completing the base case.
Inductive step: Suppose t â‰¥Tconverge(Î´, x0), and that
E2 âˆ©E3 âˆ©E4 âŠ†{|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤e(t, Î´, x0) and X(i) âˆˆ
XRPI for all i â‰¤t+1}. Note that {X(i) âˆˆXRPI for all i â‰¤
t + 1}
âŠ†
{X(i)
âˆˆ
XRPI for all i
â‰¤
t âˆ’1}
âŠ†
{g(X(i), U(i), 0) âˆˆÎ“(XRPI) for all i â‰¤t âˆ’1} âŠ†
{E[X(i) | X(i âˆ’1), U(i âˆ’1)] âˆˆXPE for all i â‰¤t}. Next,
note that E2 âˆ©E4 âˆ©{E[X(i) | X(i âˆ’1), U(i âˆ’1)] âˆˆ
XPE for all i â‰¤t} âŠ†{Î»min(G(t+1)) â‰¥cPEpPE
4
t+Î³} mak-
ing use of (54), and also observe that E3âˆ©E4âˆ©{Î»min(G(t+
1)) â‰¥cPEpPE
4
t+Î³} âŠ†{|Ë†Î¸(t)âˆ’Î¸âˆ—| â‰¤e(t+1, Î´, x0)}. Since
t â‰¥Tconverge(Î´, x0), we have e(t, Î´, x0) â‰¤Â¯Ï‘ due to (7)
and therefore {|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤e(t, Î´, x0)} âŠ†{|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤
Â¯Ï‘} making use of the definitions of E3, E4 âˆˆF and
e(t, Î´, x0) from (10). Next, note from Assumption 7 that
{|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤Â¯Ï‘} âˆ©{X(t + 1) âˆˆXRPI} âŠ†{X(t + 2) =
g(X(t+1), Î±(X(t+1), Ë†Î¸(t), S(t+1)), W(t+2)) âˆˆXRPI}.
Thus, by combining these set-theoretic inclusions to-
gether, we find that E2 âˆ©E3 âˆ©E4 âŠ†{|Ë†Î¸(t + 1) âˆ’Î¸âˆ—| â‰¤
e(t + 1, Î´, x0) and X(i) âˆˆXRPI for all i â‰¤t + 2}, con-
cluding the inductive step.
Since we have established both the base case and the in-
ductive step, we have proven (57) via induction. More-
over, since E2 âˆ©E3 âˆ©E4 is independent of t in (57), (56)
follows, and (53) subsequently follows by combining (55)
and (56).
We also find that P(E2âˆ©E3âˆ©E4) â‰¥1âˆ’Î´ by making use of
the union bound, and the fact that P(E3) â‰¥1âˆ’Î´/3 from
Lemma 4 Assumptions 1 and 2, P(E4) â‰¥1 âˆ’Î´/3 from
Lemma 5 using Assumptions 1-5, and P(E2) â‰¥1 âˆ’Î´/3
from earlier in this proof.
We now establish statement 1)-3). The proof steps for
1) are the same as the proof steps of statement 4) from
Corollary 1 in [18]. Moreover, the proof of 2) is the same
as the proof of Tburn-in(Î´, x0) < âˆžin Theorem 1 from
[18]. Finally, Tconverge(Î´, x0) follows from 1) and 2).
Theorem 1 easily follows as a consequence of Proposi-
tion 1, but is more easily interpreted.
Proof of Theorem 1
Suppose x0 âˆˆX, Î´ âˆˆ(0, 1) and (8) are satisfied. Let
E2, E3, E4 âˆˆF be defined the same as in Proposition 1.
Then, we establish (9) as follows:
P(|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤e(t, Î´, x0) for all t â‰¥Tburn-in(Î´, x0)
and X(t) âˆˆXRPI for all t âˆˆN0)
â‰¥P(E2 âˆ©E3 âˆ©E4)
(58)
â‰¥1 âˆ’Î´,
(59)
where (58) and (59) both follow from Proposition 1.
Statements 1)-3) in Theorem 1 follow directly from state-
ments 1)-3) in Proposition 1.
5.2
Stability Guarantees
We provide Proposition 2. It can be interpreted as a
bound on the magnitude of the states X(t) of the closed-
loop system (1) under the adaptive control framework
described in Algorithm 1, that depends on the probabil-
ity that the parameter estimates Ë†Î¸(t) remain in a Â¯e(t)-
ball around Î¸âˆ—at each time t â‰¥t0 (for arbitrary t0 âˆˆN0
and {Â¯e(t)}tâ‰¥t0).
Proposition 2 Suppose Assumptions 1, 2, and 8 are
satisfied. Then, for all Î´ âˆˆ(0, 1), there exists Î²1, Î²2 âˆˆ
KL, Î³3 âˆˆK, Î·2 âˆˆL and c2 â‰¥0 such that for any bounded
set X âŠ†XRPI,
P

|X(t)| â‰¤max

Î²1(max
xâˆˆX |x|, t âˆ’t0),
Î·2(t âˆ’t0) + Î²2

max
t0âˆ’1â‰¤iâ‰¤t0+âŒŠ(tâˆ’t0)/2âŒ‹âˆ’1 Â¯e(i), t âˆ’t0

,
c2 + Î³3

max
t0+âŒŠ(tâˆ’t0)/2âŒ‹â‰¤iâ‰¤tâˆ’1 Â¯e(i)

â‰¥1 âˆ’Î´ âˆ’P({X(t0) âˆˆXRPI}c
âˆª

|Ë†Î¸(i) âˆ’Î¸âˆ—| â‰¤Â¯e(i) for all i â‰¥t0 âˆ’1
	c
âˆª{X(i) âˆˆXRPI for all i â‰¥t0}c)
(60)
for all x0 âˆˆX, t0 âˆˆN0, t â‰¥t0, and {Â¯e(i)}iâ‰¥t0âŠ†Râ‰¥0
satisfying e(i) â‰¤Â¯Ï‘ for all i â‰¥t0 âˆ’1
PROOF. Let XRPI, V : XRPI â†’Râ‰¥0, and Â¯Î¸ > 0,
be such that (g, Î±, Âµw, Âµs) is (V, XRPI, Â¯Ï‘)-stochastic Lya-
punov (with existence verified via Assumption 8), and
let Î±1, Î±2, Î±3 âˆˆKâˆž, Ïƒ3 âˆˆK, and Ëœd â‰¥0, all satisfy
the requirements in Definition 4 for (g, Î±, Âµw, Âµs) to be
(V, XRPI, Â¯Ï‘)-stochastic Lyapunov.
Throughout this proof, suppose X âŠ†XRPI, x0 âˆˆX,
t0 âˆˆN0, and {Â¯e(i)}iâ‰¥t0âŠ†Râ‰¥0 satisfies e(i) â‰¤Â¯Ï‘ for all
i â‰¥t0âˆ’1. Moreover, let {ËœÎ¸(t)}tâ‰¥t0 be a random sequence
satisfying ËœÎ¸(t) = Ë†Î¸(t) âˆ’Î¸âˆ—for all t â‰¥t0 âˆ’1.
Let Î±v âˆˆKâˆžbe a convex function satisfying Î±v(r) â‰¤
Î±3 â—¦Î±âˆ’1
2 (r) for r â‰¥0, as required in Definition 4. Then,
Î±v(V (x)) â‰¤Î±vâ—¦Î±2(|x|) â‰¤Î±3(|x|) holds for all x âˆˆXRPI.
18

Therefore, for all i â‰¥t0, on the event {|Ë†Î¸(i âˆ’1) âˆ’Î¸âˆ—| â‰¤
Â¯e(i âˆ’1)} âˆ©{X(i) âˆˆXRPI},
E[V (X(i + 1)) | X(i), Ë†Î¸(i âˆ’1)] âˆ’V (X(i))
= âˆ†V (X(i), Ë†Î¸(i âˆ’1))
(61)
â‰¤âˆ’Î±3(|X(i)|) + Ëœd + Ïƒ3(|Ë†Î¸(i âˆ’1) âˆ’Î¸âˆ—|)
(62)
â‰¤âˆ’Î±v(V (X(i))) + Ëœd + Ïƒ3(|Ë†Î¸(i âˆ’1) âˆ’Î¸âˆ—|)
â‰¤âˆ’Î±v(V (X(i))) + Ëœd + Ïƒ3(Â¯e(i âˆ’1)),
(63)
where (61) follows from (11) and (62) follows from As-
sumption 8. For convenience, throughout the remainder
of this proof, let d(i) = Ëœd + Ïƒ3(Â¯e(i âˆ’1)) for i â‰¥t0.
Next, define ËœE(i) := {X(t0) âˆˆX} âˆ©{|Ë†Î¸(j) âˆ’Î¸âˆ—| â‰¤Â¯e(j âˆ’
1) and X(j) âˆˆXRPI for all j â‰¤i} for i â‰¥t0. Then, for
all i â‰¥t0, we have
E[1 ËœE(i+1)V (X(i + 1))] â‰¤E[1 ËœE(i)V (X(i + 1))]
= E[1 ËœE(i)E[V (X(i + 1)) | {Ë†Î¸(j)}iâˆ’1
j=t0âˆ’1,
{X(j)}i
j=t0]]
(64)
= E[1 ËœE(i)E[V (X(i + 1)) | Ë†Î¸(i âˆ’1), X(i)]]
(65)
â‰¤E[1 ËœE(i)(V (X(i)) âˆ’Î±v(V (X(i))) + d(i))]
(66)
â‰¤E[1 ËœE(i)V (X(i))] âˆ’(E[1 ËœE(i)Î±v(V (X(i)))]) + d(i)
â‰¤E[1 ËœE(i)V (X(i))] âˆ’(E[Î±v(1 ËœE(i)V (X(i)))])
+ d(i)
(67)
â‰¤E[1{ ËœE(i)}V (X(i))] âˆ’Î±v(E[1 ËœE(i)V (X(i))])
+ d(i)
(68)
where (64) follows from the tower property of condi-
tional expectation and pulling out known factors, (65)
follows from the conditional independence of X(i + 1)
and {Ë†Î¸(j)}iâˆ’2
j=t0âˆ’1, {X(j)}iâˆ’1
j=t0 given Ë†Î¸(i âˆ’1), X(i), (66)
follows from (63), (67) follows from the convexity of Î±v
and the fact that Î±v(0) = 0, and (68) follows via Jensenâ€™s
inequality.
Next, define ËœÎ³(r) := 2 max(Î±âˆ’1
v (r), r) for r â‰¥0, and
note that ËœÎ³ âˆˆK. We now establish that for all i â‰¥t0
and l â‰¤i, if E[1 ËœE(i)V (X(i))] â‰¤ËœÎ³(maxlâ‰¤jâ‰¤i d(j)), then
E[1 ËœE(i+1)V (X(i + 1))] â‰¤ËœÎ³(max
lâ‰¤jâ‰¤i d(j)).
(69)
We prove (69) via two cases.
Case 1: Suppose E[V (X(i))1 ËœE(i)] â‰¤ËœÎ³(maxlâ‰¤jâ‰¤i d(j))/2.
Then, we have
E[1 ËœE(i+1)V (X(i + 1))]
â‰¤E[1 ËœE(i)V (X(i))] âˆ’Î±v(E[1 ËœE(i)V (X(i))]) + max
lâ‰¤jâ‰¤i d(j)
(70)
â‰¤E[1 ËœE(i)V (X(i))] + max
lâ‰¤jâ‰¤i d(j)
â‰¤ËœÎ³(maxlâ‰¤jâ‰¤i d(j))
2
+ max
lâ‰¤jâ‰¤i d(j)
(71)
â‰¤ËœÎ³(max
lâ‰¤jâ‰¤i d(j)),
(72)
where
(70)
follows
from
(68),
(71)
follows
since
E[V (X(i))1 ËœE(i)] â‰¤ËœÎ³(maxlâ‰¤jâ‰¤i d(j))/2, and (72) follows
from maxlâ‰¤jâ‰¤i d(j) â‰¤ËœÎ³(maxlâ‰¤jâ‰¤i d(j))/2 by the defini-
tion of ËœÎ³.
Case
2:
Suppose
ËœÎ³(maxlâ‰¤jâ‰¤i d(j))/2
â‰¤
E[V (X(i))1 ËœE(i)] â‰¤ËœÎ³(maxlâ‰¤jâ‰¤i d(j)). Then,
E[1 ËœE(i+1)V (X(i + 1))]
â‰¤E[1 ËœE(i)V (X(i))] âˆ’Î±v(E[1 ËœE(i)V (X(i))])
+ max
lâ‰¤jâ‰¤i d(j)
(73)
â‰¤ËœÎ³(max
lâ‰¤jâ‰¤i d(j)) âˆ’Î±v( ËœÎ³(maxlâ‰¤jâ‰¤i d(j))
2
)
+ max
lâ‰¤jâ‰¤i d(j)
(74)
â‰¤ËœÎ³(max
lâ‰¤jâ‰¤i d(j))
(75)
where (73) follows from (68), (74) follows from the
assumption that
ËœÎ³(maxlâ‰¤jâ‰¤i d(j))/2
â‰¤
E[V (X(i))1 ËœE(iâˆ’1)]
â‰¤
ËœÎ³(maxlâ‰¤jâ‰¤i d(j)),
and
(75)
the
fact
that
âˆ’Î±v( ËœÎ³(maxlâ‰¤jâ‰¤i d(j))
2
) â‰¤âˆ’maxlâ‰¤jâ‰¤i d(j) due to the
definition of ËœÎ³.
Thus, we have proven (69) via two cases.
Next, define Î»1(s) := s âˆ’Î±v(s) + Î±v(s/2), and Î»(s) :=
(1/2)(s+maxsâ€²âˆˆ[0,1] Î»1(sâ€²)). Note that Î»1 is continuous,
Î»1(0) = 0, and Î»1(s) < s for all s > 0, but not nec-
essarily increasing. On the other hand, it can be shown
by following similar steps to [16, Theorem B.15], that
Î» âˆˆKâˆžand
Î»1(s) â‰¤Î»(s) < s
(76)
for all s > 0. We then have that for all i â‰¥t0 and l â‰¤i,
if E[V (X(i))1 ËœE(i)] > ËœÎ³(maxlâ‰¤jâ‰¤i d(j)), then
E[1 ËœE(i+1)V (X(i + 1))]
â‰¤E[1 ËœE(i)V (X(i))] âˆ’Î±v(E[1 ËœE(i)V (X(i))]) + max
lâ‰¤jâ‰¤i d(j)
(77)
â‰¤E[1 ËœE(i)V (X(i))] âˆ’Î±v(E[1 ËœE(i)V (X(i))])
+ Î±v
 
E[V (X(i))1 ËœE(iâˆ’1)]
2
!
(78)
â‰¤Î»(E[1 ËœE(i)V (X(i))])
(79)
19

where
(77)
follows
from
(68),
(78)
follows
from
E[V (X(i))1 ËœE(i)] > ËœÎ³(maxlâ‰¤jâ‰¤i d(j)), and the fact that
maxlâ‰¤jâ‰¤i d(j) â‰¤Î±v( ËœÎ³(maxlâ‰¤jâ‰¤i d(j))
2
) by definition of ËœÎ³,
and (79) follows from (76).
Now, by contraposition of (69), for all i â‰¥t0 and l â‰¤i,
if E[1 ËœE(i+1)V (X(i + 1))] > ËœÎ³(maxlâ‰¤jâ‰¤i d(j)), then
E[1 ËœE(i)V (X(i))] > ËœÎ³(max
lâ‰¤jâ‰¤i d(j)).
(80)
Let Î»i denote the composition of Î» with itself i times.
For all i â‰¥t0 and l âˆˆ{t0, . . . , i}, if E[V (X(i))1 ËœE(i)] >
ËœÎ³(maxlâ‰¤jâ‰¤i d(j)), then it follows that
E[V (X(i + 1))1 ËœE(i+1)] â‰¤Î»(E[V (X(i))1 ËœE(i)]) (81)
â‰¤Î»2(E[V (Xiâˆ’1)1 ËœE(iâˆ’1)])
(82)
â‰¤Î»iâˆ’l+1(E[V (Xl)1 ËœE(l)])
(83)
where (81) follows from (79), (82) follows from (80) and
(79), and (83) follows by iteratively repeating this pro-
cess i + 1 times.
Suppose t â‰¥t0. For all l âˆˆ{t0, . . . , t}, we have
E[V (X(t))1 ËœE(t)]
â‰¤max(Î»tâˆ’l(E[V (Xl)1 ËœE(l)]), ËœÎ³( max
lâ‰¤jâ‰¤tâˆ’1 d(j))) (84)
â‰¤max(Î»tâˆ’l(max(Î»lâˆ’t0E[V (X(t0))1 ËœE(t0)],
ËœÎ³(
max
t0â‰¤jâ‰¤lâˆ’1 d(j)))), ËœÎ³( max
lâ‰¤jâ‰¤tâˆ’1 d(i)))
(85)
â‰¤max(Î»tâˆ’l(max(Î»lâˆ’t0 â—¦Î±2(max
xâˆˆX |x|),
ËœÎ³(
max
t0â‰¤jâ‰¤lâˆ’1 d(j)))), ËœÎ³( max
lâ‰¤jâ‰¤tâˆ’1 d(j)))
= max(Î»tâˆ’t0 â—¦Î±2(max
xâˆˆX |x|),
Î»tâˆ’l â—¦ËœÎ³(
max
t0â‰¤jâ‰¤lâˆ’1 d(j)), ËœÎ³( max
lâ‰¤jâ‰¤tâˆ’1 d(j)))
where (84) follows from (69) and (83), and so does (85).
By setting l â†t0 + âŒŠ(t âˆ’t0)/2âŒ‹, it follows that
E[V (X(t))1 ËœE(t)]
â‰¤max
 
Î»tâˆ’t0 â—¦Î±2

max
xâˆˆX |x|

,
Î»tâˆ’t0âˆ’âŒŠ(tâˆ’t0)/2âŒ‹â—¦ËœÎ³

max
t0â‰¤jâ‰¤t0+âŒŠ(tâˆ’t0)/2âŒ‹âˆ’1 d(j)

,
ËœÎ³

max
t0+âŒŠ(tâˆ’t0)/2âŒ‹â‰¤jâ‰¤tâˆ’1 d(j)
!
= max(Î»tâˆ’t0 â—¦Î±2(max
xâˆˆX |x|), Î»tâˆ’t0âˆ’âŒŠ(tâˆ’t0)/2âŒ‹
â—¦ËœÎ³( Ëœd + Ïƒ3(
max
t0âˆ’1â‰¤jâ‰¤t0+âŒŠ(tâˆ’t0)/2âŒ‹âˆ’1 e(j))),
ËœÎ³( Ëœd + Ïƒ3(
max
t0+âŒŠ(tâˆ’t0)/2âŒ‹â‰¤jâ‰¤tâˆ’1 e(j))))
= max(Î»tâˆ’t0 â—¦Î±2(max
xâˆˆX |x|), Î»t0+âŒˆ(tâˆ’t0)/2âŒ‰
â—¦ËœÎ³( Ëœd + Ïƒ3(
max
t0âˆ’1â‰¤jâ‰¤t0+âŒŠ(tâˆ’t0)/2âŒ‹âˆ’1 e(j))),
ËœÎ³( Ëœd + Ïƒ3(
max
t0+âŒŠ(tâˆ’t0)/2âŒ‹â‰¤jâ‰¤tâˆ’1 e(j))))
Next, suppose Î´ âˆˆ(0, 1), and let
E1 =
(
V (X(t))1 ËœE(t) â‰¤1
Î´ max
 
Î»tâˆ’t0 â—¦Î±2

max
xâˆˆX |x|

,
Î»t0+âŒˆ(tâˆ’t0)/2âŒ‰
â—¦ËœÎ³

Ëœd + Ïƒ3

max
t0âˆ’1â‰¤jâ‰¤t0+âŒŠ(tâˆ’t0)/2âŒ‹âˆ’1 e(j)

,
ËœÎ³

Ëœd + Ïƒ3

max
t0+âŒŠ(tâˆ’t0)/2âŒ‹â‰¤jâ‰¤tâˆ’1 e(j)
!)
.
From Markovâ€™s inequality, we have
P(E1) â‰¥1 âˆ’Î´.
(86)
Moreover, on the event E1 âˆ©ËœE(t), we have
|X(t)|
â‰¤Î±âˆ’1
1 (V (X(t)))
(87)
= Î±âˆ’1
1 (V (X(t))1 ËœE(t))
â‰¤Î±âˆ’1
1
 
1
Î´ max
 
Î»tâˆ’t0 â—¦Î±2

max
xâˆˆX |x|

,
Î»t0+âŒˆ(tâˆ’t0)/2âŒ‰
â—¦ËœÎ³

Ëœd + Ïƒ3

max
t0âˆ’1â‰¤jâ‰¤t0+âŒŠ(tâˆ’t0)/2âŒ‹âˆ’1 e(j)

,
ËœÎ³

Ëœd + Ïƒ3

max
t0+âŒŠ(tâˆ’t0)/2âŒ‹â‰¤jâ‰¤tâˆ’1 e(j)
!!
â‰¤max
 
Î±âˆ’1
1
â—¦1
Î´ Î»tâˆ’t0 â—¦Î±2

max
xâˆˆX |x|

,
Î±âˆ’1
1
â—¦1
Î´ Î»t0+âŒˆ(tâˆ’t0)/2âŒ‰
â—¦ËœÎ³

Ëœd + Ïƒ3

max
t0âˆ’1â‰¤jâ‰¤t0+âŒŠ(tâˆ’t0)/2âŒ‹âˆ’1 e(j)

,
Î±âˆ’1
1
â—¦1
Î´ ËœÎ³

Ëœd + Ïƒ3

max
t0+âŒŠ(tâˆ’t0)/2âŒ‹â‰¤jâ‰¤tâˆ’1 e(j)
!
â‰¤max(Î±âˆ’1
1
â—¦1
Î´ Î»tâˆ’t0 â—¦Î±2(max
xâˆˆX |x|),
Î±âˆ’1
1
â—¦1
Î´ Î»t0+âŒˆ(tâˆ’t0)/2âŒ‰â—¦ËœÎ³(2 Ëœd) + Î±âˆ’1
1
â—¦1
Î´ Î»t0+âŒˆ(tâˆ’t0)/2âŒ‰
â—¦ËœÎ³(2Ïƒ3(
max
t0âˆ’1â‰¤jâ‰¤t0+âŒŠ(tâˆ’t0)/2âŒ‹âˆ’1 e(j))),
20

Î±âˆ’1
1
â—¦1
Î´ ËœÎ³(2 Ëœd) + Î±âˆ’1
1
â—¦1
Î´ ËœÎ³(2Ïƒ3(
max
t0+âŒŠ(tâˆ’t0)/2âŒ‹â‰¤jâ‰¤tâˆ’1 e(j))))
(88)
â‰¤max(Î²1(max
xâˆˆX |x|, t âˆ’t0), Î·2(t âˆ’t0)
+ Î²2(
max
t0âˆ’1â‰¤jâ‰¤t0+âŒŠ(tâˆ’t0)/2âŒ‹âˆ’1 e(j), t âˆ’t0),
c2 + Î³3(
max
t0+âŒŠ(tâˆ’t0)/2âŒ‹â‰¤jâ‰¤tâˆ’1 e(j)))
(89)
where (87) follows from Definition 4, (88) follows from
the weak triangle inequality for K functions in [9, Equa-
tion 6]. Line (89) follows by setting Î²1(r, k) = Î±âˆ’1
1 â—¦1
Î´ Î»kâ—¦
Î±2(r), c2 = Î±âˆ’1
1
â—¦1
Î´ ËœÎ³(2 Ëœd), and Î³3(r) = Î±âˆ’1
1
â—¦1
Î´ ËœÎ³(2Ïƒ3(r)),
where Î²1 and Î³3 are clearly of class KL and K re-
spectively, and moreover by letting Î·2 and Î²2 be class
L and KL functions respectively that satisfy Î·2(k) =
Î±âˆ’1
1
â—¦1
Î´ Î»t0+âŒˆk/2âŒ‰â—¦ËœÎ³(2 Ëœd), Î²2(r, k) = Î±âˆ’1
1
â—¦1
Î´ Î»t0+âŒˆk/2âŒ‰â—¦
ËœÎ³(2Ïƒ3(r)).
Therefore, we find that
P
 
|X(t)| â‰¤max
 
Î²1

max
xâˆˆX |x|, t âˆ’t0

,
Î·2(t âˆ’t0) + Î²2

max
t0âˆ’1â‰¤jâ‰¤t0+âŒŠ(tâˆ’t0)/2âŒ‹âˆ’1 e(j), t âˆ’t0

,
c2 + Î³3

max
t0+âŒŠ(tâˆ’t0)/2âŒ‹â‰¤jâ‰¤tâˆ’1 e(j)
!!
â‰¥P(E1 âˆ©ËœE(t))
(90)
â‰¥1 âˆ’P(Ec
1) âˆ’P( ËœEc(t))
(91)
â‰¥1 âˆ’Î´ âˆ’P( ËœEc(t)).
(92)
where (90) follows from (89), (91) follows from the union
bound, and (92) follows from (86).
We now prove Theorem 2.
Proof of Theorem 2 Suppose Î´ âˆˆ(0, 1), and let
ËœÎ´ = Î´/2. Let Â¯Ï‘ and V : XRPI â†’Râ‰¥0 be such that
(g, Î±, Âµw, Âµs) is (V, XRPI, Â¯Ï‘)-stochastic Lyapunov. Let
Î²1, Î²2 âˆˆKL, Î³3 âˆˆK, Î·2 âˆˆL and c2 â‰¥0 satisfy (60),
where the existence of these objects is ensured since un-
der our assumptions, Proposition 2 is satisfied. Now,
suppose x0 âˆˆXRPI, and (ËœÎ´, x0) satisfies condition (8)
equivalent to (13) being satisfied). Then, using Propo-
sition 1, we know there exists an event E2 âˆˆF satisfy-
ing (53), with E3, E4 âˆˆF defined in Proposition 1. Next,
note that on the event E2 âˆ©E3 âˆ©E4,
|Ë†Î¸(t) âˆ’Î¸âˆ—| â‰¤e(t, ËœÎ´, x0) for all t â‰¥Tburn-in(ËœÎ´, x0)
and X(t) âˆˆXRPI for all t âˆˆN0.
For convenience of notation, let T0 = Tconverge(ËœÎ´, x0).
Using this result, and the fact that e(t, ËœÎ´, x0) â‰¤Â¯Ï‘ for
all t â‰¥T0 by the definition of Tconverged(ËœÎ´, x0) in (7), we
apply Proposition 2 to find that for all t â‰¥T0 + 1,
P

|X(t)| â‰¤max

Î²1(x(T0 + 1, ËœÎ´/3, x0), t âˆ’(T0 + 1)),
Î²2

max
(T0+1)âˆ’1â‰¤iâ‰¤(T0+1)+âŒŠ(tâˆ’(T0+1))/2âŒ‹âˆ’1 e(i, ËœÎ´, x0),
t âˆ’(T0 + 1)) + Î·2(t âˆ’(T0 + 1)),
c2 + Î³3

max
(T0+1)+âŒŠ(tâˆ’(T0+1))/2âŒ‹â‰¤iâ‰¤tâˆ’1 e(i, ËœÎ´, x0)

â‰¥1 âˆ’ËœÎ´ âˆ’P({|X(T0 + 1)| â‰¤x(T0 + 1, ËœÎ´/3, x0)}c
âˆª

|Ë†Î¸(i) âˆ’Î¸âˆ—| â‰¤e(i, ËœÎ´, x0) for all i â‰¥(T0 + 1) âˆ’1
	c
âˆª{X(i) âˆˆXRPI for all i â‰¥(T0 + 1)}c)
â‰¥1 âˆ’ËœÎ´ âˆ’P((E2 âˆ©E3 âˆ©E4)c) â‰¥1 âˆ’2ËœÎ´
(93)
where the last inequalities follows from E2 âˆ©E3 âˆ©
E4 âŠ†{|X(T0 + 1)| â‰¤x(T0 + 1, ËœÎ´/3, x0)} âˆ©

|Ë†Î¸(i) âˆ’
Î¸âˆ—| â‰¤e(i, ËœÎ´, x0) for all i â‰¥(T0 + 1) âˆ’1
	
âˆ©{X(i) âˆˆ
XRPI for all i â‰¥(T0 + 1)}, and the fact that P(E2 âˆ©E3 âˆ©
E4) â‰¥1 âˆ’ËœÎ´ from Proposition 1.
Next, define Î· as a function from N0 to Râ‰¥0 satisfying
Î·(t) := maxtâ€²â‰¥t ËœÎ·(tâ€²) for t âˆˆN0, with ËœÎ·(t) defined as
ËœÎ·(t)
=
ï£±
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£²
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£³
x(T0 + 1, Î´/3, x0),
0 â‰¤t â‰¤T0,
max

Î²1(x(T0 + 1, Î´/3, x0), t âˆ’(T0 + 1)),
Î²2(maxT0â‰¤iâ‰¤T0+âŒŠ(tâˆ’(T0+1))/2âŒ‹e(i, Î´, x0),
t âˆ’(T0 + 1)) + Î·2(t âˆ’(T0 + 1)),
Î³3
 maxT0+1+âŒŠ(tâˆ’(T0+1))/2âŒ‹â‰¤iâ‰¤tâˆ’1 e(i, Î´, x0)

,
t â‰¥T0 + 1.
(94)
for all t
âˆˆ
N0, where clearly Î·
âˆˆ
L since since
limtâ†’âˆžËœÎ³(t) = 0 due to the fact that limtâ†’âˆže(t, ËœÎ´, x0) =
0 from Theorem 1. The conclusion follows by combining
(93) with (94), and substituting ËœÎ´ with Î´/2.
We now provide the proof of Corollary 1, which follows
from Theorem 2.
Proof
of
Corollary
1 Since
(Ïˆ, Î±, Âµw, Âµs)
is
(cPE, pPE)-globally excited by assumption, it follows
21

that (Ïˆ, Î±, Âµw, Âµs) is (XPE, cPE, pPE)-regionally excited
with XPE = X, satisfying Assumption 6. Moreover,
note that Assumption 7 is trivially satisfied with
XRPI = X. It follows trivially that Tcontained(Î´/2, x0) =
sup

T âˆˆN | Bx(T ,Î´/6,x0)(0) âˆ©X âŠ†XRPI
	
=
âˆž.
Moreover,
from
Proposition
1,
we
know
that
Tconverge(Î´/2, x0) < âˆž. Next, note that (g, Î±, Âµw, Âµs) is
(V, Â¯Ï‘)-global stochastic Lyapunov by Assumption 10, so
(g, Î±, Âµw, Âµs) is (V, X, Â¯Ï‘)-stochastic Lyapunov, satisfying
Assumption 8. Since Tconverge(Î´/2, x0) < Tcontained =
âˆž, we have verified condition (8) and hence the premise
of Theorem 2, and therefore can establish (14), con-
cluding the proof.
6
Conclusion
In this work, we have provided a framework for AC
in linearly parameterised stochastic systems, that com-
bines a parameterised stabilising policy with regularised
least squares (RLS) for parameter estimation. We de-
rived non-asymptotic error bounds for the parameter es-
timate that holds for sufficiently large time with positive
probability under some assumptions, in particular, re-
quiring that the policy will render the states of the sys-
tem positively invariant in a regionally exciting set when
the parameter estimate is close to the true parameter.
By additionally assuming the existence of a stochastic
Lyapunov function over the invariant set, probabilistic
stability bounds were then derived. These bounds were
shown to exist for a regionally controllable PWA sys-
tem example. Then, under the stricter assumption of
global excitation and the existence of a global stochas-
tic Lyapunov function with small parameter estimation
error, high probability stability bounds were derived.
The usefulness of this result was showcased on an input-
constrained linear system example.
References
[1]
Veronica
Adetola,
Darryl
DeHaan,
and
Martin
Guay.
Adaptive model predictive control for constrained nonlinear
systems. Systems & Control Letters, 58(5):320â€“326, 2009.
[2]
Veronica Adetola and Martin Guay. Robust adaptive mpc
for constrained uncertain nonlinear systems. International
Journal
of
Adaptive
Control
and
Signal
Processing,
25(2):155â€“167, 2011.
[3]
David
Angeli
and
Eduardo
D
Sontag.
Forward
completeness,
unboundedness
observability,
and
their
lyapunov characterizations. Systems & Control Letters, 38(4-
5):209â€“217, 1999.
[4]
Anuradha M Annaswamy and Alexander L Fradkov.
A
historical perspective of adaptive control and learning.
Annual Reviews in Control, 52:18â€“41, 2021.
[5]
Mouhacine Benosman. Learning-based adaptive control for
nonlinear systems.
In 2014 European Control Conference
(ECC), pages 920â€“925. IEEE, 2014.
[6]
Nicholas M Boffi, Stephen Tu, and Jean-Jacques E Slotine.
Regret bounds for adaptive nonlinear control. In Learning
for Dynamics and Control, pages 471â€“483. PMLR, 2021.
[7]
Graham C Goodwin, Peter J Ramadge, and Peter E Caines.
Discrete time stochastic adaptive control. SIAM J. Control
Optim., 19(6):829â€“853, 1981.
[8]
Lei Guo.
On critical stability of discrete-time adaptive
nonlinear control. IEEE Transactions on Automatic Control,
42(11):1488â€“1499, 1997.
[9]
Z P Jiang, Andrew R Teel, and Laurent Praly. Small-gain
theorem for iss systems and applications.
Mathematics of
Control, Signals and Systems, 7:95â€“120, 1994.
[10] Olav Kallenberg and Olav Kallenberg.
Foundations of
modern probability, volume 2. Springer, 1997.
[11] Iasson Karafyllis and Miroslav Krstic. Adaptive certainty-
equivalence
control
with
regulation-triggered
finite-time
least-squares
identification.
IEEE
Transactions
on
Automatic Control, 63(10):3261â€“3275, 2018.
[12] Johannes KÃ¶hler, Peter KÃ¶tting, Raffaele Soloperto, Frank
AllgÃ¶wer, and Matthias A MÃ¼ller. A robust adaptive model
predictive control framework for nonlinear uncertain systems.
International Journal of Robust and Nonlinear Control,
31(18):8725â€“8749, 2021.
[13] Chanying Li and James Lam.
Stabilization of discrete-
time nonlinear uncertain systems by feedback based on ls
algorithm.
SIAM Journal on Control and Optimization,
51(2):1128â€“1151, 2013.
[14] Zhaobo Liu and Chanying Li.
Is it possible to stabilize
discrete-time
parameterized
uncertain
systems
growing
exponentially
fast?
SIAM
Journal
on
Control
and
Optimization, 57(3):1965â€“1984, 2019.
[15] Robert D McAllister and James B Rawlings. The stochastic
robustness
of
nominal
and
stochastic
model
predictive
control. IEEE Transactions on Automatic Control, 2022.
[16] James Blake Rawlings, David Q Mayne, and Moritz Diehl.
Model predictive control: theory, computation, and design,
volume 2. Nob Hill Publishing Madison, WI, 2017.
[17] AndrÃ¡s Sasfi, Melanie N Zeilinger, and Johannes KÃ¶hler.
Robust adaptive mpc using control contraction metrics.
Automatica, 155:111169, 2023.
[18] Seth Siriya, Jingge Zhu, Dragan NeÅ¡iÄ‡, and Ye Pu.
Non-
asymptotic bounds for closed-loop identification of unstable
nonlinear stochastic systems.
[19] Seth Siriya, Jingge Zhu, Dragan NeÅ¡iÄ‡, and Ye Pu. Learning-
based adaptive control for stochastic linear systems with
input constraints. IEEE Control Systems Letters, 2022.
[20] Seth Siriya, Jingge Zhu, Dragan NeÅ¡iÄ‡, and Ye Pu. Stability
bounds for learning-based adaptive control of discrete-
time multi-dimensional stochastic linear systems with input
constraints. In 2023 62nd IEEE Conference on Decision and
Control (CDC), pages 3802â€“3807. IEEE, 2023.
[21] Chen Wei and Lei Guo.
Prediction-based discrete-time
adaptive nonlinear stochastic control. IEEE Transactions on
Automatic Control, 44(9):1725â€“1729, 1999.
[22] LL Xie and Lei Guo. Adaptive control of a class of discrete-
time affine nonlinear systems.
Systems & control letters,
35(3):201â€“206, 1998.
22
