PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for
Personalized LLM
Siqi Liang1*†, Yudi Zhang2*, Yue Guo3
1Purdue University
2Iowa State University
3Columbia University
Abstract
We propose a novel framework for persona-based language
model system, motivated by the need for personalized AI
agents that adapt to individual user preferences. In our
approach, the agent embodies the user’s “persona” (e.g.
user profile or taste) and is powered by a large language
model (LLM). To enable the agent to leverage rich contex-
tual information, we introduce a Knowledge-Graph-enhanced
Retrieval-Augmented Generation (Graph RAG) mechanism
that constructs an LLM-derived graph index of relevant doc-
uments and summarizes communities of related information.
Our framework generates personalized prompts by combin-
ing: (1) a summary of the user’s historical behaviors and
preferences extracted from the knowledge graph, and (2) rel-
evant global interaction patterns identified through graph-
based community detection. This dynamic prompt engineer-
ing approach allows the agent to maintain consistent persona-
aligned behaviors while benefiting from collective knowl-
edge. On the LaMP benchmark, our method improves news
categorization F1 by 11.1%, movie tagging F1 by 56.1%, and
reduces product rating MAE by 10.4% over prior methods.
Our code is available at https://anonymous.4open.science/r/
PersonaAgentwGraphRAG-DE6F
Introduction
Large Language Models (LLMs) have shown strong perfor-
mance across applications, from recommendation tasks (Xu
and Zhang 2025; Liang, Zhang, and Wang 2025; Yu et al.
2025; Said 2025; Lin and et al. 2023) to agent-based sys-
tems capable of reasoning, dialogue, and tool use (Ruan and
et al. 2023). While earlier work applied LLMs to isolated
components of recommender systems, recent agent-based
approaches address more ambitious challenges such as
long-horizon decision-making, collaboration, and domain-
specific reasoning (Wang et al. 2024), often enhanced with
memory, planning, retrieval, and inter-agent communica-
tion for tasks like tutoring, simulation, and assistant work-
flows (Zou et al. 2025).
*These authors contributed equally.
†Equal
contribution
(alphabetical
order).
Corresponding
authors:
Siqi
Liang
(lsq950917@gmail.com),
Yudi
Zhang
(yudiz@iastate.edu)
Copyright © 2026, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
Within this paradigm, persona-driven agents are increas-
ingly important for personalization: in recommender sys-
tems, an agent may reflect a user’s taste profile; in decision-
support, it may simulate an expert’s reasoning style. By en-
coding preferences and behaviors into a natural language
persona, LLMs can adapt outputs to individual users, achiev-
ing personalized behavior across dialogue, reasoning, and
recommendation (Kenan Jiang 2024; Samuel, Zou, and et al.
2024). However, most prior work relies on static personas or
templates, without dynamically incorporating evolving be-
haviors or community knowledge. In domains like movie
recommendation or e-commerce, agents must produce de-
cisions aligned with changing preferences, motivating our
framework for persona-based LLM agents that ground out-
puts in both individual and collective knowledge.
Our system integrates three components: (1) a per-
sona prompt encoding user preferences; (2) a knowledge
graph capturing personal interactions and community pat-
terns (Chen and et al. 2024; Xu and et al. 2024); and (3)
a GraphRAG mechanism that retrieves and synthesizes rel-
evant context. Given a query, dense search identifies can-
didate nodes, graph traversal collects related user and item
signals, and the resulting subgraph is linearized and com-
bined with the persona prompt for generation. This enables
grounding in both user history and community wisdom, sup-
porting accurate and explainable personalization (Mansour
and et al. 2024; Zerhoudi and Granitzer 2024).
To our knowledge, this is the first system to combine
graph-based retrieval with dynamic persona prompting de-
rived from both individual and community patterns. The re-
sult is a knowledge-aware, preference-aligned agent that im-
proves personalization in tasks such as movie tagging and
product rating.
Related Work
Persona-Based LLM Agents
Recent work has begun to endow LLM agents with ex-
plicit personas to achieve personalized behavior. Persona
agents have demonstrated improved contextual and person-
alized responses across applications such as tutoring, cus-
tomer support, and gaming (Zhang and et al. 2024). Per-
sonaGym (Samuel, Zou, and et al. 2024) measures whether
agents take optimal actions aligned with their personas,
arXiv:2511.17467v1  [cs.LG]  21 Nov 2025

Figure 1: Overview of the PersonaAgent with GraphRAG framework.
it assesses adherence to persona-specific communication
styles, consistency in persona attributes, and avoidance of
harmful outputs. HARBOR (Kenan Jiang 2024) explores
how an agent’s assigned persona affects its bidding behav-
ior, whether agents can accurately profile competitors’ per-
sonas during auctions. Other studies have shown that per-
sona prompts allow agents to extrapolate consistent prefer-
ences (e.g., adjusting answers about a tractor differently for
a farmer vs. an urban planner persona). However, most prior
work focuses on static personas or template-based personal-
ization, rather than dynamically incorporating user behavior
patterns and community knowledge.
Memory and Knowledge Integration in LLM
Systems
Memory and knowledge integration are critical for maintain-
ing consistent and informed agent behavior. LLM-memory
systems typically combine short-term context windows with
long-term external memories (Xu and et al. 2024; Chen and
et al. 2024). For example, Xu et al (Xu and et al. 2024)
proposes a sophisticated memory architecture with multi-
ple specialized memory types (episodic, semantic, procedu-
ral, etc) to support complex reasoning tasks. More generally,
surveys have drawn analogies between human memory sys-
tems and AI memory modules (Chen and et al. 2024). These
insights inform our approach to maintaining user preference
histories and behavioral patterns.
Retrieval-Augmented Generation and Knowledge
Graphs
Retrieval-Augmented Generation (RAG) techniques use ex-
ternal knowledge to improve LLM outputs. Classical RAG
approaches select relevant text passages via sparse term-
matching or dense embedding search (Lewis and et al. 2023;
Mansour and et al. 2024). Recent work has extended this
to graph-based knowledge structures. Graph-based RAG
(GraphRAG) enriches retrieval with structured knowledge
graphs: after an initial search for relevant entities, the system
traverses graph links to gather related information (Man-
sour and et al. 2024; Zerhoudi and Granitzer 2024). This ap-
proach grounds LLMs in relational data, improving factual
accuracy and explainability. Our framework builds on these
ideas by encoding both domain knowledge and user behav-
ior patterns in a knowledge graph, using a combination of
vector retrieval and graph expansion to construct personal-
ized contexts for the LLM.
Methodology
Our PersonaAgent system leverages Knowledge Graph-
based GraphRAG to enable personalized content genera-
tion. The system combines individual user preferences with
broader community insights through a structured knowledge
graph and personalized prompt generation (see Fig 1).
Knowledge Graph Construction
Our system maintains a heterogeneous knowledge graph
G = (V, E) where nodes V represent:
1. Interaction nodes: Represent user interactions and con-
tain metadata such as title, text, category, and timestamp.
2. Concept nodes: Represent extracted named entities and
domain-relevant keywords from interaction text. These
nodes generalize across users and support semantic rea-
soning.
3. Category nodes: Represent high-level content domains,
linking interactions with broader thematic structures.
Edges E in the graph capture semantic relationships be-
tween nodes:
• Interaction ↔Category: Connects interactions to their
categorical domain.
• Interaction ↔Concept: Links an interaction to its ex-
tracted concepts or entities.

• Concept ↔Concept: Can be inferred via co-occurrence
across interactions or shared categories to enable graph-
based community detection.
For each new interaction, the system 1) Creates an interac-
tion node with unique identifier; 2) Extracts relevant con-
cepts using pattern-based and domain-specific methods; 3)
Establishes connections to existing nodes based on semantic
relationships.
GraphRAG Retrieval Mechanism
The system employs a dual-source retrieval approach that
combines personal and community-based insights:
User-Specific Retrieval For a given user u and query q,
we retrieve relevant interactions from their history:
Iuser(u, q) = TopK(sim(q, i) : i ∈Hu)
where Hu represents user u’s interaction history and sim
refers to the Cosine similarity measured by TF-IDF.
Global Retrieval We augment personal context with rel-
evant community interactions:
Iglobal(u, q) = TopK(sim(q, i) : i ∈Hall \ Hu)
The combined semantic context C(u, q) includes:
C(u, q) = {Iuser(u, q), Iglobal(u, q),
(1)
Pcat(u), Econcepts(u, q)}
(2)
where Pcat(u) represents user category preferences and
Econcepts(u, q) contains relevant concepts.
Personalized Prompt Generation
The system generates context-rich prompts by combining:
1) Task-specific instructions and available categories; 2) Re-
trieved personal interactions with relevance scores; 3) Re-
lated global community interactions and patterns; 4) User
preference distributions; 5) Relevant concept clusters.
The prompt construction process follows:
Algorithm 1: Personalized Prompt Generation
Require: User ID u, Query q, Categories C
Ensure: Personalized prompt P
1: context ←GetSemanticContext(u, q)
2: content ←ExtractTaskContent(q)
3: P ←InitializeBasePrompt(content, C)
4: P ←P+ FormatUserIntereaction
5: P ←P+ FormatCommunityIntereaction
6: P ←P+ FormatPreferencesAndConcepts(context)
7: return P
Results
Data Description
We evaluate our framework using the LaMP bench-
mark (Salemi et al. 2023), focusing on three decision-
making tasks: news categorization, movie tagging, and prod-
uct rating. These tasks enable us to assess the effectiveness
of personalized agents across diverse personalization do-
mains. Following the data processing procedure described
in (Zhang and et al. 2024), we construct test sets by selecting
the 100 users with the most extensive activity histories from
the time-ordered version of the LaMP dataset. In the train-
ing sets which are used to construct the knowledge graph,
the news data includes 274 users, the movie data includes
829 users, and product rating includes 1000 users.
Metircs Comparison
Table 1 presents results on three personalized tasks:
news categorization (LaMP-2N), movie tagging (LaMP-
2M), and product rating (LaMP-3). PersonaAgent with
GraphRAG consistently outperforms all baselines includ-
ing non-personalized LLMs (Liu et al. 2021), retrieval-
augmented prompting (ReAct) (Yao et al. 2023), memory-
based models (MemBank) (Zhong et al. 2023), and the prior
state-of-the-art PersonaAgent (Zhang and et al. 2024). On
LaMP-2N, it achieves 0.804 accuracy and 0.591 F1, improv-
ing over PersonaAgent by 1.0% and 11.1%, respectively.
On LaMP-2M, the gains are larger, with accuracy increasing
from 0.513 to 0.653 (+27.3%) and F1 from 0.424 to 0.662
(+56.1%), demonstrating stronger personalization for sub-
jective behaviors. For LaMP-3, GraphRAG reduces MAE
from 0.241 to 0.216 (–10.4%) and RMSE from 0.509 to
0.484 (–4.9%), indicating more precise rating prediction. We
also noticed that with our method, small models, such as
LLaMA3 can perform better than competing methods, for
example, on the movie data, accuracy can be improved by
13.6%. These results highlight the value of integrating struc-
tured user memory with graph-based retrieval.
Figure 2: LLMs Comparison on LaMP-2N
Figure
2
compares
five
language
models—Mistral
Small (Jiang and et al. 2023), LLaMA2-7B (Touvron and
et al. 2023), LLaMA3-8B (AI 2024), Claude 3.5 Sonnet,
and Claude 4 (Anthropic 2024)—on the LaMP-2N per-
sonalized news categorization task. Mistral Small performs
worst across all metrics, reflecting its limited capacity for
personalization. LLaMA2-7B shows strong results, rivaling
LLaMA3-8B in Accuracy and Recall despite its smaller size,
while LLaMA3-8B offers more balanced improvements in
F1 and Recall. Among Claude models, Claude 3.5 Sonnet
achieves the best overall performance, with the highest F1

Metrics
Non-Personalized
ReAct
MemBank
PersonaAgent
PersonaAgent
with GraphRAG
LaMP-2N: Personalized
News Categorization
Acc
0.660
0.639
0.741
0.796*
0.804
F1
0.386
0.381
0.456
0.532*
0.591
LaMP-2M: Personalized
Movie Tagging
Acc
0.387
0.450
0.470
0.513*
0.653
F1
0.302
0.378
0.391
0.424
0.662
LaMP-3: Personalized
Product Rating
MAE
0.295
0.313
0.321
0.241*
0.216
RMSE
0.590
0.590
0.582
0.509*
0.484
Table 1: Performance comparison across different tasks and models
Figure 3: Case study of PersonaAgent with GraphRAG for personalized classification
and Recall, highlighting its superior alignment with user-
specific content. By contrast, Claude 4 underperforms across
all metrics, often overcomplicating the task and failing to
provide correct answers.
Case Study
The example in Fig 3 demonstrates that incorporating glob-
ally similar interactions from other users into the person-
alization prompt substantially improves classification ac-
curacy by providing a broader contextual grounding be-
yond a single user’s history. In our example, the LLaMA3-
8B model misclassified an article about a Parkland shoot-
ing survivor’s essay for Teen Vogue as belonging to the
“women” category when only the user’s personal interaction
history was considered. This error is likely due to the user’s
strong historical preference for women-focused protest arti-
cles, which skewed the model’s prediction. However, when
we enriched the prompt with globally similar articles—such
as those involving youth activism and gun law reform (e.g.,
“Teen Survivors Of Florida Shooting To March On Wash-
ington”)—the model correctly classified the article as “pol-
itics”. These globally similar interactions helped steer the
model toward the correct thematic alignment by introducing
relevant but more nuanced examples, thus balancing person-
alization with generalizability. This demonstrates that com-
munity context acts as a corrective signal, especially when
a user’s preferences are strongly skewed or lack diversity
across topics.
Conclusion
We introduced PersonaAgent with GraphRAG, a frame-
work that integrates persona-driven prompting with graph-
enhanced retrieval to provide accurate, explainable, and con-
sistent personalization. By leveraging both user-specific his-
tories and global community patterns, the system balances
individual preferences with collective knowledge, yielding
improvements in news categorization, movie tagging, and
product rating.
Looking forward, two promising directions emerge. First,
multi-agent collaboration, where persona agents interact, ne-
gotiate, and share knowledge, could enhance robustness and
enable collective intelligence for recommendation, classifi-
cation, and decision-support. Second, incorporating inverse
reinforcement learning (IRL) (Beliaev and Sadigh 2024; Ke
et al. 2025; Jeon et al. 2020) would allow agents to infer
latent preference signals from behavior, aligning with both
explicit histories and implicit reward structures. This could
produce agents that better adapt to evolving goals while re-
maining consistent with user values.
References
AI, M. 2024. LLaMA 3 8B.
Anthropic. 2024. Claude 3.5 Sonnet.
Beliaev, M.; and Sadigh, D. 2024. Inverse Reinforcement
Learning by Estimating Expertise of Demonstrators. arXiv
preprint. Extended version of AAAI publication.

Chen, J.; and et al. 2024. From Persona to Personalization:
A Survey on Role-Playing Language Agents. arXiv preprint
arXiv:2404.18231.
Jeon, W.; Su, C.-Y.; Barde, P.; and et al. 2020. Regularized
Inverse Reinforcement Learning. arXiv:2010.03691.
Jiang, A. Q.; and et al. 2023. Mistral 7B. arXiv:2310.06825.
Ke, J.; Wu, F.; Wang, J.; and et al. 2025. Inverse Reinforce-
ment Learning with Switching Rewards and History Depen-
dency. In ICLR. Submission 10850.
Kenan Jiang, F. L., Li Xiong. 2024.
HARBOR: Explor-
ing Persona Dynamics in Multi-Agent Competition. arXiv
preprint arXiv:2502.12149.
Lewis, P.; and et al. 2023. Retrieval-Augmented Genera-
tion for Knowledge-Intensive NLP Tasks: A Survey. arXiv
preprint arXiv:2303.06519.
Liang, S.; Zhang, Y.; and Wang, Y. 2025.
C-TLSAN:
Content-Enhanced Time-Aware Long-and Short-Term At-
tention Network for Personalized Recommendation. arXiv
preprint arXiv:2506.13021.
Lin, J.; and et al. 2023. How Can Recommender Systems
Benefit from Large Language Models: A Survey.
arXiv
preprint arXiv:2306.05817.
Liu, J.; Shen, D.; Zhang, Y.; and et al. 2021. What Makes
Good In-Context Examples for GPT-3? arXiv:2101.06804.
Mansour, S.; and et al. 2024.
PAARS: Persona Aligned
Agentic Retail Shoppers. arXiv preprint arXiv:2506.13021.
Ruan, J.; and et al. 2023. TPTU: Large Language Model-
based AI Agents for Task Planning and Tool Usage. arXiv
preprint arXiv:2308.03427.
Said, A. 2025. On explaining recommendations with Large
Language Models: a review.
Frontiers in Big Data, 7:
1505284.
Salemi, A.; Mysore, S.; Bendersky, M.; and et al. 2023.
LaMP: When Large Language Models Meet Personaliza-
tion. arXiv:2304.11406.
Samuel, V.; Zou, H. P.; and et al., Y. Z. 2024. PersonaGym:
Evaluating Persona Agents and LLMs.
arXiv preprint
arXiv:2407.18416.
Touvron, H.; and et al. 2023. Llama 2: Open Foundation and
Fine-Tuned Chat Models. arXiv:2307.09288.
Wang, L.; Ma, C.; Feng, X.; and et al. 2024. A survey on
large language model based autonomous agents. Frontiers
of Computer Science, 18(6).
Xu, R.; and et al. 2024. Character is Destiny: Can Role-
Playing Language Agents Make Persona-Driven Decisions?
arXiv preprint arXiv:2404.12138.
Xu, Z.; and Zhang, Y. 2025.
LLM-Enhanced Rerank-
ing
for
Complementary
Product
Recommendation.
arXiv:2507.16237.
Yao, S.; Zhao, J.; Yu, D.; and et al. 2023.
ReAct:
Synergizing Reasoning and Acting in Language Models.
arXiv:2210.03629.
Yu, P.; Xu, Z.; Wang, J.; and et al. 2025. The Application
of Large Language Models in Recommendation Systems.
arXiv preprint arXiv:2501.02178. ArXiv:2501.02178v2.
Zerhoudi, S.; and Granitzer, M. 2024.
PersonaRAG:
Enhancing Retrieval-Augmented Generation Systems with
User-Centric Agents. arXiv preprint arXiv:2407.09394.
Zhang, W.; and et al. 2024.
PersonaAgent: When Large
Language Model Agents Meet Personalization at Test Time.
arXiv preprint arXiv:2506.06254.
Zhong, W.; Guo, L.; Gao, Q.; and et al. 2023. MemoryBank:
Enhancing Large Language Models with Long-Term Mem-
ory. arXiv:2305.10250.
Zou, H. P.; Huang, W.-C.; Wu, Y.; ; and et al. 2025. LLM-
Based Human-Agent Collaboration and Interaction Sys-
tems: A Survey. arXiv:2505.00753.
